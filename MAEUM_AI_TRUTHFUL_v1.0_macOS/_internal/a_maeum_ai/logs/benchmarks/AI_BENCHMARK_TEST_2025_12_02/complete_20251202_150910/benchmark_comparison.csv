benchmark_id,benchmark_name,category,avg_latency_ms,avg_accuracy,avg_power_w,mode_count
mmlu,MMLU,knowledge,1634.75,0.5025,188.72,4
mmlu_pro,MMLU-Pro,knowledge,1947.18,0.1825,194.45,4
hellaswag,HellaSwag,reasoning,1683.09,0.7575,190.91,4
arc_challenge,ARC-Challenge,reasoning,1750.89,0.8275,189.21,4
winogrande,WinoGrande,reasoning,1684.47,0.59,186.87,4
truthfulqa,TruthfulQA,truthfulness,1689.05,0.6825,187.35,4
gsm8k,GSM8K,math,1569.75,0.625,185.86,4
math,MATH,math,1830.57,0.495,189.37,4
humaneval,HumanEval,coding,1877.78,0.545,190.73,4
mbpp,MBPP,coding,1775.11,0.0,187.57,4
bbh,BBH,reasoning,1605.32,1.0,187.39,4
coqa,CoQA,conversation,1813.7,0.75,180.46,4
kobest,KoBEST,korean,1624.08,0.925,189.39,4
klue,KLUE,korean,1554.26,0.485,187.18,4
kmmlu,KMMLU,korean,1659.24,0.915,188.5,4
xnli,XNLI,multilingual,1184.73,0.33,195.23,4
latency,Latency,performance,1706.48,,181.18,4
