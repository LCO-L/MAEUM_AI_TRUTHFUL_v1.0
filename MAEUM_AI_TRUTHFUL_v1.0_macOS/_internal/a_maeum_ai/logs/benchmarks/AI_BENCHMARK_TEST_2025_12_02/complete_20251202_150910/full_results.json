{
  "generated_at": "2025-12-02T17:51:33.473132",
  "total_benchmarks": 68,
  "modes": [
    "auto",
    "balanced",
    "fast",
    "quality"
  ],
  "benchmark_ids": [
    "mmlu",
    "mmlu_pro",
    "hellaswag",
    "arc_challenge",
    "winogrande",
    "truthfulqa",
    "gsm8k",
    "math",
    "humaneval",
    "mbpp",
    "bbh",
    "coqa",
    "kobest",
    "klue",
    "kmmlu",
    "xnli",
    "latency"
  ],
  "system_info": {
    "os_system": "Windows",
    "os_release": "10",
    "os_version": "10.0.26100",
    "hostname": "DESKTOP-0K2OI03",
    "python_version": "3.10.10",
    "python_implementation": "CPython",
    "cpu_name": "AMD64 Family 26 Model 68 Stepping 0, AuthenticAMD",
    "cpu_cores": 8,
    "cpu_threads": 16,
    "cpu_freq_mhz": 4700.0,
    "memory_total_gb": 31.15,
    "memory_available_gb": 19.11,
    "gpu_name": "NVIDIA GeForce RTX 5080",
    "gpu_count": 1,
    "gpu_memory_total_mb": 16303.0,
    "gpu_driver_version": "581.08",
    "cuda_version": "12.8",
    "maeum_version": "",
    "model_name": "",
    "model_variant": "",
    "quantization": ""
  },
  "results": [
    {
      "benchmark_id": "mmlu",
      "benchmark_name": "MMLU",
      "category": "knowledge",
      "mode": "auto",
      "timestamp": "20251202_150910",
      "duration_s": 171.5158727169037,
      "num_samples": 100,
      "success_count": 100,
      "error_count": 0,
      "latency": {
        "avg_ms": 1638.9657250186428,
        "p50_ms": 1926.9067000132054,
        "p90_ms": 1983.025600016117,
        "p95_ms": 1996.7604589287662,
        "p99_ms": 2010.495317841415,
        "min_ms": 247.87590000778437,
        "max_ms": 2152.5522000156343,
        "std_ms": 0.0,
        "count": 100
      },
      "power": {
        "power_avg_w": 187.29390793862592,
        "power_max_w": 217.181,
        "power_min_w": null,
        "gpu_util_avg": 55.36490993995997,
        "gpu_util_max": null,
        "gpu_mem_avg_mb": null,
        "gpu_mem_peak_mb": 5256.9296875,
        "gpu_temp_avg_c": null,
        "gpu_temp_max_c": 59.0,
        "cpu_util_avg": 8.131020680453647,
        "cpu_util_max": null,
        "cpu_mem_avg_mb": null,
        "cpu_mem_peak_mb": 12784.7265625
      },
      "accuracy": {
        "accuracy": 0.52,
        "f1": 0.52,
        "em": 0.52,
        "precision": null,
        "recall": null,
        "extra": {
          "num_samples": 100,
          "dataset_status": "official_dataset",
          "dataset_name": "cais/mmlu"
        }
      },
      "efficiency": {
        "perf_per_watt": 0.0031243511130525205,
        "latency_per_watt": 306968.29561620497,
        "tokens_per_second": null,
        "tokens_per_watt": null
      },
      "config": {
        "suite_name": "knowledge",
        "benchmark_name": "mmlu",
        "task_name": "MMLU",
        "concurrency": 1,
        "num_requests": 100,
        "duration_s": null,
        "host": "localhost",
        "port": 12345,
        "endpoint": "/generate/simple",
        "mode": "auto",
        "max_tokens": 256,
        "temperature": 0.7,
        "model_name": null,
        "model_variant": null,
        "quantization": null,
        "compression_techniques": null,
        "context_window": null,
        "run_id": "78981e6c-0f0b-4825-a654-e759e7eaa590"
      },
      "system_info": {
        "os_system": "Windows",
        "os_release": "10",
        "os_version": "10.0.26100",
        "hostname": "DESKTOP-0K2OI03",
        "python_version": "3.10.10",
        "python_implementation": "CPython",
        "cpu_name": "AMD64 Family 26 Model 68 Stepping 0, AuthenticAMD",
        "cpu_cores": 8,
        "cpu_threads": 16,
        "cpu_freq_mhz": 4700.0,
        "memory_total_gb": 31.15,
        "memory_available_gb": 19.11,
        "gpu_name": "NVIDIA GeForce RTX 5080",
        "gpu_count": 1,
        "gpu_memory_total_mb": 16303.0,
        "gpu_driver_version": "581.08",
        "cuda_version": "12.8",
        "maeum_version": "",
        "model_name": "",
        "model_variant": "",
        "quantization": ""
      },
      "model_info": {},
      "notes": {
        "status": "official_dataset",
        "benchmark_type": "mmlu",
        "dataset": "cais/mmlu"
      },
      "raw_latencies": []
    },
    {
      "benchmark_id": "mmlu",
      "benchmark_name": "MMLU",
      "category": "knowledge",
      "mode": "balanced",
      "timestamp": "20251202_150910",
      "duration_s": 170.20341730117798,
      "num_samples": 100,
      "success_count": 100,
      "error_count": 0,
      "latency": {
        "avg_ms": 1637.800149996765,
        "p50_ms": 1930.218950030394,
        "p90_ms": 1994.609349919483,
        "p95_ms": 2009.0979369636625,
        "p99_ms": 2023.5865240078422,
        "min_ms": 264.86769993789494,
        "max_ms": 2050.3585000988096,
        "std_ms": 0.0,
        "count": 100
      },
      "power": {
        "power_avg_w": 188.90665443629098,
        "power_max_w": 218.307,
        "power_min_w": null,
        "gpu_util_avg": 55.00733822548366,
        "gpu_util_max": null,
        "gpu_mem_avg_mb": null,
        "gpu_mem_peak_mb": 5256.9296875,
        "gpu_temp_avg_c": null,
        "gpu_temp_max_c": 59.0,
        "cpu_util_avg": 8.157304869913284,
        "cpu_util_max": null,
        "cpu_mem_avg_mb": null,
        "cpu_mem_peak_mb": 12728.43359375
      },
      "accuracy": {
        "accuracy": 0.41,
        "f1": 0.41,
        "em": 0.41,
        "precision": null,
        "recall": null,
        "extra": {
          "num_samples": 100,
          "dataset_status": "official_dataset",
          "dataset_name": "cais/mmlu"
        }
      },
      "efficiency": {
        "perf_per_watt": 0.0031218498219091157,
        "latency_per_watt": 309391.34697114443,
        "tokens_per_second": null,
        "tokens_per_watt": null
      },
      "config": {
        "suite_name": "knowledge",
        "benchmark_name": "mmlu",
        "task_name": "MMLU",
        "concurrency": 1,
        "num_requests": 100,
        "duration_s": null,
        "host": "localhost",
        "port": 12345,
        "endpoint": "/generate/simple",
        "mode": "balanced",
        "max_tokens": 256,
        "temperature": 0.7,
        "model_name": null,
        "model_variant": null,
        "quantization": null,
        "compression_techniques": null,
        "context_window": null,
        "run_id": "27496032-3e7b-4f8f-9364-9b57586ec997"
      },
      "system_info": {
        "os_system": "Windows",
        "os_release": "10",
        "os_version": "10.0.26100",
        "hostname": "DESKTOP-0K2OI03",
        "python_version": "3.10.10",
        "python_implementation": "CPython",
        "cpu_name": "AMD64 Family 26 Model 68 Stepping 0, AuthenticAMD",
        "cpu_cores": 8,
        "cpu_threads": 16,
        "cpu_freq_mhz": 4700.0,
        "memory_total_gb": 31.15,
        "memory_available_gb": 19.11,
        "gpu_name": "NVIDIA GeForce RTX 5080",
        "gpu_count": 1,
        "gpu_memory_total_mb": 16303.0,
        "gpu_driver_version": "581.08",
        "cuda_version": "12.8",
        "maeum_version": "",
        "model_name": "",
        "model_variant": "",
        "quantization": ""
      },
      "model_info": {},
      "notes": {
        "status": "official_dataset",
        "benchmark_type": "mmlu",
        "dataset": "cais/mmlu"
      },
      "raw_latencies": []
    },
    {
      "benchmark_id": "mmlu",
      "benchmark_name": "MMLU",
      "category": "knowledge",
      "mode": "fast",
      "timestamp": "20251202_150910",
      "duration_s": 172.70896172523499,
      "num_samples": 100,
      "success_count": 100,
      "error_count": 0,
      "latency": {
        "avg_ms": 1667.33484597411,
        "p50_ms": 1928.0952999833971,
        "p90_ms": 1983.3465899107978,
        "p95_ms": 1992.708100421587,
        "p99_ms": 2002.0696109323762,
        "min_ms": 259.40440013073385,
        "max_ms": 2008.0701000988483,
        "std_ms": 0.0,
        "count": 100
      },
      "power": {
        "power_avg_w": 190.52158480681163,
        "power_max_w": 217.763,
        "power_min_w": null,
        "gpu_util_avg": 62.127046496398165,
        "gpu_util_max": null,
        "gpu_mem_avg_mb": null,
        "gpu_mem_peak_mb": 5256.9296875,
        "gpu_temp_avg_c": null,
        "gpu_temp_max_c": 60.0,
        "cpu_util_avg": 8.087164374590715,
        "cpu_util_max": null,
        "cpu_mem_avg_mb": null,
        "cpu_mem_peak_mb": 12696.140625
      },
      "accuracy": {
        "accuracy": 0.58,
        "f1": 0.58,
        "em": 0.58,
        "precision": null,
        "recall": null,
        "extra": {
          "num_samples": 100,
          "dataset_status": "official_dataset",
          "dataset_name": "cais/mmlu"
        }
      },
      "efficiency": {
        "perf_per_watt": 0.003049001092455294,
        "latency_per_watt": 317663.2772586086,
        "tokens_per_second": null,
        "tokens_per_watt": null
      },
      "config": {
        "suite_name": "knowledge",
        "benchmark_name": "mmlu",
        "task_name": "MMLU",
        "concurrency": 1,
        "num_requests": 100,
        "duration_s": null,
        "host": "localhost",
        "port": 12345,
        "endpoint": "/generate/simple",
        "mode": "fast",
        "max_tokens": 256,
        "temperature": 0.7,
        "model_name": null,
        "model_variant": null,
        "quantization": null,
        "compression_techniques": null,
        "context_window": null,
        "run_id": "0a7e962f-8f91-4e1e-97ae-8a049df4bed7"
      },
      "system_info": {
        "os_system": "Windows",
        "os_release": "10",
        "os_version": "10.0.26100",
        "hostname": "DESKTOP-0K2OI03",
        "python_version": "3.10.10",
        "python_implementation": "CPython",
        "cpu_name": "AMD64 Family 26 Model 68 Stepping 0, AuthenticAMD",
        "cpu_cores": 8,
        "cpu_threads": 16,
        "cpu_freq_mhz": 4700.0,
        "memory_total_gb": 31.15,
        "memory_available_gb": 19.11,
        "gpu_name": "NVIDIA GeForce RTX 5080",
        "gpu_count": 1,
        "gpu_memory_total_mb": 16303.0,
        "gpu_driver_version": "581.08",
        "cuda_version": "12.8",
        "maeum_version": "",
        "model_name": "",
        "model_variant": "",
        "quantization": ""
      },
      "model_info": {},
      "notes": {
        "status": "official_dataset",
        "benchmark_type": "mmlu",
        "dataset": "cais/mmlu"
      },
      "raw_latencies": []
    },
    {
      "benchmark_id": "mmlu",
      "benchmark_name": "MMLU",
      "category": "knowledge",
      "mode": "quality",
      "timestamp": "20251202_150910",
      "duration_s": 165.6030662059784,
      "num_samples": 100,
      "success_count": 100,
      "error_count": 0,
      "latency": {
        "avg_ms": 1594.8869900102727,
        "p50_ms": 1931.9794500479475,
        "p90_ms": 1976.5755201457068,
        "p95_ms": 1997.5023189827334,
        "p99_ms": 2018.42911781976,
        "min_ms": 265.5472999904305,
        "max_ms": 2024.4501000270247,
        "std_ms": 0.0,
        "count": 100
      },
      "power": {
        "power_avg_w": 188.16951471594868,
        "power_max_w": 217.34,
        "power_min_w": null,
        "gpu_util_avg": 57.75770020533881,
        "gpu_util_max": null,
        "gpu_mem_avg_mb": null,
        "gpu_mem_peak_mb": 5256.9921875,
        "gpu_temp_avg_c": null,
        "gpu_temp_max_c": 59.0,
        "cpu_util_avg": 8.183504449007533,
        "cpu_util_max": null,
        "cpu_mem_avg_mb": null,
        "cpu_mem_peak_mb": 12743.30078125
      },
      "accuracy": {
        "accuracy": 0.5,
        "f1": 0.5,
        "em": 0.5,
        "precision": null,
        "recall": null,
        "extra": {
          "num_samples": 100,
          "dataset_status": "official_dataset",
          "dataset_name": "cais/mmlu"
        }
      },
      "efficiency": {
        "perf_per_watt": 0.003220930116069656,
        "latency_per_watt": 300109.1109370131,
        "tokens_per_second": null,
        "tokens_per_watt": null
      },
      "config": {
        "suite_name": "knowledge",
        "benchmark_name": "mmlu",
        "task_name": "MMLU",
        "concurrency": 1,
        "num_requests": 100,
        "duration_s": null,
        "host": "localhost",
        "port": 12345,
        "endpoint": "/generate/simple",
        "mode": "quality",
        "max_tokens": 256,
        "temperature": 0.7,
        "model_name": null,
        "model_variant": null,
        "quantization": null,
        "compression_techniques": null,
        "context_window": null,
        "run_id": "09e23b47-497e-46c0-b303-ba5747f08868"
      },
      "system_info": {
        "os_system": "Windows",
        "os_release": "10",
        "os_version": "10.0.26100",
        "hostname": "DESKTOP-0K2OI03",
        "python_version": "3.10.10",
        "python_implementation": "CPython",
        "cpu_name": "AMD64 Family 26 Model 68 Stepping 0, AuthenticAMD",
        "cpu_cores": 8,
        "cpu_threads": 16,
        "cpu_freq_mhz": 4700.0,
        "memory_total_gb": 31.15,
        "memory_available_gb": 19.11,
        "gpu_name": "NVIDIA GeForce RTX 5080",
        "gpu_count": 1,
        "gpu_memory_total_mb": 16303.0,
        "gpu_driver_version": "581.08",
        "cuda_version": "12.8",
        "maeum_version": "",
        "model_name": "",
        "model_variant": "",
        "quantization": ""
      },
      "model_info": {},
      "notes": {
        "status": "official_dataset",
        "benchmark_type": "mmlu",
        "dataset": "cais/mmlu"
      },
      "raw_latencies": []
    },
    {
      "benchmark_id": "mmlu_pro",
      "benchmark_name": "MMLU-Pro",
      "category": "knowledge",
      "mode": "auto",
      "timestamp": "20251202_150910",
      "duration_s": 198.24492287635803,
      "num_samples": 100,
      "success_count": 100,
      "error_count": 0,
      "latency": {
        "avg_ms": 1925.590729007963,
        "p50_ms": 1981.3444000901654,
        "p90_ms": 2024.8601200059056,
        "p95_ms": 2049.472088016337,
        "p99_ms": 2074.0840560267684,
        "min_ms": 947.7663999423385,
        "max_ms": 2123.2233000919223,
        "std_ms": 0.0,
        "count": 100
      },
      "power": {
        "power_avg_w": 194.17191181458452,
        "power_max_w": 218.93,
        "power_min_w": null,
        "gpu_util_avg": 60.345958168456754,
        "gpu_util_max": null,
        "gpu_mem_avg_mb": null,
        "gpu_mem_peak_mb": 5254.4921875,
        "gpu_temp_avg_c": null,
        "gpu_temp_max_c": 61.0,
        "cpu_util_avg": 10.15647258338044,
        "cpu_util_max": null,
        "cpu_mem_avg_mb": null,
        "cpu_mem_peak_mb": 12785.58984375
      },
      "accuracy": {
        "accuracy": 0.24,
        "f1": 0.24,
        "em": 0.24,
        "precision": null,
        "recall": null,
        "extra": {
          "num_samples": 100,
          "dataset_status": "official_dataset",
          "dataset_name": "TIGER-Lab/MMLU-Pro"
        }
      },
      "efficiency": {
        "perf_per_watt": 0.0026062777753976937,
        "latency_per_watt": 373895.6332239157,
        "tokens_per_second": null,
        "tokens_per_watt": null
      },
      "config": {
        "suite_name": "knowledge",
        "benchmark_name": "mmlu_pro",
        "task_name": "MMLU-Pro",
        "concurrency": 1,
        "num_requests": 100,
        "duration_s": null,
        "host": "localhost",
        "port": 12345,
        "endpoint": "/generate/simple",
        "mode": "auto",
        "max_tokens": 256,
        "temperature": 0.7,
        "model_name": null,
        "model_variant": null,
        "quantization": null,
        "compression_techniques": null,
        "context_window": null,
        "run_id": "6b936ff3-b395-4037-b112-0f9a70d5c2e3"
      },
      "system_info": {
        "os_system": "Windows",
        "os_release": "10",
        "os_version": "10.0.26100",
        "hostname": "DESKTOP-0K2OI03",
        "python_version": "3.10.10",
        "python_implementation": "CPython",
        "cpu_name": "AMD64 Family 26 Model 68 Stepping 0, AuthenticAMD",
        "cpu_cores": 8,
        "cpu_threads": 16,
        "cpu_freq_mhz": 4700.0,
        "memory_total_gb": 31.15,
        "memory_available_gb": 19.11,
        "gpu_name": "NVIDIA GeForce RTX 5080",
        "gpu_count": 1,
        "gpu_memory_total_mb": 16303.0,
        "gpu_driver_version": "581.08",
        "cuda_version": "12.8",
        "maeum_version": "",
        "model_name": "",
        "model_variant": "",
        "quantization": ""
      },
      "model_info": {},
      "notes": {
        "status": "official_dataset",
        "benchmark_type": "mmlu_pro",
        "dataset": "TIGER-Lab/MMLU-Pro"
      },
      "raw_latencies": []
    },
    {
      "benchmark_id": "mmlu_pro",
      "benchmark_name": "MMLU-Pro",
      "category": "knowledge",
      "mode": "balanced",
      "timestamp": "20251202_150910",
      "duration_s": 201.56992435455322,
      "num_samples": 100,
      "success_count": 100,
      "error_count": 0,
      "latency": {
        "avg_ms": 1968.8217999902554,
        "p50_ms": 1975.1673500286415,
        "p90_ms": 2023.235589894466,
        "p95_ms": 2039.8216404090635,
        "p99_ms": 2056.407690923661,
        "min_ms": 1289.9413998238742,
        "max_ms": 2070.306400069967,
        "std_ms": 0.0,
        "count": 100
      },
      "power": {
        "power_avg_w": 194.54727464008877,
        "power_max_w": 220.238,
        "power_min_w": null,
        "gpu_util_avg": 62.19490586932447,
        "gpu_util_max": null,
        "gpu_mem_avg_mb": null,
        "gpu_mem_peak_mb": 5029.4921875,
        "gpu_temp_avg_c": null,
        "gpu_temp_max_c": 61.0,
        "cpu_util_avg": 9.89352159468441,
        "cpu_util_max": null,
        "cpu_mem_avg_mb": null,
        "cpu_mem_peak_mb": 12941.19140625
      },
      "accuracy": {
        "accuracy": 0.14,
        "f1": 0.14,
        "em": 0.14,
        "precision": null,
        "recall": null,
        "extra": {
          "num_samples": 100,
          "dataset_status": "official_dataset",
          "dataset_name": "TIGER-Lab/MMLU-Pro"
        }
      },
      "efficiency": {
        "perf_per_watt": 0.002558053843050636,
        "latency_per_watt": 383028.91544009815,
        "tokens_per_second": null,
        "tokens_per_watt": null
      },
      "config": {
        "suite_name": "knowledge",
        "benchmark_name": "mmlu_pro",
        "task_name": "MMLU-Pro",
        "concurrency": 1,
        "num_requests": 100,
        "duration_s": null,
        "host": "localhost",
        "port": 12345,
        "endpoint": "/generate/simple",
        "mode": "balanced",
        "max_tokens": 256,
        "temperature": 0.7,
        "model_name": null,
        "model_variant": null,
        "quantization": null,
        "compression_techniques": null,
        "context_window": null,
        "run_id": "c769cf62-527f-4646-9743-45e5e1a645eb"
      },
      "system_info": {
        "os_system": "Windows",
        "os_release": "10",
        "os_version": "10.0.26100",
        "hostname": "DESKTOP-0K2OI03",
        "python_version": "3.10.10",
        "python_implementation": "CPython",
        "cpu_name": "AMD64 Family 26 Model 68 Stepping 0, AuthenticAMD",
        "cpu_cores": 8,
        "cpu_threads": 16,
        "cpu_freq_mhz": 4700.0,
        "memory_total_gb": 31.15,
        "memory_available_gb": 19.11,
        "gpu_name": "NVIDIA GeForce RTX 5080",
        "gpu_count": 1,
        "gpu_memory_total_mb": 16303.0,
        "gpu_driver_version": "581.08",
        "cuda_version": "12.8",
        "maeum_version": "",
        "model_name": "",
        "model_variant": "",
        "quantization": ""
      },
      "model_info": {},
      "notes": {
        "status": "official_dataset",
        "benchmark_type": "mmlu_pro",
        "dataset": "TIGER-Lab/MMLU-Pro"
      },
      "raw_latencies": []
    },
    {
      "benchmark_id": "mmlu_pro",
      "benchmark_name": "MMLU-Pro",
      "category": "knowledge",
      "mode": "fast",
      "timestamp": "20251202_150910",
      "duration_s": 200.11797404289246,
      "num_samples": 100,
      "success_count": 100,
      "error_count": 0,
      "latency": {
        "avg_ms": 1953.7505279993638,
        "p50_ms": 1975.1221000915393,
        "p90_ms": 2009.2194501077756,
        "p95_ms": 2033.566240076907,
        "p99_ms": 2057.9130300460383,
        "min_ms": 1159.9727000575513,
        "max_ms": 2063.3213999681175,
        "std_ms": 0.0,
        "count": 100
      },
      "power": {
        "power_avg_w": 194.4033552338531,
        "power_max_w": 217.849,
        "power_min_w": null,
        "gpu_util_avg": 54.80011135857461,
        "gpu_util_max": null,
        "gpu_mem_avg_mb": null,
        "gpu_mem_peak_mb": 5032.8984375,
        "gpu_temp_avg_c": null,
        "gpu_temp_max_c": 61.0,
        "cpu_util_avg": 10.044599109131413,
        "cpu_util_max": null,
        "cpu_mem_avg_mb": null,
        "cpu_mem_peak_mb": 12917.6875
      },
      "accuracy": {
        "accuracy": 0.19,
        "f1": 0.19,
        "em": 0.19,
        "precision": null,
        "recall": null,
        "extra": {
          "num_samples": 100,
          "dataset_status": "official_dataset",
          "dataset_name": "TIGER-Lab/MMLU-Pro"
        }
      },
      "efficiency": {
        "perf_per_watt": 0.0025788253617041556,
        "latency_per_watt": 379815.65793298837,
        "tokens_per_second": null,
        "tokens_per_watt": null
      },
      "config": {
        "suite_name": "knowledge",
        "benchmark_name": "mmlu_pro",
        "task_name": "MMLU-Pro",
        "concurrency": 1,
        "num_requests": 100,
        "duration_s": null,
        "host": "localhost",
        "port": 12345,
        "endpoint": "/generate/simple",
        "mode": "fast",
        "max_tokens": 256,
        "temperature": 0.7,
        "model_name": null,
        "model_variant": null,
        "quantization": null,
        "compression_techniques": null,
        "context_window": null,
        "run_id": "78beb755-342c-45ee-bba0-e7392262b65e"
      },
      "system_info": {
        "os_system": "Windows",
        "os_release": "10",
        "os_version": "10.0.26100",
        "hostname": "DESKTOP-0K2OI03",
        "python_version": "3.10.10",
        "python_implementation": "CPython",
        "cpu_name": "AMD64 Family 26 Model 68 Stepping 0, AuthenticAMD",
        "cpu_cores": 8,
        "cpu_threads": 16,
        "cpu_freq_mhz": 4700.0,
        "memory_total_gb": 31.15,
        "memory_available_gb": 19.11,
        "gpu_name": "NVIDIA GeForce RTX 5080",
        "gpu_count": 1,
        "gpu_memory_total_mb": 16303.0,
        "gpu_driver_version": "581.08",
        "cuda_version": "12.8",
        "maeum_version": "",
        "model_name": "",
        "model_variant": "",
        "quantization": ""
      },
      "model_info": {},
      "notes": {
        "status": "official_dataset",
        "benchmark_type": "mmlu_pro",
        "dataset": "TIGER-Lab/MMLU-Pro"
      },
      "raw_latencies": []
    },
    {
      "benchmark_id": "mmlu_pro",
      "benchmark_name": "MMLU-Pro",
      "category": "knowledge",
      "mode": "quality",
      "timestamp": "20251202_150910",
      "duration_s": 201.44083333015442,
      "num_samples": 100,
      "success_count": 100,
      "error_count": 0,
      "latency": {
        "avg_ms": 1940.5376059911214,
        "p50_ms": 1965.0242000352591,
        "p90_ms": 2002.4100001901388,
        "p95_ms": 2013.2815680885687,
        "p99_ms": 2024.153135986999,
        "min_ms": 790.4959998559207,
        "max_ms": 2072.4587999284267,
        "std_ms": 0.0,
        "count": 100
      },
      "power": {
        "power_avg_w": 194.68189313835683,
        "power_max_w": 220.596,
        "power_min_w": null,
        "gpu_util_avg": 60.11867266591676,
        "gpu_util_max": null,
        "gpu_mem_avg_mb": null,
        "gpu_mem_peak_mb": 5033.5859375,
        "gpu_temp_avg_c": null,
        "gpu_temp_max_c": 60.0,
        "cpu_util_avg": 8.66878515185604,
        "cpu_util_max": null,
        "cpu_mem_avg_mb": null,
        "cpu_mem_peak_mb": 12826.6171875
      },
      "accuracy": {
        "accuracy": 0.16,
        "f1": 0.16,
        "em": 0.16,
        "precision": null,
        "recall": null,
        "extra": {
          "num_samples": 100,
          "dataset_status": "official_dataset",
          "dataset_name": "TIGER-Lab/MMLU-Pro"
        }
      },
      "efficiency": {
        "perf_per_watt": 0.0025582709890773735,
        "latency_per_watt": 377787.5348405263,
        "tokens_per_second": null,
        "tokens_per_watt": null
      },
      "config": {
        "suite_name": "knowledge",
        "benchmark_name": "mmlu_pro",
        "task_name": "MMLU-Pro",
        "concurrency": 1,
        "num_requests": 100,
        "duration_s": null,
        "host": "localhost",
        "port": 12345,
        "endpoint": "/generate/simple",
        "mode": "quality",
        "max_tokens": 256,
        "temperature": 0.7,
        "model_name": null,
        "model_variant": null,
        "quantization": null,
        "compression_techniques": null,
        "context_window": null,
        "run_id": "8e476245-be4a-43f7-9eb2-04e96f1fdb25"
      },
      "system_info": {
        "os_system": "Windows",
        "os_release": "10",
        "os_version": "10.0.26100",
        "hostname": "DESKTOP-0K2OI03",
        "python_version": "3.10.10",
        "python_implementation": "CPython",
        "cpu_name": "AMD64 Family 26 Model 68 Stepping 0, AuthenticAMD",
        "cpu_cores": 8,
        "cpu_threads": 16,
        "cpu_freq_mhz": 4700.0,
        "memory_total_gb": 31.15,
        "memory_available_gb": 19.11,
        "gpu_name": "NVIDIA GeForce RTX 5080",
        "gpu_count": 1,
        "gpu_memory_total_mb": 16303.0,
        "gpu_driver_version": "581.08",
        "cuda_version": "12.8",
        "maeum_version": "",
        "model_name": "",
        "model_variant": "",
        "quantization": ""
      },
      "model_info": {},
      "notes": {
        "status": "official_dataset",
        "benchmark_type": "mmlu_pro",
        "dataset": "TIGER-Lab/MMLU-Pro"
      },
      "raw_latencies": []
    },
    {
      "benchmark_id": "hellaswag",
      "benchmark_name": "HellaSwag",
      "category": "reasoning",
      "mode": "auto",
      "timestamp": "20251202_150910",
      "duration_s": 177.72114205360413,
      "num_samples": 100,
      "success_count": 100,
      "error_count": 0,
      "latency": {
        "avg_ms": 1705.4889359977096,
        "p50_ms": 1834.5318000065163,
        "p90_ms": 1997.1289701061323,
        "p95_ms": 2010.8517085458152,
        "p99_ms": 2024.574446985498,
        "min_ms": 513.1095999386162,
        "max_ms": 2026.8363000359386,
        "std_ms": 0.0,
        "count": 100
      },
      "power": {
        "power_avg_w": 191.2109313662602,
        "power_max_w": 217.38,
        "power_min_w": null,
        "gpu_util_avg": 59.30532392559333,
        "gpu_util_max": null,
        "gpu_mem_avg_mb": null,
        "gpu_mem_peak_mb": 4997.7421875,
        "gpu_temp_avg_c": null,
        "gpu_temp_max_c": 60.0,
        "cpu_util_avg": 8.191276459268792,
        "cpu_util_max": null,
        "cpu_mem_avg_mb": null,
        "cpu_mem_peak_mb": 12756.51171875
      },
      "accuracy": {
        "accuracy": 0.73,
        "f1": 0.73,
        "em": 0.73,
        "precision": null,
        "recall": null,
        "extra": {
          "num_samples": 100,
          "dataset_status": "official_dataset",
          "dataset_name": "Rowan/hellaswag"
        }
      },
      "efficiency": {
        "perf_per_watt": 0.002953105579712065,
        "latency_per_watt": 326108.1278869742,
        "tokens_per_second": null,
        "tokens_per_watt": null
      },
      "config": {
        "suite_name": "reasoning",
        "benchmark_name": "hellaswag",
        "task_name": "HellaSwag",
        "concurrency": 1,
        "num_requests": 100,
        "duration_s": null,
        "host": "localhost",
        "port": 12345,
        "endpoint": "/generate/simple",
        "mode": "auto",
        "max_tokens": 256,
        "temperature": 0.7,
        "model_name": null,
        "model_variant": null,
        "quantization": null,
        "compression_techniques": null,
        "context_window": null,
        "run_id": "93f4db42-c02e-4a64-a5a3-341112f0ff94"
      },
      "system_info": {
        "os_system": "Windows",
        "os_release": "10",
        "os_version": "10.0.26100",
        "hostname": "DESKTOP-0K2OI03",
        "python_version": "3.10.10",
        "python_implementation": "CPython",
        "cpu_name": "AMD64 Family 26 Model 68 Stepping 0, AuthenticAMD",
        "cpu_cores": 8,
        "cpu_threads": 16,
        "cpu_freq_mhz": 4700.0,
        "memory_total_gb": 31.15,
        "memory_available_gb": 19.11,
        "gpu_name": "NVIDIA GeForce RTX 5080",
        "gpu_count": 1,
        "gpu_memory_total_mb": 16303.0,
        "gpu_driver_version": "581.08",
        "cuda_version": "12.8",
        "maeum_version": "",
        "model_name": "",
        "model_variant": "",
        "quantization": ""
      },
      "model_info": {},
      "notes": {
        "status": "official_dataset",
        "benchmark_type": "hellaswag",
        "dataset": "Rowan/hellaswag"
      },
      "raw_latencies": []
    },
    {
      "benchmark_id": "hellaswag",
      "benchmark_name": "HellaSwag",
      "category": "reasoning",
      "mode": "balanced",
      "timestamp": "20251202_150910",
      "duration_s": 174.32735872268677,
      "num_samples": 100,
      "success_count": 100,
      "error_count": 0,
      "latency": {
        "avg_ms": 1678.7744459859096,
        "p50_ms": 1810.5270999949425,
        "p90_ms": 2002.5010999292135,
        "p95_ms": 2016.1368935299106,
        "p99_ms": 2029.7726871306077,
        "min_ms": 315.81959989853203,
        "max_ms": 2030.1178998779505,
        "std_ms": 0.0,
        "count": 100
      },
      "power": {
        "power_avg_w": 190.83588013029348,
        "power_max_w": 218.105,
        "power_min_w": null,
        "gpu_util_avg": 54.81628664495114,
        "gpu_util_max": null,
        "gpu_mem_avg_mb": null,
        "gpu_mem_peak_mb": 4997.9921875,
        "gpu_temp_avg_c": null,
        "gpu_temp_max_c": 59.0,
        "cpu_util_avg": 8.154788273615656,
        "cpu_util_max": null,
        "cpu_mem_avg_mb": null,
        "cpu_mem_peak_mb": 12739.4140625
      },
      "accuracy": {
        "accuracy": 0.81,
        "f1": 0.81,
        "em": 0.81,
        "precision": null,
        "recall": null,
        "extra": {
          "num_samples": 100,
          "dataset_status": "official_dataset",
          "dataset_name": "Rowan/hellaswag"
        }
      },
      "efficiency": {
        "perf_per_watt": 0.003016883306133598,
        "latency_per_watt": 320370.39893996686,
        "tokens_per_second": null,
        "tokens_per_watt": null
      },
      "config": {
        "suite_name": "reasoning",
        "benchmark_name": "hellaswag",
        "task_name": "HellaSwag",
        "concurrency": 1,
        "num_requests": 100,
        "duration_s": null,
        "host": "localhost",
        "port": 12345,
        "endpoint": "/generate/simple",
        "mode": "balanced",
        "max_tokens": 256,
        "temperature": 0.7,
        "model_name": null,
        "model_variant": null,
        "quantization": null,
        "compression_techniques": null,
        "context_window": null,
        "run_id": "c5619afa-0907-472a-ac59-56d36d6bf80a"
      },
      "system_info": {
        "os_system": "Windows",
        "os_release": "10",
        "os_version": "10.0.26100",
        "hostname": "DESKTOP-0K2OI03",
        "python_version": "3.10.10",
        "python_implementation": "CPython",
        "cpu_name": "AMD64 Family 26 Model 68 Stepping 0, AuthenticAMD",
        "cpu_cores": 8,
        "cpu_threads": 16,
        "cpu_freq_mhz": 4700.0,
        "memory_total_gb": 31.15,
        "memory_available_gb": 19.11,
        "gpu_name": "NVIDIA GeForce RTX 5080",
        "gpu_count": 1,
        "gpu_memory_total_mb": 16303.0,
        "gpu_driver_version": "581.08",
        "cuda_version": "12.8",
        "maeum_version": "",
        "model_name": "",
        "model_variant": "",
        "quantization": ""
      },
      "model_info": {},
      "notes": {
        "status": "official_dataset",
        "benchmark_type": "hellaswag",
        "dataset": "Rowan/hellaswag"
      },
      "raw_latencies": []
    },
    {
      "benchmark_id": "hellaswag",
      "benchmark_name": "HellaSwag",
      "category": "reasoning",
      "mode": "fast",
      "timestamp": "20251202_150910",
      "duration_s": 175.93490886688232,
      "num_samples": 100,
      "success_count": 100,
      "error_count": 0,
      "latency": {
        "avg_ms": 1692.0542089897208,
        "p50_ms": 1901.855949894525,
        "p90_ms": 2004.0028798626736,
        "p95_ms": 2018.4329024597541,
        "p99_ms": 2032.8629250568347,
        "min_ms": 310.21509994752705,
        "max_ms": 2188.76069993712,
        "std_ms": 0.0,
        "count": 100
      },
      "power": {
        "power_avg_w": 191.1341020671838,
        "power_max_w": 218.3,
        "power_min_w": null,
        "gpu_util_avg": 56.08462532299742,
        "gpu_util_max": null,
        "gpu_mem_avg_mb": null,
        "gpu_mem_peak_mb": 4997.9921875,
        "gpu_temp_avg_c": null,
        "gpu_temp_max_c": 59.0,
        "cpu_util_avg": 7.990826873385038,
        "cpu_util_max": null,
        "cpu_mem_avg_mb": null,
        "cpu_mem_peak_mb": 12750.4609375
      },
      "accuracy": {
        "accuracy": 0.78,
        "f1": 0.78,
        "em": 0.78,
        "precision": null,
        "recall": null,
        "extra": {
          "num_samples": 100,
          "dataset_status": "official_dataset",
          "dataset_name": "Rowan/hellaswag"
        }
      },
      "efficiency": {
        "perf_per_watt": 0.002985082239456262,
        "latency_per_watt": 323409.2618842492,
        "tokens_per_second": null,
        "tokens_per_watt": null
      },
      "config": {
        "suite_name": "reasoning",
        "benchmark_name": "hellaswag",
        "task_name": "HellaSwag",
        "concurrency": 1,
        "num_requests": 100,
        "duration_s": null,
        "host": "localhost",
        "port": 12345,
        "endpoint": "/generate/simple",
        "mode": "fast",
        "max_tokens": 256,
        "temperature": 0.7,
        "model_name": null,
        "model_variant": null,
        "quantization": null,
        "compression_techniques": null,
        "context_window": null,
        "run_id": "3ead04d4-89b1-4227-ab3f-81ac19167b2d"
      },
      "system_info": {
        "os_system": "Windows",
        "os_release": "10",
        "os_version": "10.0.26100",
        "hostname": "DESKTOP-0K2OI03",
        "python_version": "3.10.10",
        "python_implementation": "CPython",
        "cpu_name": "AMD64 Family 26 Model 68 Stepping 0, AuthenticAMD",
        "cpu_cores": 8,
        "cpu_threads": 16,
        "cpu_freq_mhz": 4700.0,
        "memory_total_gb": 31.15,
        "memory_available_gb": 19.11,
        "gpu_name": "NVIDIA GeForce RTX 5080",
        "gpu_count": 1,
        "gpu_memory_total_mb": 16303.0,
        "gpu_driver_version": "581.08",
        "cuda_version": "12.8",
        "maeum_version": "",
        "model_name": "",
        "model_variant": "",
        "quantization": ""
      },
      "model_info": {},
      "notes": {
        "status": "official_dataset",
        "benchmark_type": "hellaswag",
        "dataset": "Rowan/hellaswag"
      },
      "raw_latencies": []
    },
    {
      "benchmark_id": "hellaswag",
      "benchmark_name": "HellaSwag",
      "category": "reasoning",
      "mode": "quality",
      "timestamp": "20251202_150910",
      "duration_s": 171.6292667388916,
      "num_samples": 100,
      "success_count": 100,
      "error_count": 0,
      "latency": {
        "avg_ms": 1656.026687012054,
        "p50_ms": 1812.807900016196,
        "p90_ms": 2001.3303398620337,
        "p95_ms": 2007.0219079509843,
        "p99_ms": 2012.713476039935,
        "min_ms": 277.1312000695616,
        "max_ms": 2019.0668997820467,
        "std_ms": 0.0,
        "count": 100
      },
      "power": {
        "power_avg_w": 190.4695940594062,
        "power_max_w": 218.557,
        "power_min_w": null,
        "gpu_util_avg": 60.02904290429043,
        "gpu_util_max": null,
        "gpu_mem_avg_mb": null,
        "gpu_mem_peak_mb": 4997.9921875,
        "gpu_temp_avg_c": null,
        "gpu_temp_max_c": 59.0,
        "cpu_util_avg": 7.997227722772299,
        "cpu_util_max": null,
        "cpu_mem_avg_mb": null,
        "cpu_mem_peak_mb": 12747.54296875
      },
      "accuracy": {
        "accuracy": 0.71,
        "f1": 0.71,
        "em": 0.71,
        "precision": null,
        "recall": null,
        "extra": {
          "num_samples": 100,
          "dataset_status": "official_dataset",
          "dataset_name": "Rowan/hellaswag"
        }
      },
      "efficiency": {
        "perf_per_watt": 0.0030710279917829956,
        "latency_per_watt": 315422.73082672927,
        "tokens_per_second": null,
        "tokens_per_watt": null
      },
      "config": {
        "suite_name": "reasoning",
        "benchmark_name": "hellaswag",
        "task_name": "HellaSwag",
        "concurrency": 1,
        "num_requests": 100,
        "duration_s": null,
        "host": "localhost",
        "port": 12345,
        "endpoint": "/generate/simple",
        "mode": "quality",
        "max_tokens": 256,
        "temperature": 0.7,
        "model_name": null,
        "model_variant": null,
        "quantization": null,
        "compression_techniques": null,
        "context_window": null,
        "run_id": "3ee79f02-369c-4460-b66f-8ebf08298fd4"
      },
      "system_info": {
        "os_system": "Windows",
        "os_release": "10",
        "os_version": "10.0.26100",
        "hostname": "DESKTOP-0K2OI03",
        "python_version": "3.10.10",
        "python_implementation": "CPython",
        "cpu_name": "AMD64 Family 26 Model 68 Stepping 0, AuthenticAMD",
        "cpu_cores": 8,
        "cpu_threads": 16,
        "cpu_freq_mhz": 4700.0,
        "memory_total_gb": 31.15,
        "memory_available_gb": 19.11,
        "gpu_name": "NVIDIA GeForce RTX 5080",
        "gpu_count": 1,
        "gpu_memory_total_mb": 16303.0,
        "gpu_driver_version": "581.08",
        "cuda_version": "12.8",
        "maeum_version": "",
        "model_name": "",
        "model_variant": "",
        "quantization": ""
      },
      "model_info": {},
      "notes": {
        "status": "official_dataset",
        "benchmark_type": "hellaswag",
        "dataset": "Rowan/hellaswag"
      },
      "raw_latencies": []
    },
    {
      "benchmark_id": "arc_challenge",
      "benchmark_name": "ARC-Challenge",
      "category": "reasoning",
      "mode": "auto",
      "timestamp": "20251202_150910",
      "duration_s": 178.8394260406494,
      "num_samples": 100,
      "success_count": 100,
      "error_count": 0,
      "latency": {
        "avg_ms": 1712.1439810097218,
        "p50_ms": 1871.2622000603005,
        "p90_ms": 1948.9272399805486,
        "p95_ms": 1961.429501521634,
        "p99_ms": 1973.9317630627195,
        "min_ms": 946.1741999257356,
        "max_ms": 1998.7176998984069,
        "std_ms": 0.0,
        "count": 100
      },
      "power": {
        "power_avg_w": 189.1024939451885,
        "power_max_w": 217.332,
        "power_min_w": null,
        "gpu_util_avg": 58.52899936265137,
        "gpu_util_max": null,
        "gpu_mem_avg_mb": null,
        "gpu_mem_peak_mb": 4997.9921875,
        "gpu_temp_avg_c": null,
        "gpu_temp_max_c": 59.0,
        "cpu_util_avg": 7.991714467813907,
        "cpu_util_max": null,
        "cpu_mem_avg_mb": null,
        "cpu_mem_peak_mb": 12756.0234375
      },
      "accuracy": {
        "accuracy": 0.84,
        "f1": 0.84,
        "em": 0.84,
        "precision": null,
        "recall": null,
        "extra": {
          "num_samples": 100,
          "dataset_status": "official_dataset",
          "dataset_name": "allenai/ai2_arc"
        }
      },
      "efficiency": {
        "perf_per_watt": 0.0029669854915950747,
        "latency_per_watt": 323770.6968021819,
        "tokens_per_second": null,
        "tokens_per_watt": null
      },
      "config": {
        "suite_name": "reasoning",
        "benchmark_name": "arc_challenge",
        "task_name": "ARC-Challenge",
        "concurrency": 1,
        "num_requests": 100,
        "duration_s": null,
        "host": "localhost",
        "port": 12345,
        "endpoint": "/generate/simple",
        "mode": "auto",
        "max_tokens": 256,
        "temperature": 0.7,
        "model_name": null,
        "model_variant": null,
        "quantization": null,
        "compression_techniques": null,
        "context_window": null,
        "run_id": "c3b46187-d793-4f15-a2d8-1f8cb33b2170"
      },
      "system_info": {
        "os_system": "Windows",
        "os_release": "10",
        "os_version": "10.0.26100",
        "hostname": "DESKTOP-0K2OI03",
        "python_version": "3.10.10",
        "python_implementation": "CPython",
        "cpu_name": "AMD64 Family 26 Model 68 Stepping 0, AuthenticAMD",
        "cpu_cores": 8,
        "cpu_threads": 16,
        "cpu_freq_mhz": 4700.0,
        "memory_total_gb": 31.15,
        "memory_available_gb": 19.11,
        "gpu_name": "NVIDIA GeForce RTX 5080",
        "gpu_count": 1,
        "gpu_memory_total_mb": 16303.0,
        "gpu_driver_version": "581.08",
        "cuda_version": "12.8",
        "maeum_version": "",
        "model_name": "",
        "model_variant": "",
        "quantization": ""
      },
      "model_info": {},
      "notes": {
        "status": "official_dataset",
        "benchmark_type": "arc_challenge",
        "dataset": "allenai/ai2_arc"
      },
      "raw_latencies": []
    },
    {
      "benchmark_id": "arc_challenge",
      "benchmark_name": "ARC-Challenge",
      "category": "reasoning",
      "mode": "balanced",
      "timestamp": "20251202_150910",
      "duration_s": 177.65200424194336,
      "num_samples": 100,
      "success_count": 100,
      "error_count": 0,
      "latency": {
        "avg_ms": 1722.265201001428,
        "p50_ms": 1916.9074499513954,
        "p90_ms": 1944.8869000189006,
        "p95_ms": 1956.9836579810362,
        "p99_ms": 1969.080415943172,
        "min_ms": 831.2179001513869,
        "max_ms": 2020.7005999982357,
        "std_ms": 0.0,
        "count": 100
      },
      "power": {
        "power_avg_w": 189.5558997461929,
        "power_max_w": 215.516,
        "power_min_w": null,
        "gpu_util_avg": 62.1491116751269,
        "gpu_util_max": null,
        "gpu_mem_avg_mb": null,
        "gpu_mem_peak_mb": 4997.9921875,
        "gpu_temp_avg_c": null,
        "gpu_temp_max_c": 59.0,
        "cpu_util_avg": 8.037182741116776,
        "cpu_util_max": null,
        "cpu_mem_avg_mb": null,
        "cpu_mem_peak_mb": 12744.63671875
      },
      "accuracy": {
        "accuracy": 0.87,
        "f1": 0.87,
        "em": 0.87,
        "precision": null,
        "recall": null,
        "extra": {
          "num_samples": 100,
          "dataset_status": "official_dataset",
          "dataset_name": "allenai/ai2_arc"
        }
      },
      "efficiency": {
        "perf_per_watt": 0.0029801891240311207,
        "latency_per_watt": 326465.52977738343,
        "tokens_per_second": null,
        "tokens_per_watt": null
      },
      "config": {
        "suite_name": "reasoning",
        "benchmark_name": "arc_challenge",
        "task_name": "ARC-Challenge",
        "concurrency": 1,
        "num_requests": 100,
        "duration_s": null,
        "host": "localhost",
        "port": 12345,
        "endpoint": "/generate/simple",
        "mode": "balanced",
        "max_tokens": 256,
        "temperature": 0.7,
        "model_name": null,
        "model_variant": null,
        "quantization": null,
        "compression_techniques": null,
        "context_window": null,
        "run_id": "f0eb2048-b043-47fd-b56b-189ea58e873e"
      },
      "system_info": {
        "os_system": "Windows",
        "os_release": "10",
        "os_version": "10.0.26100",
        "hostname": "DESKTOP-0K2OI03",
        "python_version": "3.10.10",
        "python_implementation": "CPython",
        "cpu_name": "AMD64 Family 26 Model 68 Stepping 0, AuthenticAMD",
        "cpu_cores": 8,
        "cpu_threads": 16,
        "cpu_freq_mhz": 4700.0,
        "memory_total_gb": 31.15,
        "memory_available_gb": 19.11,
        "gpu_name": "NVIDIA GeForce RTX 5080",
        "gpu_count": 1,
        "gpu_memory_total_mb": 16303.0,
        "gpu_driver_version": "581.08",
        "cuda_version": "12.8",
        "maeum_version": "",
        "model_name": "",
        "model_variant": "",
        "quantization": ""
      },
      "model_info": {},
      "notes": {
        "status": "official_dataset",
        "benchmark_type": "arc_challenge",
        "dataset": "allenai/ai2_arc"
      },
      "raw_latencies": []
    },
    {
      "benchmark_id": "arc_challenge",
      "benchmark_name": "ARC-Challenge",
      "category": "reasoning",
      "mode": "fast",
      "timestamp": "20251202_150910",
      "duration_s": 185.270761013031,
      "num_samples": 100,
      "success_count": 100,
      "error_count": 0,
      "latency": {
        "avg_ms": 1798.8399670133367,
        "p50_ms": 1923.3118001138791,
        "p90_ms": 1949.1349898511544,
        "p95_ms": 1985.778438912239,
        "p99_ms": 2022.4218879733235,
        "min_ms": 713.7538001406938,
        "max_ms": 2028.1825000420213,
        "std_ms": 0.0,
        "count": 100
      },
      "power": {
        "power_avg_w": 189.3125652701875,
        "power_max_w": 215.844,
        "power_min_w": null,
        "gpu_util_avg": 61.44869459623558,
        "gpu_util_max": null,
        "gpu_mem_avg_mb": null,
        "gpu_mem_peak_mb": 4997.9921875,
        "gpu_temp_avg_c": null,
        "gpu_temp_max_c": 59.0,
        "cpu_util_avg": 8.03527625986643,
        "cpu_util_max": null,
        "cpu_mem_avg_mb": null,
        "cpu_mem_peak_mb": 12760.44140625
      },
      "accuracy": {
        "accuracy": 0.82,
        "f1": 0.82,
        "em": 0.82,
        "precision": null,
        "recall": null,
        "extra": {
          "num_samples": 100,
          "dataset_status": "official_dataset",
          "dataset_name": "allenai/ai2_arc"
        }
      },
      "efficiency": {
        "perf_per_watt": 0.00286110025067214,
        "latency_per_watt": 340543.0086658342,
        "tokens_per_second": null,
        "tokens_per_watt": null
      },
      "config": {
        "suite_name": "reasoning",
        "benchmark_name": "arc_challenge",
        "task_name": "ARC-Challenge",
        "concurrency": 1,
        "num_requests": 100,
        "duration_s": null,
        "host": "localhost",
        "port": 12345,
        "endpoint": "/generate/simple",
        "mode": "fast",
        "max_tokens": 256,
        "temperature": 0.7,
        "model_name": null,
        "model_variant": null,
        "quantization": null,
        "compression_techniques": null,
        "context_window": null,
        "run_id": "09cb6564-9343-4563-a804-d0a44d5f2912"
      },
      "system_info": {
        "os_system": "Windows",
        "os_release": "10",
        "os_version": "10.0.26100",
        "hostname": "DESKTOP-0K2OI03",
        "python_version": "3.10.10",
        "python_implementation": "CPython",
        "cpu_name": "AMD64 Family 26 Model 68 Stepping 0, AuthenticAMD",
        "cpu_cores": 8,
        "cpu_threads": 16,
        "cpu_freq_mhz": 4700.0,
        "memory_total_gb": 31.15,
        "memory_available_gb": 19.11,
        "gpu_name": "NVIDIA GeForce RTX 5080",
        "gpu_count": 1,
        "gpu_memory_total_mb": 16303.0,
        "gpu_driver_version": "581.08",
        "cuda_version": "12.8",
        "maeum_version": "",
        "model_name": "",
        "model_variant": "",
        "quantization": ""
      },
      "model_info": {},
      "notes": {
        "status": "official_dataset",
        "benchmark_type": "arc_challenge",
        "dataset": "allenai/ai2_arc"
      },
      "raw_latencies": []
    },
    {
      "benchmark_id": "arc_challenge",
      "benchmark_name": "ARC-Challenge",
      "category": "reasoning",
      "mode": "quality",
      "timestamp": "20251202_150910",
      "duration_s": 182.35864925384521,
      "num_samples": 100,
      "success_count": 100,
      "error_count": 0,
      "latency": {
        "avg_ms": 1770.293926994782,
        "p50_ms": 1916.5546499425545,
        "p90_ms": 1940.4721000697464,
        "p95_ms": 1949.7928550781216,
        "p99_ms": 1959.1136100864971,
        "min_ms": 949.0899001248181,
        "max_ms": 1981.7460000049323,
        "std_ms": 0.0,
        "count": 100
      },
      "power": {
        "power_avg_w": 188.85103824799444,
        "power_max_w": 214.66,
        "power_min_w": null,
        "gpu_util_avg": 57.080814312152995,
        "gpu_util_max": null,
        "gpu_mem_avg_mb": null,
        "gpu_mem_peak_mb": 4997.9921875,
        "gpu_temp_avg_c": null,
        "gpu_temp_max_c": 59.0,
        "cpu_util_avg": 8.006971005552153,
        "cpu_util_max": null,
        "cpu_mem_avg_mb": null,
        "cpu_mem_peak_mb": 12724.81640625
      },
      "accuracy": {
        "accuracy": 0.78,
        "f1": 0.78,
        "em": 0.78,
        "precision": null,
        "recall": null,
        "extra": {
          "num_samples": 100,
          "dataset_status": "official_dataset",
          "dataset_name": "allenai/ai2_arc"
        }
      },
      "efficiency": {
        "perf_per_watt": 0.0029131280342439285,
        "latency_per_watt": 334321.84611708386,
        "tokens_per_second": null,
        "tokens_per_watt": null
      },
      "config": {
        "suite_name": "reasoning",
        "benchmark_name": "arc_challenge",
        "task_name": "ARC-Challenge",
        "concurrency": 1,
        "num_requests": 100,
        "duration_s": null,
        "host": "localhost",
        "port": 12345,
        "endpoint": "/generate/simple",
        "mode": "quality",
        "max_tokens": 256,
        "temperature": 0.7,
        "model_name": null,
        "model_variant": null,
        "quantization": null,
        "compression_techniques": null,
        "context_window": null,
        "run_id": "70b99818-9326-4af7-8c1a-700700ce4a12"
      },
      "system_info": {
        "os_system": "Windows",
        "os_release": "10",
        "os_version": "10.0.26100",
        "hostname": "DESKTOP-0K2OI03",
        "python_version": "3.10.10",
        "python_implementation": "CPython",
        "cpu_name": "AMD64 Family 26 Model 68 Stepping 0, AuthenticAMD",
        "cpu_cores": 8,
        "cpu_threads": 16,
        "cpu_freq_mhz": 4700.0,
        "memory_total_gb": 31.15,
        "memory_available_gb": 19.11,
        "gpu_name": "NVIDIA GeForce RTX 5080",
        "gpu_count": 1,
        "gpu_memory_total_mb": 16303.0,
        "gpu_driver_version": "581.08",
        "cuda_version": "12.8",
        "maeum_version": "",
        "model_name": "",
        "model_variant": "",
        "quantization": ""
      },
      "model_info": {},
      "notes": {
        "status": "official_dataset",
        "benchmark_type": "arc_challenge",
        "dataset": "allenai/ai2_arc"
      },
      "raw_latencies": []
    },
    {
      "benchmark_id": "winogrande",
      "benchmark_name": "WinoGrande",
      "category": "reasoning",
      "mode": "auto",
      "timestamp": "20251202_150910",
      "duration_s": 178.84435486793518,
      "num_samples": 100,
      "success_count": 100,
      "error_count": 0,
      "latency": {
        "avg_ms": 1703.1627350021154,
        "p50_ms": 1909.992799977772,
        "p90_ms": 1931.1515800654888,
        "p95_ms": 1943.2003999850717,
        "p99_ms": 1955.2492199046544,
        "min_ms": 769.5170999504626,
        "max_ms": 2069.93280001916,
        "std_ms": 0.0,
        "count": 100
      },
      "power": {
        "power_avg_w": 187.33503651505367,
        "power_max_w": 213.534,
        "power_min_w": null,
        "gpu_util_avg": 56.12299807815503,
        "gpu_util_max": null,
        "gpu_mem_avg_mb": null,
        "gpu_mem_peak_mb": 4997.9921875,
        "gpu_temp_avg_c": null,
        "gpu_temp_max_c": 59.0,
        "cpu_util_avg": 7.926137091607963,
        "cpu_util_max": null,
        "cpu_mem_avg_mb": null,
        "cpu_mem_peak_mb": 12693.63671875
      },
      "accuracy": {
        "accuracy": 0.61,
        "f1": 0.61,
        "em": 0.61,
        "precision": null,
        "recall": null,
        "extra": {
          "num_samples": 100,
          "dataset_status": "official_dataset",
          "dataset_name": "allenai/winogrande"
        }
      },
      "efficiency": {
        "perf_per_watt": 0.0029955078530272856,
        "latency_per_watt": 319062.05315269995,
        "tokens_per_second": null,
        "tokens_per_watt": null
      },
      "config": {
        "suite_name": "reasoning",
        "benchmark_name": "winogrande",
        "task_name": "WinoGrande",
        "concurrency": 1,
        "num_requests": 100,
        "duration_s": null,
        "host": "localhost",
        "port": 12345,
        "endpoint": "/generate/simple",
        "mode": "auto",
        "max_tokens": 256,
        "temperature": 0.7,
        "model_name": null,
        "model_variant": null,
        "quantization": null,
        "compression_techniques": null,
        "context_window": null,
        "run_id": "285f6b41-cbf6-43ed-b28a-1b1a77508567"
      },
      "system_info": {
        "os_system": "Windows",
        "os_release": "10",
        "os_version": "10.0.26100",
        "hostname": "DESKTOP-0K2OI03",
        "python_version": "3.10.10",
        "python_implementation": "CPython",
        "cpu_name": "AMD64 Family 26 Model 68 Stepping 0, AuthenticAMD",
        "cpu_cores": 8,
        "cpu_threads": 16,
        "cpu_freq_mhz": 4700.0,
        "memory_total_gb": 31.15,
        "memory_available_gb": 19.11,
        "gpu_name": "NVIDIA GeForce RTX 5080",
        "gpu_count": 1,
        "gpu_memory_total_mb": 16303.0,
        "gpu_driver_version": "581.08",
        "cuda_version": "12.8",
        "maeum_version": "",
        "model_name": "",
        "model_variant": "",
        "quantization": ""
      },
      "model_info": {},
      "notes": {
        "status": "official_dataset",
        "benchmark_type": "winogrande",
        "dataset": "allenai/winogrande"
      },
      "raw_latencies": []
    },
    {
      "benchmark_id": "winogrande",
      "benchmark_name": "WinoGrande",
      "category": "reasoning",
      "mode": "balanced",
      "timestamp": "20251202_150910",
      "duration_s": 175.67144393920898,
      "num_samples": 99,
      "success_count": 99,
      "error_count": 0,
      "latency": {
        "avg_ms": 1702.1091020014137,
        "p50_ms": 1909.2203000327572,
        "p90_ms": 1933.4055399056524,
        "p95_ms": 1941.7064514488447,
        "p99_ms": 1950.007362992037,
        "min_ms": 768.4581000357866,
        "max_ms": 1953.2707000616938,
        "std_ms": 0.0,
        "count": 99
      },
      "power": {
        "power_avg_w": 187.10345862732504,
        "power_max_w": 213.011,
        "power_min_w": null,
        "gpu_util_avg": 57.86144964720975,
        "gpu_util_max": null,
        "gpu_mem_avg_mb": null,
        "gpu_mem_peak_mb": 4997.9921875,
        "gpu_temp_avg_c": null,
        "gpu_temp_max_c": 59.0,
        "cpu_util_avg": 8.121808851828096,
        "cpu_util_max": null,
        "cpu_mem_avg_mb": null,
        "cpu_mem_peak_mb": 12704.4609375
      },
      "accuracy": {
        "accuracy": 0.57,
        "f1": 0.57,
        "em": 0.57,
        "precision": null,
        "recall": null,
        "extra": {
          "num_samples": 100,
          "dataset_status": "official_dataset",
          "dataset_name": "allenai/winogrande"
        }
      },
      "efficiency": {
        "perf_per_watt": 0.003052319747102162,
        "latency_per_watt": 318470.4999455149,
        "tokens_per_second": null,
        "tokens_per_watt": null
      },
      "config": {
        "suite_name": "reasoning",
        "benchmark_name": "winogrande",
        "task_name": "WinoGrande",
        "concurrency": 1,
        "num_requests": 100,
        "duration_s": null,
        "host": "localhost",
        "port": 12345,
        "endpoint": "/generate/simple",
        "mode": "balanced",
        "max_tokens": 256,
        "temperature": 0.7,
        "model_name": null,
        "model_variant": null,
        "quantization": null,
        "compression_techniques": null,
        "context_window": null,
        "run_id": "a8c06481-2bd6-4dc8-82ae-1be32300214c"
      },
      "system_info": {
        "os_system": "Windows",
        "os_release": "10",
        "os_version": "10.0.26100",
        "hostname": "DESKTOP-0K2OI03",
        "python_version": "3.10.10",
        "python_implementation": "CPython",
        "cpu_name": "AMD64 Family 26 Model 68 Stepping 0, AuthenticAMD",
        "cpu_cores": 8,
        "cpu_threads": 16,
        "cpu_freq_mhz": 4700.0,
        "memory_total_gb": 31.15,
        "memory_available_gb": 19.11,
        "gpu_name": "NVIDIA GeForce RTX 5080",
        "gpu_count": 1,
        "gpu_memory_total_mb": 16303.0,
        "gpu_driver_version": "581.08",
        "cuda_version": "12.8",
        "maeum_version": "",
        "model_name": "",
        "model_variant": "",
        "quantization": ""
      },
      "model_info": {},
      "notes": {
        "status": "official_dataset",
        "benchmark_type": "winogrande",
        "dataset": "allenai/winogrande"
      },
      "raw_latencies": []
    },
    {
      "benchmark_id": "winogrande",
      "benchmark_name": "WinoGrande",
      "category": "reasoning",
      "mode": "fast",
      "timestamp": "20251202_150910",
      "duration_s": 175.21784162521362,
      "num_samples": 99,
      "success_count": 99,
      "error_count": 0,
      "latency": {
        "avg_ms": 1686.6658290009946,
        "p50_ms": 1907.9038499621674,
        "p90_ms": 1937.357270019129,
        "p95_ms": 1946.0717265470885,
        "p99_ms": 1954.786183075048,
        "min_ms": 339.93720007129014,
        "max_ms": 1960.8234998304397,
        "std_ms": 0.0,
        "count": 99
      },
      "power": {
        "power_avg_w": 186.94928562176142,
        "power_max_w": 213.369,
        "power_min_w": null,
        "gpu_util_avg": 57.89961139896373,
        "gpu_util_max": null,
        "gpu_mem_avg_mb": null,
        "gpu_mem_peak_mb": 4997.9921875,
        "gpu_temp_avg_c": null,
        "gpu_temp_max_c": 59.0,
        "cpu_util_avg": 8.008873056994846,
        "cpu_util_max": null,
        "cpu_mem_avg_mb": null,
        "cpu_mem_peak_mb": 12734.06640625
      },
      "accuracy": {
        "accuracy": 0.56,
        "f1": 0.56,
        "em": 0.56,
        "precision": null,
        "recall": null,
        "extra": {
          "num_samples": 100,
          "dataset_status": "official_dataset",
          "dataset_name": "allenai/winogrande"
        }
      },
      "efficiency": {
        "perf_per_watt": 0.003063832124962141,
        "latency_per_watt": 315320.97181437194,
        "tokens_per_second": null,
        "tokens_per_watt": null
      },
      "config": {
        "suite_name": "reasoning",
        "benchmark_name": "winogrande",
        "task_name": "WinoGrande",
        "concurrency": 1,
        "num_requests": 100,
        "duration_s": null,
        "host": "localhost",
        "port": 12345,
        "endpoint": "/generate/simple",
        "mode": "fast",
        "max_tokens": 256,
        "temperature": 0.7,
        "model_name": null,
        "model_variant": null,
        "quantization": null,
        "compression_techniques": null,
        "context_window": null,
        "run_id": "2fe24398-a835-43bd-b7e5-014094d01f67"
      },
      "system_info": {
        "os_system": "Windows",
        "os_release": "10",
        "os_version": "10.0.26100",
        "hostname": "DESKTOP-0K2OI03",
        "python_version": "3.10.10",
        "python_implementation": "CPython",
        "cpu_name": "AMD64 Family 26 Model 68 Stepping 0, AuthenticAMD",
        "cpu_cores": 8,
        "cpu_threads": 16,
        "cpu_freq_mhz": 4700.0,
        "memory_total_gb": 31.15,
        "memory_available_gb": 19.11,
        "gpu_name": "NVIDIA GeForce RTX 5080",
        "gpu_count": 1,
        "gpu_memory_total_mb": 16303.0,
        "gpu_driver_version": "581.08",
        "cuda_version": "12.8",
        "maeum_version": "",
        "model_name": "",
        "model_variant": "",
        "quantization": ""
      },
      "model_info": {},
      "notes": {
        "status": "official_dataset",
        "benchmark_type": "winogrande",
        "dataset": "allenai/winogrande"
      },
      "raw_latencies": []
    },
    {
      "benchmark_id": "winogrande",
      "benchmark_name": "WinoGrande",
      "category": "reasoning",
      "mode": "quality",
      "timestamp": "20251202_150910",
      "duration_s": 170.13319206237793,
      "num_samples": 100,
      "success_count": 100,
      "error_count": 0,
      "latency": {
        "avg_ms": 1645.9406109992415,
        "p50_ms": 1899.0743500180542,
        "p90_ms": 1929.9817000050098,
        "p95_ms": 1941.0358555417047,
        "p99_ms": 1952.0900110783994,
        "min_ms": 772.9344998952001,
        "max_ms": 2068.069600034505,
        "std_ms": 0.0,
        "count": 100
      },
      "power": {
        "power_avg_w": 186.10183466135447,
        "power_max_w": 212.991,
        "power_min_w": null,
        "gpu_util_avg": 57.93559096945551,
        "gpu_util_max": null,
        "gpu_mem_avg_mb": null,
        "gpu_mem_peak_mb": 4997.9921875,
        "gpu_temp_avg_c": null,
        "gpu_temp_max_c": 59.0,
        "cpu_util_avg": 7.980345285524572,
        "cpu_util_max": null,
        "cpu_mem_avg_mb": null,
        "cpu_mem_peak_mb": 12700.21484375
      },
      "accuracy": {
        "accuracy": 0.62,
        "f1": 0.62,
        "em": 0.62,
        "precision": null,
        "recall": null,
        "extra": {
          "num_samples": 100,
          "dataset_status": "official_dataset",
          "dataset_name": "allenai/winogrande"
        }
      },
      "efficiency": {
        "perf_per_watt": 0.0031691506797101756,
        "latency_per_watt": 306312.5674505896,
        "tokens_per_second": null,
        "tokens_per_watt": null
      },
      "config": {
        "suite_name": "reasoning",
        "benchmark_name": "winogrande",
        "task_name": "WinoGrande",
        "concurrency": 1,
        "num_requests": 100,
        "duration_s": null,
        "host": "localhost",
        "port": 12345,
        "endpoint": "/generate/simple",
        "mode": "quality",
        "max_tokens": 256,
        "temperature": 0.7,
        "model_name": null,
        "model_variant": null,
        "quantization": null,
        "compression_techniques": null,
        "context_window": null,
        "run_id": "2c1c5a62-dc78-457e-9d2e-49f92e650a79"
      },
      "system_info": {
        "os_system": "Windows",
        "os_release": "10",
        "os_version": "10.0.26100",
        "hostname": "DESKTOP-0K2OI03",
        "python_version": "3.10.10",
        "python_implementation": "CPython",
        "cpu_name": "AMD64 Family 26 Model 68 Stepping 0, AuthenticAMD",
        "cpu_cores": 8,
        "cpu_threads": 16,
        "cpu_freq_mhz": 4700.0,
        "memory_total_gb": 31.15,
        "memory_available_gb": 19.11,
        "gpu_name": "NVIDIA GeForce RTX 5080",
        "gpu_count": 1,
        "gpu_memory_total_mb": 16303.0,
        "gpu_driver_version": "581.08",
        "cuda_version": "12.8",
        "maeum_version": "",
        "model_name": "",
        "model_variant": "",
        "quantization": ""
      },
      "model_info": {},
      "notes": {
        "status": "official_dataset",
        "benchmark_type": "winogrande",
        "dataset": "allenai/winogrande"
      },
      "raw_latencies": []
    },
    {
      "benchmark_id": "truthfulqa",
      "benchmark_name": "TruthfulQA",
      "category": "truthfulness",
      "mode": "auto",
      "timestamp": "20251202_150910",
      "duration_s": 177.9486095905304,
      "num_samples": 100,
      "success_count": 100,
      "error_count": 0,
      "latency": {
        "avg_ms": 1691.1889560054988,
        "p50_ms": 1920.9451000206172,
        "p90_ms": 1952.0891500636935,
        "p95_ms": 1962.966660601087,
        "p99_ms": 1973.8441711384803,
        "min_ms": 331.3954998739064,
        "max_ms": 1979.880299884826,
        "std_ms": 0.0,
        "count": 100
      },
      "power": {
        "power_avg_w": 187.5943109677423,
        "power_max_w": 214.193,
        "power_min_w": null,
        "gpu_util_avg": 59.19741935483871,
        "gpu_util_max": null,
        "gpu_mem_avg_mb": null,
        "gpu_mem_peak_mb": 4997.9921875,
        "gpu_temp_avg_c": null,
        "gpu_temp_max_c": 59.0,
        "cpu_util_avg": 8.043354838709709,
        "cpu_util_max": null,
        "cpu_mem_avg_mb": null,
        "cpu_mem_peak_mb": 12788.98046875
      },
      "accuracy": {
        "accuracy": 0.68,
        "f1": 0.68,
        "em": 0.68,
        "precision": null,
        "recall": null,
        "extra": {
          "num_samples": 100,
          "dataset_status": "official_dataset",
          "dataset_name": "truthful_qa"
        }
      },
      "efficiency": {
        "perf_per_watt": 0.003005425511864926,
        "latency_per_watt": 317257.42691810697,
        "tokens_per_second": null,
        "tokens_per_watt": null
      },
      "config": {
        "suite_name": "truthfulness",
        "benchmark_name": "truthfulqa",
        "task_name": "TruthfulQA",
        "concurrency": 1,
        "num_requests": 100,
        "duration_s": null,
        "host": "localhost",
        "port": 12345,
        "endpoint": "/generate/simple",
        "mode": "auto",
        "max_tokens": 256,
        "temperature": 0.7,
        "model_name": null,
        "model_variant": null,
        "quantization": null,
        "compression_techniques": null,
        "context_window": null,
        "run_id": "4ee47e57-6221-46d1-a2d2-947012afc420"
      },
      "system_info": {
        "os_system": "Windows",
        "os_release": "10",
        "os_version": "10.0.26100",
        "hostname": "DESKTOP-0K2OI03",
        "python_version": "3.10.10",
        "python_implementation": "CPython",
        "cpu_name": "AMD64 Family 26 Model 68 Stepping 0, AuthenticAMD",
        "cpu_cores": 8,
        "cpu_threads": 16,
        "cpu_freq_mhz": 4700.0,
        "memory_total_gb": 31.15,
        "memory_available_gb": 19.11,
        "gpu_name": "NVIDIA GeForce RTX 5080",
        "gpu_count": 1,
        "gpu_memory_total_mb": 16303.0,
        "gpu_driver_version": "581.08",
        "cuda_version": "12.8",
        "maeum_version": "",
        "model_name": "",
        "model_variant": "",
        "quantization": ""
      },
      "model_info": {},
      "notes": {
        "status": "official_dataset",
        "benchmark_type": "truthfulqa",
        "dataset": "truthful_qa"
      },
      "raw_latencies": []
    },
    {
      "benchmark_id": "truthfulqa",
      "benchmark_name": "TruthfulQA",
      "category": "truthfulness",
      "mode": "balanced",
      "timestamp": "20251202_150910",
      "duration_s": 175.28698754310608,
      "num_samples": 99,
      "success_count": 99,
      "error_count": 0,
      "latency": {
        "avg_ms": 1702.2028140025213,
        "p50_ms": 1918.4880501125008,
        "p90_ms": 1957.5387900462374,
        "p95_ms": 1977.9881290695635,
        "p99_ms": 1998.4374680928893,
        "min_ms": 264.0847999136895,
        "max_ms": 2117.9965999908745,
        "std_ms": 0.0,
        "count": 99
      },
      "power": {
        "power_avg_w": 187.50275528507376,
        "power_max_w": 214.317,
        "power_min_w": null,
        "gpu_util_avg": 59.631005765534915,
        "gpu_util_max": null,
        "gpu_mem_avg_mb": null,
        "gpu_mem_peak_mb": 4997.9921875,
        "gpu_temp_avg_c": null,
        "gpu_temp_max_c": 59.0,
        "cpu_util_avg": 7.874823830877675,
        "cpu_util_max": null,
        "cpu_mem_avg_mb": null,
        "cpu_mem_peak_mb": 12723.84765625
      },
      "accuracy": {
        "accuracy": 0.62,
        "f1": 0.62,
        "em": 0.62,
        "precision": null,
        "recall": null,
        "extra": {
          "num_samples": 100,
          "dataset_status": "official_dataset",
          "dataset_name": "truthful_qa"
        }
      },
      "efficiency": {
        "perf_per_watt": 0.0030533019041483886,
        "latency_per_watt": 319167.7176794787,
        "tokens_per_second": null,
        "tokens_per_watt": null
      },
      "config": {
        "suite_name": "truthfulness",
        "benchmark_name": "truthfulqa",
        "task_name": "TruthfulQA",
        "concurrency": 1,
        "num_requests": 100,
        "duration_s": null,
        "host": "localhost",
        "port": 12345,
        "endpoint": "/generate/simple",
        "mode": "balanced",
        "max_tokens": 256,
        "temperature": 0.7,
        "model_name": null,
        "model_variant": null,
        "quantization": null,
        "compression_techniques": null,
        "context_window": null,
        "run_id": "cc20d3d5-28b2-4627-b8c9-ea3b9a1c5665"
      },
      "system_info": {
        "os_system": "Windows",
        "os_release": "10",
        "os_version": "10.0.26100",
        "hostname": "DESKTOP-0K2OI03",
        "python_version": "3.10.10",
        "python_implementation": "CPython",
        "cpu_name": "AMD64 Family 26 Model 68 Stepping 0, AuthenticAMD",
        "cpu_cores": 8,
        "cpu_threads": 16,
        "cpu_freq_mhz": 4700.0,
        "memory_total_gb": 31.15,
        "memory_available_gb": 19.11,
        "gpu_name": "NVIDIA GeForce RTX 5080",
        "gpu_count": 1,
        "gpu_memory_total_mb": 16303.0,
        "gpu_driver_version": "581.08",
        "cuda_version": "12.8",
        "maeum_version": "",
        "model_name": "",
        "model_variant": "",
        "quantization": ""
      },
      "model_info": {},
      "notes": {
        "status": "official_dataset",
        "benchmark_type": "truthfulqa",
        "dataset": "truthful_qa"
      },
      "raw_latencies": []
    },
    {
      "benchmark_id": "truthfulqa",
      "benchmark_name": "TruthfulQA",
      "category": "truthfulness",
      "mode": "fast",
      "timestamp": "20251202_150910",
      "duration_s": 174.67119240760803,
      "num_samples": 100,
      "success_count": 100,
      "error_count": 0,
      "latency": {
        "avg_ms": 1695.3334610001184,
        "p50_ms": 1915.7772499602288,
        "p90_ms": 1949.3873099796474,
        "p95_ms": 1965.3871425252878,
        "p99_ms": 1981.386975070928,
        "min_ms": 297.3374000284821,
        "max_ms": 2129.6270999591798,
        "std_ms": 0.0,
        "count": 100
      },
      "power": {
        "power_avg_w": 187.69314101738576,
        "power_max_w": 214.339,
        "power_min_w": null,
        "gpu_util_avg": 61.11719253058596,
        "gpu_util_max": null,
        "gpu_mem_avg_mb": null,
        "gpu_mem_peak_mb": 4997.9921875,
        "gpu_temp_avg_c": null,
        "gpu_temp_max_c": 59.0,
        "cpu_util_avg": 7.838441725692212,
        "cpu_util_max": null,
        "cpu_mem_avg_mb": null,
        "cpu_mem_peak_mb": 12716.46875
      },
      "accuracy": {
        "accuracy": 0.63,
        "f1": 0.63,
        "em": 0.63,
        "precision": null,
        "recall": null,
        "extra": {
          "num_samples": 100,
          "dataset_status": "official_dataset",
          "dataset_name": "truthful_qa"
        }
      },
      "efficiency": {
        "perf_per_watt": 0.00306050433602585,
        "latency_per_watt": 318202.4623669879,
        "tokens_per_second": null,
        "tokens_per_watt": null
      },
      "config": {
        "suite_name": "truthfulness",
        "benchmark_name": "truthfulqa",
        "task_name": "TruthfulQA",
        "concurrency": 1,
        "num_requests": 100,
        "duration_s": null,
        "host": "localhost",
        "port": 12345,
        "endpoint": "/generate/simple",
        "mode": "fast",
        "max_tokens": 256,
        "temperature": 0.7,
        "model_name": null,
        "model_variant": null,
        "quantization": null,
        "compression_techniques": null,
        "context_window": null,
        "run_id": "c1449e98-5a70-47ec-82af-c49f4937881d"
      },
      "system_info": {
        "os_system": "Windows",
        "os_release": "10",
        "os_version": "10.0.26100",
        "hostname": "DESKTOP-0K2OI03",
        "python_version": "3.10.10",
        "python_implementation": "CPython",
        "cpu_name": "AMD64 Family 26 Model 68 Stepping 0, AuthenticAMD",
        "cpu_cores": 8,
        "cpu_threads": 16,
        "cpu_freq_mhz": 4700.0,
        "memory_total_gb": 31.15,
        "memory_available_gb": 19.11,
        "gpu_name": "NVIDIA GeForce RTX 5080",
        "gpu_count": 1,
        "gpu_memory_total_mb": 16303.0,
        "gpu_driver_version": "581.08",
        "cuda_version": "12.8",
        "maeum_version": "",
        "model_name": "",
        "model_variant": "",
        "quantization": ""
      },
      "model_info": {},
      "notes": {
        "status": "official_dataset",
        "benchmark_type": "truthfulqa",
        "dataset": "truthful_qa"
      },
      "raw_latencies": []
    },
    {
      "benchmark_id": "truthfulqa",
      "benchmark_name": "TruthfulQA",
      "category": "truthfulness",
      "mode": "quality",
      "timestamp": "20251202_150910",
      "duration_s": 172.95737290382385,
      "num_samples": 100,
      "success_count": 100,
      "error_count": 0,
      "latency": {
        "avg_ms": 1667.4641399946995,
        "p50_ms": 1899.857849930413,
        "p90_ms": 1952.7170799905434,
        "p95_ms": 1968.294007441728,
        "p99_ms": 1983.8709348929124,
        "min_ms": 288.43830013647676,
        "max_ms": 2174.5385001413524,
        "std_ms": 0.0,
        "count": 100
      },
      "power": {
        "power_avg_w": 186.61236607727545,
        "power_max_w": 214.662,
        "power_min_w": null,
        "gpu_util_avg": 61.37066142763589,
        "gpu_util_max": null,
        "gpu_mem_avg_mb": null,
        "gpu_mem_peak_mb": 4997.9921875,
        "gpu_temp_avg_c": null,
        "gpu_temp_max_c": 59.0,
        "cpu_util_avg": 7.913948919449915,
        "cpu_util_max": null,
        "cpu_mem_avg_mb": null,
        "cpu_mem_peak_mb": 12716.83984375
      },
      "accuracy": {
        "accuracy": 0.8,
        "f1": 0.8,
        "em": 0.8,
        "precision": null,
        "recall": null,
        "extra": {
          "num_samples": 100,
          "dataset_status": "official_dataset",
          "dataset_name": "truthful_qa"
        }
      },
      "efficiency": {
        "perf_per_watt": 0.0031088319127772716,
        "latency_per_watt": 311169.42851342016,
        "tokens_per_second": null,
        "tokens_per_watt": null
      },
      "config": {
        "suite_name": "truthfulness",
        "benchmark_name": "truthfulqa",
        "task_name": "TruthfulQA",
        "concurrency": 1,
        "num_requests": 100,
        "duration_s": null,
        "host": "localhost",
        "port": 12345,
        "endpoint": "/generate/simple",
        "mode": "quality",
        "max_tokens": 256,
        "temperature": 0.7,
        "model_name": null,
        "model_variant": null,
        "quantization": null,
        "compression_techniques": null,
        "context_window": null,
        "run_id": "8db42c23-0332-4f90-a114-4b0953b4f32a"
      },
      "system_info": {
        "os_system": "Windows",
        "os_release": "10",
        "os_version": "10.0.26100",
        "hostname": "DESKTOP-0K2OI03",
        "python_version": "3.10.10",
        "python_implementation": "CPython",
        "cpu_name": "AMD64 Family 26 Model 68 Stepping 0, AuthenticAMD",
        "cpu_cores": 8,
        "cpu_threads": 16,
        "cpu_freq_mhz": 4700.0,
        "memory_total_gb": 31.15,
        "memory_available_gb": 19.11,
        "gpu_name": "NVIDIA GeForce RTX 5080",
        "gpu_count": 1,
        "gpu_memory_total_mb": 16303.0,
        "gpu_driver_version": "581.08",
        "cuda_version": "12.8",
        "maeum_version": "",
        "model_name": "",
        "model_variant": "",
        "quantization": ""
      },
      "model_info": {},
      "notes": {
        "status": "official_dataset",
        "benchmark_type": "truthfulqa",
        "dataset": "truthful_qa"
      },
      "raw_latencies": []
    },
    {
      "benchmark_id": "gsm8k",
      "benchmark_name": "GSM8K",
      "category": "math",
      "mode": "auto",
      "timestamp": "20251202_150910",
      "duration_s": 163.01849126815796,
      "num_samples": 100,
      "success_count": 100,
      "error_count": 0,
      "latency": {
        "avg_ms": 1565.9513719961978,
        "p50_ms": 1659.3428999185562,
        "p90_ms": 1946.5101100038737,
        "p95_ms": 1956.8836270482284,
        "p99_ms": 1967.2571440925833,
        "min_ms": 245.97889999859035,
        "max_ms": 2181.507400004193,
        "std_ms": 0.0,
        "count": 100
      },
      "power": {
        "power_avg_w": 185.7250062761509,
        "power_max_w": 214.789,
        "power_min_w": null,
        "gpu_util_avg": 58.47907949790795,
        "gpu_util_max": null,
        "gpu_mem_avg_mb": null,
        "gpu_mem_peak_mb": 4997.9921875,
        "gpu_temp_avg_c": null,
        "gpu_temp_max_c": 59.0,
        "cpu_util_avg": 7.894490934449093,
        "cpu_util_max": null,
        "cpu_mem_avg_mb": null,
        "cpu_mem_peak_mb": 12732.26171875
      },
      "accuracy": {
        "accuracy": 0.6,
        "f1": 0.6,
        "em": 0.6,
        "precision": null,
        "recall": null,
        "extra": {
          "num_samples": 100,
          "dataset_status": "official_dataset",
          "dataset_name": "openai/gsm8k"
        }
      },
      "efficiency": {
        "perf_per_watt": 0.0033140383685454013,
        "latency_per_watt": 290836.328392141,
        "tokens_per_second": null,
        "tokens_per_watt": null
      },
      "config": {
        "suite_name": "math",
        "benchmark_name": "gsm8k",
        "task_name": "GSM8K",
        "concurrency": 1,
        "num_requests": 100,
        "duration_s": null,
        "host": "localhost",
        "port": 12345,
        "endpoint": "/generate/simple",
        "mode": "auto",
        "max_tokens": 256,
        "temperature": 0.7,
        "model_name": null,
        "model_variant": null,
        "quantization": null,
        "compression_techniques": null,
        "context_window": null,
        "run_id": "9e60d01c-8a71-4322-a1e6-3300cbc1309f"
      },
      "system_info": {
        "os_system": "Windows",
        "os_release": "10",
        "os_version": "10.0.26100",
        "hostname": "DESKTOP-0K2OI03",
        "python_version": "3.10.10",
        "python_implementation": "CPython",
        "cpu_name": "AMD64 Family 26 Model 68 Stepping 0, AuthenticAMD",
        "cpu_cores": 8,
        "cpu_threads": 16,
        "cpu_freq_mhz": 4700.0,
        "memory_total_gb": 31.15,
        "memory_available_gb": 19.11,
        "gpu_name": "NVIDIA GeForce RTX 5080",
        "gpu_count": 1,
        "gpu_memory_total_mb": 16303.0,
        "gpu_driver_version": "581.08",
        "cuda_version": "12.8",
        "maeum_version": "",
        "model_name": "",
        "model_variant": "",
        "quantization": ""
      },
      "model_info": {},
      "notes": {
        "status": "official_dataset",
        "benchmark_type": "gsm8k",
        "dataset": "openai/gsm8k"
      },
      "raw_latencies": []
    },
    {
      "benchmark_id": "gsm8k",
      "benchmark_name": "GSM8K",
      "category": "math",
      "mode": "balanced",
      "timestamp": "20251202_150910",
      "duration_s": 166.3981854915619,
      "num_samples": 99,
      "success_count": 99,
      "error_count": 0,
      "latency": {
        "avg_ms": 1618.0828429874964,
        "p50_ms": 1847.8243000572547,
        "p90_ms": 1942.217630147934,
        "p95_ms": 1953.2421505462846,
        "p99_ms": 1964.2666709446353,
        "min_ms": 273.59270001761615,
        "max_ms": 2055.442800046876,
        "std_ms": 0.0,
        "count": 99
      },
      "power": {
        "power_avg_w": 186.94633625336854,
        "power_max_w": 214.619,
        "power_min_w": null,
        "gpu_util_avg": 59.475067385444746,
        "gpu_util_max": null,
        "gpu_mem_avg_mb": null,
        "gpu_mem_peak_mb": 4997.9921875,
        "gpu_temp_avg_c": null,
        "gpu_temp_max_c": 59.0,
        "cpu_util_avg": 8.059568733153643,
        "cpu_util_max": null,
        "cpu_mem_avg_mb": null,
        "cpu_mem_peak_mb": 12753.30859375
      },
      "accuracy": {
        "accuracy": 0.57,
        "f1": 0.57,
        "em": 0.57,
        "precision": null,
        "recall": null,
        "extra": {
          "num_samples": 100,
          "dataset_status": "official_dataset",
          "dataset_name": "openai/gsm8k"
        }
      },
      "efficiency": {
        "perf_per_watt": 0.003225944307733933,
        "latency_per_watt": 302494.65925094706,
        "tokens_per_second": null,
        "tokens_per_watt": null
      },
      "config": {
        "suite_name": "math",
        "benchmark_name": "gsm8k",
        "task_name": "GSM8K",
        "concurrency": 1,
        "num_requests": 100,
        "duration_s": null,
        "host": "localhost",
        "port": 12345,
        "endpoint": "/generate/simple",
        "mode": "balanced",
        "max_tokens": 256,
        "temperature": 0.7,
        "model_name": null,
        "model_variant": null,
        "quantization": null,
        "compression_techniques": null,
        "context_window": null,
        "run_id": "575a6fc3-3a13-4d28-a85d-d9923d4f224f"
      },
      "system_info": {
        "os_system": "Windows",
        "os_release": "10",
        "os_version": "10.0.26100",
        "hostname": "DESKTOP-0K2OI03",
        "python_version": "3.10.10",
        "python_implementation": "CPython",
        "cpu_name": "AMD64 Family 26 Model 68 Stepping 0, AuthenticAMD",
        "cpu_cores": 8,
        "cpu_threads": 16,
        "cpu_freq_mhz": 4700.0,
        "memory_total_gb": 31.15,
        "memory_available_gb": 19.11,
        "gpu_name": "NVIDIA GeForce RTX 5080",
        "gpu_count": 1,
        "gpu_memory_total_mb": 16303.0,
        "gpu_driver_version": "581.08",
        "cuda_version": "12.8",
        "maeum_version": "",
        "model_name": "",
        "model_variant": "",
        "quantization": ""
      },
      "model_info": {},
      "notes": {
        "status": "official_dataset",
        "benchmark_type": "gsm8k",
        "dataset": "openai/gsm8k"
      },
      "raw_latencies": []
    },
    {
      "benchmark_id": "gsm8k",
      "benchmark_name": "GSM8K",
      "category": "math",
      "mode": "fast",
      "timestamp": "20251202_150910",
      "duration_s": 161.97391080856323,
      "num_samples": 100,
      "success_count": 100,
      "error_count": 0,
      "latency": {
        "avg_ms": 1576.8925930233672,
        "p50_ms": 1752.1457500988618,
        "p90_ms": 1932.0434799185023,
        "p95_ms": 1945.453235504683,
        "p99_ms": 1958.8629910908642,
        "min_ms": 270.10570000857115,
        "max_ms": 2017.1731000300497,
        "std_ms": 0.0,
        "count": 100
      },
      "power": {
        "power_avg_w": 185.94331484049962,
        "power_max_w": 213.759,
        "power_min_w": null,
        "gpu_util_avg": 57.262829403606105,
        "gpu_util_max": null,
        "gpu_mem_avg_mb": null,
        "gpu_mem_peak_mb": 4997.9921875,
        "gpu_temp_avg_c": null,
        "gpu_temp_max_c": 58.0,
        "cpu_util_avg": 7.84257975034676,
        "cpu_util_max": null,
        "cpu_mem_avg_mb": null,
        "cpu_mem_peak_mb": 12737.1328125
      },
      "accuracy": {
        "accuracy": 0.58,
        "f1": 0.58,
        "em": 0.58,
        "precision": null,
        "recall": null,
        "extra": {
          "num_samples": 100,
          "dataset_status": "official_dataset",
          "dataset_name": "openai/gsm8k"
        }
      },
      "efficiency": {
        "perf_per_watt": 0.003332815138863492,
        "latency_per_watt": 293212.6358941958,
        "tokens_per_second": null,
        "tokens_per_watt": null
      },
      "config": {
        "suite_name": "math",
        "benchmark_name": "gsm8k",
        "task_name": "GSM8K",
        "concurrency": 1,
        "num_requests": 100,
        "duration_s": null,
        "host": "localhost",
        "port": 12345,
        "endpoint": "/generate/simple",
        "mode": "fast",
        "max_tokens": 256,
        "temperature": 0.7,
        "model_name": null,
        "model_variant": null,
        "quantization": null,
        "compression_techniques": null,
        "context_window": null,
        "run_id": "387512eb-3ce1-43ab-a1a6-834de1d665eb"
      },
      "system_info": {
        "os_system": "Windows",
        "os_release": "10",
        "os_version": "10.0.26100",
        "hostname": "DESKTOP-0K2OI03",
        "python_version": "3.10.10",
        "python_implementation": "CPython",
        "cpu_name": "AMD64 Family 26 Model 68 Stepping 0, AuthenticAMD",
        "cpu_cores": 8,
        "cpu_threads": 16,
        "cpu_freq_mhz": 4700.0,
        "memory_total_gb": 31.15,
        "memory_available_gb": 19.11,
        "gpu_name": "NVIDIA GeForce RTX 5080",
        "gpu_count": 1,
        "gpu_memory_total_mb": 16303.0,
        "gpu_driver_version": "581.08",
        "cuda_version": "12.8",
        "maeum_version": "",
        "model_name": "",
        "model_variant": "",
        "quantization": ""
      },
      "model_info": {},
      "notes": {
        "status": "official_dataset",
        "benchmark_type": "gsm8k",
        "dataset": "openai/gsm8k"
      },
      "raw_latencies": []
    },
    {
      "benchmark_id": "gsm8k",
      "benchmark_name": "GSM8K",
      "category": "math",
      "mode": "quality",
      "timestamp": "20251202_150910",
      "duration_s": 156.16909456253052,
      "num_samples": 100,
      "success_count": 100,
      "error_count": 0,
      "latency": {
        "avg_ms": 1518.0682250089012,
        "p50_ms": 1613.9464500593022,
        "p90_ms": 1938.3308500051498,
        "p95_ms": 1945.9366929973476,
        "p99_ms": 1953.5425359895453,
        "min_ms": 247.60979996062815,
        "max_ms": 1969.2672998644412,
        "std_ms": 0.0,
        "count": 100
      },
      "power": {
        "power_avg_w": 184.84139583333408,
        "power_max_w": 214.374,
        "power_min_w": null,
        "gpu_util_avg": 59.58620689655172,
        "gpu_util_max": null,
        "gpu_mem_avg_mb": null,
        "gpu_mem_peak_mb": 4997.9921875,
        "gpu_temp_avg_c": null,
        "gpu_temp_max_c": 58.0,
        "cpu_util_avg": 7.804238505747139,
        "cpu_util_max": null,
        "cpu_mem_avg_mb": null,
        "cpu_mem_peak_mb": 12728.21875
      },
      "accuracy": {
        "accuracy": 0.75,
        "f1": 0.75,
        "em": 0.75,
        "precision": null,
        "recall": null,
        "extra": {
          "num_samples": 100,
          "dataset_status": "official_dataset",
          "dataset_name": "openai/gsm8k"
        }
      },
      "efficiency": {
        "perf_per_watt": 0.003479045642003799,
        "latency_per_watt": 280601.8496808772,
        "tokens_per_second": null,
        "tokens_per_watt": null
      },
      "config": {
        "suite_name": "math",
        "benchmark_name": "gsm8k",
        "task_name": "GSM8K",
        "concurrency": 1,
        "num_requests": 100,
        "duration_s": null,
        "host": "localhost",
        "port": 12345,
        "endpoint": "/generate/simple",
        "mode": "quality",
        "max_tokens": 256,
        "temperature": 0.7,
        "model_name": null,
        "model_variant": null,
        "quantization": null,
        "compression_techniques": null,
        "context_window": null,
        "run_id": "6c563c2f-3ffb-429d-872b-6b707ec04498"
      },
      "system_info": {
        "os_system": "Windows",
        "os_release": "10",
        "os_version": "10.0.26100",
        "hostname": "DESKTOP-0K2OI03",
        "python_version": "3.10.10",
        "python_implementation": "CPython",
        "cpu_name": "AMD64 Family 26 Model 68 Stepping 0, AuthenticAMD",
        "cpu_cores": 8,
        "cpu_threads": 16,
        "cpu_freq_mhz": 4700.0,
        "memory_total_gb": 31.15,
        "memory_available_gb": 19.11,
        "gpu_name": "NVIDIA GeForce RTX 5080",
        "gpu_count": 1,
        "gpu_memory_total_mb": 16303.0,
        "gpu_driver_version": "581.08",
        "cuda_version": "12.8",
        "maeum_version": "",
        "model_name": "",
        "model_variant": "",
        "quantization": ""
      },
      "model_info": {},
      "notes": {
        "status": "official_dataset",
        "benchmark_type": "gsm8k",
        "dataset": "openai/gsm8k"
      },
      "raw_latencies": []
    },
    {
      "benchmark_id": "math",
      "benchmark_name": "MATH",
      "category": "math",
      "mode": "auto",
      "timestamp": "20251202_150910",
      "duration_s": 92.15934872627258,
      "num_samples": 50,
      "success_count": 50,
      "error_count": 0,
      "latency": {
        "avg_ms": 1826.0763100069016,
        "p50_ms": 1894.1926499828696,
        "p90_ms": 1916.515729879029,
        "p95_ms": 1922.6337964646518,
        "p99_ms": 1928.7518630502746,
        "min_ms": 1097.2484000958502,
        "max_ms": 1930.893799988553,
        "std_ms": 0.0,
        "count": 50
      },
      "power": {
        "power_avg_w": 189.32011976047878,
        "power_max_w": 213.639,
        "power_min_w": null,
        "gpu_util_avg": 61.12814371257485,
        "gpu_util_max": null,
        "gpu_mem_avg_mb": null,
        "gpu_mem_peak_mb": 4997.9921875,
        "gpu_temp_avg_c": null,
        "gpu_temp_max_c": 58.0,
        "cpu_util_avg": 8.108982035928154,
        "cpu_util_max": null,
        "cpu_mem_avg_mb": null,
        "cpu_mem_peak_mb": 12718.03515625
      },
      "accuracy": {
        "accuracy": 0.5,
        "f1": 0.059608947953618575,
        "em": 0.5,
        "precision": null,
        "recall": null,
        "extra": {
          "num_samples": 50,
          "dataset_status": "builtin_samples",
          "dataset_name": "lighteval/MATH"
        }
      },
      "efficiency": {
        "perf_per_watt": 0.0028852351988256086,
        "latency_per_watt": 345712.9857022798,
        "tokens_per_second": null,
        "tokens_per_watt": null
      },
      "config": {
        "suite_name": "math",
        "benchmark_name": "math",
        "task_name": "MATH",
        "concurrency": 1,
        "num_requests": 50,
        "duration_s": null,
        "host": "localhost",
        "port": 12345,
        "endpoint": "/generate/simple",
        "mode": "auto",
        "max_tokens": 256,
        "temperature": 0.7,
        "model_name": null,
        "model_variant": null,
        "quantization": null,
        "compression_techniques": null,
        "context_window": null,
        "run_id": "b41d3305-1abf-4757-bbcb-e044f56388e3"
      },
      "system_info": {
        "os_system": "Windows",
        "os_release": "10",
        "os_version": "10.0.26100",
        "hostname": "DESKTOP-0K2OI03",
        "python_version": "3.10.10",
        "python_implementation": "CPython",
        "cpu_name": "AMD64 Family 26 Model 68 Stepping 0, AuthenticAMD",
        "cpu_cores": 8,
        "cpu_threads": 16,
        "cpu_freq_mhz": 4700.0,
        "memory_total_gb": 31.15,
        "memory_available_gb": 19.11,
        "gpu_name": "NVIDIA GeForce RTX 5080",
        "gpu_count": 1,
        "gpu_memory_total_mb": 16303.0,
        "gpu_driver_version": "581.08",
        "cuda_version": "12.8",
        "maeum_version": "",
        "model_name": "",
        "model_variant": "",
        "quantization": ""
      },
      "model_info": {},
      "notes": {
        "status": "builtin_samples",
        "benchmark_type": "math",
        "dataset": "lighteval/MATH"
      },
      "raw_latencies": []
    },
    {
      "benchmark_id": "math",
      "benchmark_name": "MATH",
      "category": "math",
      "mode": "balanced",
      "timestamp": "20251202_150910",
      "duration_s": 91.72615218162537,
      "num_samples": 50,
      "success_count": 50,
      "error_count": 0,
      "latency": {
        "avg_ms": 1817.8376500075683,
        "p50_ms": 1888.029900030233,
        "p90_ms": 1908.6954801576212,
        "p95_ms": 1915.2744915743824,
        "p99_ms": 1921.8535029911436,
        "min_ms": 1154.7094001434743,
        "max_ms": 1923.463299870491,
        "std_ms": 0.0,
        "count": 50
      },
      "power": {
        "power_avg_w": 189.99113221153814,
        "power_max_w": 213.583,
        "power_min_w": null,
        "gpu_util_avg": 59.95793269230769,
        "gpu_util_max": null,
        "gpu_mem_avg_mb": null,
        "gpu_mem_peak_mb": 4997.9921875,
        "gpu_temp_avg_c": null,
        "gpu_temp_max_c": 58.0,
        "cpu_util_avg": 7.919110576923081,
        "cpu_util_max": null,
        "cpu_mem_avg_mb": null,
        "cpu_mem_peak_mb": 12719.63671875
      },
      "accuracy": {
        "accuracy": 0.48,
        "f1": 0.05886667545812199,
        "em": 0.48,
        "precision": null,
        "recall": null,
        "extra": {
          "num_samples": 50,
          "dataset_status": "builtin_samples",
          "dataset_name": "lighteval/MATH"
        }
      },
      "efficiency": {
        "perf_per_watt": 0.0028884170948914505,
        "latency_per_watt": 345373.03330169973,
        "tokens_per_second": null,
        "tokens_per_watt": null
      },
      "config": {
        "suite_name": "math",
        "benchmark_name": "math",
        "task_name": "MATH",
        "concurrency": 1,
        "num_requests": 50,
        "duration_s": null,
        "host": "localhost",
        "port": 12345,
        "endpoint": "/generate/simple",
        "mode": "balanced",
        "max_tokens": 256,
        "temperature": 0.7,
        "model_name": null,
        "model_variant": null,
        "quantization": null,
        "compression_techniques": null,
        "context_window": null,
        "run_id": "f4707a26-3c5b-44c1-9e44-aa7cc38fb5ce"
      },
      "system_info": {
        "os_system": "Windows",
        "os_release": "10",
        "os_version": "10.0.26100",
        "hostname": "DESKTOP-0K2OI03",
        "python_version": "3.10.10",
        "python_implementation": "CPython",
        "cpu_name": "AMD64 Family 26 Model 68 Stepping 0, AuthenticAMD",
        "cpu_cores": 8,
        "cpu_threads": 16,
        "cpu_freq_mhz": 4700.0,
        "memory_total_gb": 31.15,
        "memory_available_gb": 19.11,
        "gpu_name": "NVIDIA GeForce RTX 5080",
        "gpu_count": 1,
        "gpu_memory_total_mb": 16303.0,
        "gpu_driver_version": "581.08",
        "cuda_version": "12.8",
        "maeum_version": "",
        "model_name": "",
        "model_variant": "",
        "quantization": ""
      },
      "model_info": {},
      "notes": {
        "status": "builtin_samples",
        "benchmark_type": "math",
        "dataset": "lighteval/MATH"
      },
      "raw_latencies": []
    },
    {
      "benchmark_id": "math",
      "benchmark_name": "MATH",
      "category": "math",
      "mode": "fast",
      "timestamp": "20251202_150910",
      "duration_s": 92.73844861984253,
      "num_samples": 49,
      "success_count": 49,
      "error_count": 0,
      "latency": {
        "avg_ms": 1837.2091839974746,
        "p50_ms": 1891.5995999705046,
        "p90_ms": 1915.3344901045784,
        "p95_ms": 1922.015346067492,
        "p99_ms": 1928.6962020304054,
        "min_ms": 1509.081399999559,
        "max_ms": 1937.6241001300514,
        "std_ms": 0.0,
        "count": 49
      },
      "power": {
        "power_avg_w": 189.4349334916864,
        "power_max_w": 213.294,
        "power_min_w": null,
        "gpu_util_avg": 60.01306413301663,
        "gpu_util_max": null,
        "gpu_mem_avg_mb": null,
        "gpu_mem_peak_mb": 4997.9921875,
        "gpu_temp_avg_c": null,
        "gpu_temp_max_c": 58.0,
        "cpu_util_avg": 8.130641330166284,
        "cpu_util_max": null,
        "cpu_mem_avg_mb": null,
        "cpu_mem_peak_mb": 12745.49609375
      },
      "accuracy": {
        "accuracy": 0.5,
        "f1": 0.06037889045870367,
        "em": 0.5,
        "precision": null,
        "recall": null,
        "extra": {
          "num_samples": 50,
          "dataset_status": "builtin_samples",
          "dataset_name": "lighteval/MATH"
        }
      },
      "efficiency": {
        "perf_per_watt": 0.0028665442018021205,
        "latency_per_watt": 348031.59958087705,
        "tokens_per_second": null,
        "tokens_per_watt": null
      },
      "config": {
        "suite_name": "math",
        "benchmark_name": "math",
        "task_name": "MATH",
        "concurrency": 1,
        "num_requests": 50,
        "duration_s": null,
        "host": "localhost",
        "port": 12345,
        "endpoint": "/generate/simple",
        "mode": "fast",
        "max_tokens": 256,
        "temperature": 0.7,
        "model_name": null,
        "model_variant": null,
        "quantization": null,
        "compression_techniques": null,
        "context_window": null,
        "run_id": "c278b216-109d-4570-ba13-3247ad3c0055"
      },
      "system_info": {
        "os_system": "Windows",
        "os_release": "10",
        "os_version": "10.0.26100",
        "hostname": "DESKTOP-0K2OI03",
        "python_version": "3.10.10",
        "python_implementation": "CPython",
        "cpu_name": "AMD64 Family 26 Model 68 Stepping 0, AuthenticAMD",
        "cpu_cores": 8,
        "cpu_threads": 16,
        "cpu_freq_mhz": 4700.0,
        "memory_total_gb": 31.15,
        "memory_available_gb": 19.11,
        "gpu_name": "NVIDIA GeForce RTX 5080",
        "gpu_count": 1,
        "gpu_memory_total_mb": 16303.0,
        "gpu_driver_version": "581.08",
        "cuda_version": "12.8",
        "maeum_version": "",
        "model_name": "",
        "model_variant": "",
        "quantization": ""
      },
      "model_info": {},
      "notes": {
        "status": "builtin_samples",
        "benchmark_type": "math",
        "dataset": "lighteval/MATH"
      },
      "raw_latencies": []
    },
    {
      "benchmark_id": "math",
      "benchmark_name": "MATH",
      "category": "math",
      "mode": "quality",
      "timestamp": "20251202_150910",
      "duration_s": 92.8229467868805,
      "num_samples": 49,
      "success_count": 49,
      "error_count": 0,
      "latency": {
        "avg_ms": 1841.1723580118269,
        "p50_ms": 1890.5495499493554,
        "p90_ms": 1918.0430801119655,
        "p95_ms": 1926.4529035321902,
        "p99_ms": 1934.862726952415,
        "min_ms": 1536.464300006628,
        "max_ms": 1935.1653999183327,
        "std_ms": 0.0,
        "count": 49
      },
      "power": {
        "power_avg_w": 188.752569905213,
        "power_max_w": 213.413,
        "power_min_w": null,
        "gpu_util_avg": 62.64336492890995,
        "gpu_util_max": null,
        "gpu_mem_avg_mb": null,
        "gpu_mem_peak_mb": 4997.9921875,
        "gpu_temp_avg_c": null,
        "gpu_temp_max_c": 58.0,
        "cpu_util_avg": 8.05225118483413,
        "cpu_util_max": null,
        "cpu_mem_avg_mb": null,
        "cpu_mem_peak_mb": 12734.6640625
      },
      "accuracy": {
        "accuracy": 0.5,
        "f1": 0.05986103228119806,
        "em": 0.5,
        "precision": null,
        "recall": null,
        "extra": {
          "num_samples": 50,
          "dataset_status": "builtin_samples",
          "dataset_name": "lighteval/MATH"
        }
      },
      "efficiency": {
        "perf_per_watt": 0.0028707775113034732,
        "latency_per_watt": 347526.0142131732,
        "tokens_per_second": null,
        "tokens_per_watt": null
      },
      "config": {
        "suite_name": "math",
        "benchmark_name": "math",
        "task_name": "MATH",
        "concurrency": 1,
        "num_requests": 50,
        "duration_s": null,
        "host": "localhost",
        "port": 12345,
        "endpoint": "/generate/simple",
        "mode": "quality",
        "max_tokens": 256,
        "temperature": 0.7,
        "model_name": null,
        "model_variant": null,
        "quantization": null,
        "compression_techniques": null,
        "context_window": null,
        "run_id": "719827cf-b4d7-40b5-a400-e17993765816"
      },
      "system_info": {
        "os_system": "Windows",
        "os_release": "10",
        "os_version": "10.0.26100",
        "hostname": "DESKTOP-0K2OI03",
        "python_version": "3.10.10",
        "python_implementation": "CPython",
        "cpu_name": "AMD64 Family 26 Model 68 Stepping 0, AuthenticAMD",
        "cpu_cores": 8,
        "cpu_threads": 16,
        "cpu_freq_mhz": 4700.0,
        "memory_total_gb": 31.15,
        "memory_available_gb": 19.11,
        "gpu_name": "NVIDIA GeForce RTX 5080",
        "gpu_count": 1,
        "gpu_memory_total_mb": 16303.0,
        "gpu_driver_version": "581.08",
        "cuda_version": "12.8",
        "maeum_version": "",
        "model_name": "",
        "model_variant": "",
        "quantization": ""
      },
      "model_info": {},
      "notes": {
        "status": "builtin_samples",
        "benchmark_type": "math",
        "dataset": "lighteval/MATH"
      },
      "raw_latencies": []
    },
    {
      "benchmark_id": "humaneval",
      "benchmark_name": "HumanEval",
      "category": "coding",
      "mode": "auto",
      "timestamp": "20251202_150910",
      "duration_s": 99.8981511592865,
      "num_samples": 50,
      "success_count": 50,
      "error_count": 0,
      "latency": {
        "avg_ms": 1898.0715060187504,
        "p50_ms": 1945.9504500264302,
        "p90_ms": 1979.8718699952587,
        "p95_ms": 1986.8835235130973,
        "p99_ms": 1993.8951770309359,
        "min_ms": 828.987100161612,
        "max_ms": 1994.577599922195,
        "std_ms": 0.0,
        "count": 50
      },
      "power": {
        "power_avg_w": 190.89099769319515,
        "power_max_w": 215.919,
        "power_min_w": null,
        "gpu_util_avg": 59.78316032295271,
        "gpu_util_max": null,
        "gpu_mem_avg_mb": null,
        "gpu_mem_peak_mb": 4997.9921875,
        "gpu_temp_avg_c": null,
        "gpu_temp_max_c": 59.0,
        "cpu_util_avg": 8.130565167243377,
        "cpu_util_max": null,
        "cpu_mem_avg_mb": null,
        "cpu_mem_peak_mb": 12724.92578125
      },
      "accuracy": {
        "accuracy": 0.52,
        "f1": 0.52,
        "em": 0.52,
        "precision": null,
        "recall": null,
        "extra": {
          "num_samples": 50,
          "dataset_status": "official_dataset",
          "dataset_name": "openai/openai_humaneval"
        }
      },
      "efficiency": {
        "perf_per_watt": 0.0026371301463385104,
        "latency_per_watt": 362324.7634769447,
        "tokens_per_second": null,
        "tokens_per_watt": null
      },
      "config": {
        "suite_name": "coding",
        "benchmark_name": "humaneval",
        "task_name": "HumanEval",
        "concurrency": 1,
        "num_requests": 50,
        "duration_s": null,
        "host": "localhost",
        "port": 12345,
        "endpoint": "/generate/simple",
        "mode": "auto",
        "max_tokens": 256,
        "temperature": 0.7,
        "model_name": null,
        "model_variant": null,
        "quantization": null,
        "compression_techniques": null,
        "context_window": null,
        "run_id": "c5dbdeb5-d12d-4a54-a3f1-19876a12ccd9"
      },
      "system_info": {
        "os_system": "Windows",
        "os_release": "10",
        "os_version": "10.0.26100",
        "hostname": "DESKTOP-0K2OI03",
        "python_version": "3.10.10",
        "python_implementation": "CPython",
        "cpu_name": "AMD64 Family 26 Model 68 Stepping 0, AuthenticAMD",
        "cpu_cores": 8,
        "cpu_threads": 16,
        "cpu_freq_mhz": 4700.0,
        "memory_total_gb": 31.15,
        "memory_available_gb": 19.11,
        "gpu_name": "NVIDIA GeForce RTX 5080",
        "gpu_count": 1,
        "gpu_memory_total_mb": 16303.0,
        "gpu_driver_version": "581.08",
        "cuda_version": "12.8",
        "maeum_version": "",
        "model_name": "",
        "model_variant": "",
        "quantization": ""
      },
      "model_info": {},
      "notes": {
        "status": "official_dataset",
        "benchmark_type": "humaneval",
        "dataset": "openai/openai_humaneval"
      },
      "raw_latencies": []
    },
    {
      "benchmark_id": "humaneval",
      "benchmark_name": "HumanEval",
      "category": "coding",
      "mode": "balanced",
      "timestamp": "20251202_150910",
      "duration_s": 99.61726880073547,
      "num_samples": 50,
      "success_count": 50,
      "error_count": 0,
      "latency": {
        "avg_ms": 1924.4942439859733,
        "p50_ms": 1941.636300063692,
        "p90_ms": 1981.8871098337695,
        "p95_ms": 1992.0333928370383,
        "p99_ms": 2002.179675840307,
        "min_ms": 1210.1743998937309,
        "max_ms": 2013.374999864027,
        "std_ms": 0.0,
        "count": 50
      },
      "power": {
        "power_avg_w": 191.47572985244045,
        "power_max_w": 216.143,
        "power_min_w": null,
        "gpu_util_avg": 62.70034052213394,
        "gpu_util_max": null,
        "gpu_mem_avg_mb": null,
        "gpu_mem_peak_mb": 4997.9921875,
        "gpu_temp_avg_c": null,
        "gpu_temp_max_c": 59.0,
        "cpu_util_avg": 7.911464245175936,
        "cpu_util_max": null,
        "cpu_mem_avg_mb": null,
        "cpu_mem_peak_mb": 12721.85546875
      },
      "accuracy": {
        "accuracy": 0.58,
        "f1": 0.58,
        "em": 0.58,
        "precision": null,
        "recall": null,
        "extra": {
          "num_samples": 50,
          "dataset_status": "official_dataset",
          "dataset_name": "openai/openai_humaneval"
        }
      },
      "efficiency": {
        "perf_per_watt": 0.0026382600336543557,
        "latency_per_watt": 368493.9399640348,
        "tokens_per_second": null,
        "tokens_per_watt": null
      },
      "config": {
        "suite_name": "coding",
        "benchmark_name": "humaneval",
        "task_name": "HumanEval",
        "concurrency": 1,
        "num_requests": 50,
        "duration_s": null,
        "host": "localhost",
        "port": 12345,
        "endpoint": "/generate/simple",
        "mode": "balanced",
        "max_tokens": 256,
        "temperature": 0.7,
        "model_name": null,
        "model_variant": null,
        "quantization": null,
        "compression_techniques": null,
        "context_window": null,
        "run_id": "2ff2b528-7f4e-48f7-a588-092ce60f8f6b"
      },
      "system_info": {
        "os_system": "Windows",
        "os_release": "10",
        "os_version": "10.0.26100",
        "hostname": "DESKTOP-0K2OI03",
        "python_version": "3.10.10",
        "python_implementation": "CPython",
        "cpu_name": "AMD64 Family 26 Model 68 Stepping 0, AuthenticAMD",
        "cpu_cores": 8,
        "cpu_threads": 16,
        "cpu_freq_mhz": 4700.0,
        "memory_total_gb": 31.15,
        "memory_available_gb": 19.11,
        "gpu_name": "NVIDIA GeForce RTX 5080",
        "gpu_count": 1,
        "gpu_memory_total_mb": 16303.0,
        "gpu_driver_version": "581.08",
        "cuda_version": "12.8",
        "maeum_version": "",
        "model_name": "",
        "model_variant": "",
        "quantization": ""
      },
      "model_info": {},
      "notes": {
        "status": "official_dataset",
        "benchmark_type": "humaneval",
        "dataset": "openai/openai_humaneval"
      },
      "raw_latencies": []
    },
    {
      "benchmark_id": "humaneval",
      "benchmark_name": "HumanEval",
      "category": "coding",
      "mode": "fast",
      "timestamp": "20251202_150910",
      "duration_s": 97.23395466804504,
      "num_samples": 50,
      "success_count": 50,
      "error_count": 0,
      "latency": {
        "avg_ms": 1871.7893879907206,
        "p50_ms": 1936.2502499716356,
        "p90_ms": 1970.6417001318187,
        "p95_ms": 1982.145298528485,
        "p99_ms": 1993.6488969251513,
        "min_ms": 667.3995000310242,
        "max_ms": 1997.193899936974,
        "std_ms": 0.0,
        "count": 50
      },
      "power": {
        "power_avg_w": 190.56304200700143,
        "power_max_w": 215.8,
        "power_min_w": null,
        "gpu_util_avg": 62.02100350058343,
        "gpu_util_max": null,
        "gpu_mem_avg_mb": null,
        "gpu_mem_peak_mb": 4997.9921875,
        "gpu_temp_avg_c": null,
        "gpu_temp_max_c": 58.0,
        "cpu_util_avg": 7.958926487747969,
        "cpu_util_max": null,
        "cpu_mem_avg_mb": null,
        "cpu_mem_peak_mb": 12717.30078125
      },
      "accuracy": {
        "accuracy": 0.55,
        "f1": 0.55,
        "em": 0.55,
        "precision": null,
        "recall": null,
        "extra": {
          "num_samples": 50,
          "dataset_status": "official_dataset",
          "dataset_name": "openai/openai_humaneval"
        }
      },
      "efficiency": {
        "perf_per_watt": 0.0027172128270444374,
        "latency_per_watt": 356693.8797719352,
        "tokens_per_second": null,
        "tokens_per_watt": null
      },
      "config": {
        "suite_name": "coding",
        "benchmark_name": "humaneval",
        "task_name": "HumanEval",
        "concurrency": 1,
        "num_requests": 50,
        "duration_s": null,
        "host": "localhost",
        "port": 12345,
        "endpoint": "/generate/simple",
        "mode": "fast",
        "max_tokens": 256,
        "temperature": 0.7,
        "model_name": null,
        "model_variant": null,
        "quantization": null,
        "compression_techniques": null,
        "context_window": null,
        "run_id": "bc042653-c0c8-41a4-bda7-9a6f1d0ccd0c"
      },
      "system_info": {
        "os_system": "Windows",
        "os_release": "10",
        "os_version": "10.0.26100",
        "hostname": "DESKTOP-0K2OI03",
        "python_version": "3.10.10",
        "python_implementation": "CPython",
        "cpu_name": "AMD64 Family 26 Model 68 Stepping 0, AuthenticAMD",
        "cpu_cores": 8,
        "cpu_threads": 16,
        "cpu_freq_mhz": 4700.0,
        "memory_total_gb": 31.15,
        "memory_available_gb": 19.11,
        "gpu_name": "NVIDIA GeForce RTX 5080",
        "gpu_count": 1,
        "gpu_memory_total_mb": 16303.0,
        "gpu_driver_version": "581.08",
        "cuda_version": "12.8",
        "maeum_version": "",
        "model_name": "",
        "model_variant": "",
        "quantization": ""
      },
      "model_info": {},
      "notes": {
        "status": "official_dataset",
        "benchmark_type": "humaneval",
        "dataset": "openai/openai_humaneval"
      },
      "raw_latencies": []
    },
    {
      "benchmark_id": "humaneval",
      "benchmark_name": "HumanEval",
      "category": "coding",
      "mode": "quality",
      "timestamp": "20251202_150910",
      "duration_s": 94.19194173812866,
      "num_samples": 49,
      "success_count": 49,
      "error_count": 0,
      "latency": {
        "avg_ms": 1816.7557460116223,
        "p50_ms": 1937.362749944441,
        "p90_ms": 1986.1223299754784,
        "p95_ms": 2007.2176715626847,
        "p99_ms": 2028.313013149891,
        "min_ms": 386.94239989854395,
        "max_ms": 2044.8830001987517,
        "std_ms": 0.0,
        "count": 49
      },
      "power": {
        "power_avg_w": 190.0050793269233,
        "power_max_w": 215.889,
        "power_min_w": null,
        "gpu_util_avg": 57.05889423076923,
        "gpu_util_max": null,
        "gpu_mem_avg_mb": null,
        "gpu_mem_peak_mb": 4997.9921875,
        "gpu_temp_avg_c": null,
        "gpu_temp_max_c": 58.0,
        "cpu_util_avg": 8.081610576923081,
        "cpu_util_max": null,
        "cpu_mem_avg_mb": null,
        "cpu_mem_peak_mb": 12741.7890625
      },
      "accuracy": {
        "accuracy": 0.53,
        "f1": 0.53,
        "em": 0.53,
        "precision": null,
        "recall": null,
        "extra": {
          "num_samples": 50,
          "dataset_status": "official_dataset",
          "dataset_name": "openai/openai_humaneval"
        }
      },
      "efficiency": {
        "perf_per_watt": 0.0028126081057921752,
        "latency_per_watt": 345192.819638582,
        "tokens_per_second": null,
        "tokens_per_watt": null
      },
      "config": {
        "suite_name": "coding",
        "benchmark_name": "humaneval",
        "task_name": "HumanEval",
        "concurrency": 1,
        "num_requests": 50,
        "duration_s": null,
        "host": "localhost",
        "port": 12345,
        "endpoint": "/generate/simple",
        "mode": "quality",
        "max_tokens": 256,
        "temperature": 0.7,
        "model_name": null,
        "model_variant": null,
        "quantization": null,
        "compression_techniques": null,
        "context_window": null,
        "run_id": "3b851714-2172-43c1-802d-9d789a5d4d44"
      },
      "system_info": {
        "os_system": "Windows",
        "os_release": "10",
        "os_version": "10.0.26100",
        "hostname": "DESKTOP-0K2OI03",
        "python_version": "3.10.10",
        "python_implementation": "CPython",
        "cpu_name": "AMD64 Family 26 Model 68 Stepping 0, AuthenticAMD",
        "cpu_cores": 8,
        "cpu_threads": 16,
        "cpu_freq_mhz": 4700.0,
        "memory_total_gb": 31.15,
        "memory_available_gb": 19.11,
        "gpu_name": "NVIDIA GeForce RTX 5080",
        "gpu_count": 1,
        "gpu_memory_total_mb": 16303.0,
        "gpu_driver_version": "581.08",
        "cuda_version": "12.8",
        "maeum_version": "",
        "model_name": "",
        "model_variant": "",
        "quantization": ""
      },
      "model_info": {},
      "notes": {
        "status": "official_dataset",
        "benchmark_type": "humaneval",
        "dataset": "openai/openai_humaneval"
      },
      "raw_latencies": []
    },
    {
      "benchmark_id": "mbpp",
      "benchmark_name": "MBPP",
      "category": "coding",
      "mode": "auto",
      "timestamp": "20251202_150910",
      "duration_s": 184.18357157707214,
      "num_samples": 100,
      "success_count": 100,
      "error_count": 0,
      "latency": {
        "avg_ms": 1755.7978839962743,
        "p50_ms": 1900.5756499245763,
        "p90_ms": 1924.1904300870374,
        "p95_ms": 2656.221306578955,
        "p99_ms": 3388.252183070873,
        "min_ms": 265.8044002018869,
        "max_ms": 3588.309699902311,
        "std_ms": 0.0,
        "count": 100
      },
      "power": {
        "power_avg_w": 182.4014772868702,
        "power_max_w": 214.274,
        "power_min_w": null,
        "gpu_util_avg": 57.66397013067828,
        "gpu_util_max": null,
        "gpu_mem_avg_mb": null,
        "gpu_mem_peak_mb": 4997.9921875,
        "gpu_temp_avg_c": null,
        "gpu_temp_max_c": 59.0,
        "cpu_util_avg": 7.848786558805234,
        "cpu_util_max": null,
        "cpu_mem_avg_mb": null,
        "cpu_mem_peak_mb": 12816.0546875
      },
      "accuracy": {
        "accuracy": 0.0,
        "f1": 0.11874664966381805,
        "em": 0.0,
        "precision": null,
        "recall": null,
        "extra": {
          "num_samples": 100,
          "dataset_status": "official_dataset",
          "dataset_name": "google-research-datasets/mbpp"
        }
      },
      "efficiency": {
        "perf_per_watt": 0.0029862629759235,
        "latency_per_watt": 320260.1278580812,
        "tokens_per_second": null,
        "tokens_per_watt": null
      },
      "config": {
        "suite_name": "coding",
        "benchmark_name": "mbpp",
        "task_name": "MBPP",
        "concurrency": 1,
        "num_requests": 100,
        "duration_s": null,
        "host": "localhost",
        "port": 12345,
        "endpoint": "/generate/simple",
        "mode": "auto",
        "max_tokens": 256,
        "temperature": 0.7,
        "model_name": null,
        "model_variant": null,
        "quantization": null,
        "compression_techniques": null,
        "context_window": null,
        "run_id": "71bd369e-1622-4079-a233-abddb953db44"
      },
      "system_info": {
        "os_system": "Windows",
        "os_release": "10",
        "os_version": "10.0.26100",
        "hostname": "DESKTOP-0K2OI03",
        "python_version": "3.10.10",
        "python_implementation": "CPython",
        "cpu_name": "AMD64 Family 26 Model 68 Stepping 0, AuthenticAMD",
        "cpu_cores": 8,
        "cpu_threads": 16,
        "cpu_freq_mhz": 4700.0,
        "memory_total_gb": 31.15,
        "memory_available_gb": 19.11,
        "gpu_name": "NVIDIA GeForce RTX 5080",
        "gpu_count": 1,
        "gpu_memory_total_mb": 16303.0,
        "gpu_driver_version": "581.08",
        "cuda_version": "12.8",
        "maeum_version": "",
        "model_name": "",
        "model_variant": "",
        "quantization": ""
      },
      "model_info": {},
      "notes": {
        "status": "official_dataset",
        "benchmark_type": "mbpp",
        "dataset": "google-research-datasets/mbpp"
      },
      "raw_latencies": []
    },
    {
      "benchmark_id": "mbpp",
      "benchmark_name": "MBPP",
      "category": "coding",
      "mode": "balanced",
      "timestamp": "20251202_150910",
      "duration_s": 182.0337779521942,
      "num_samples": 100,
      "success_count": 100,
      "error_count": 0,
      "latency": {
        "avg_ms": 1747.9383110068738,
        "p50_ms": 1904.4138500466943,
        "p90_ms": 1946.0063600214198,
        "p95_ms": 2065.9374509134805,
        "p99_ms": 2185.8685418055406,
        "min_ms": 268.74880003742874,
        "max_ms": 2450.7274001371115,
        "std_ms": 0.0,
        "count": 100
      },
      "power": {
        "power_avg_w": 187.3249350405991,
        "power_max_w": 214.993,
        "power_min_w": null,
        "gpu_util_avg": 55.51967520299812,
        "gpu_util_max": null,
        "gpu_mem_avg_mb": null,
        "gpu_mem_peak_mb": 5043.1484375,
        "gpu_temp_avg_c": null,
        "gpu_temp_max_c": 59.0,
        "cpu_util_avg": 8.993691442848233,
        "cpu_util_max": null,
        "cpu_mem_avg_mb": null,
        "cpu_mem_peak_mb": 13060.9140625
      },
      "accuracy": {
        "accuracy": 0.0,
        "f1": 0.11921545979362688,
        "em": 0.0,
        "precision": null,
        "recall": null,
        "extra": {
          "num_samples": 100,
          "dataset_status": "official_dataset",
          "dataset_name": "google-research-datasets/mbpp"
        }
      },
      "efficiency": {
        "perf_per_watt": 0.0029429181506915422,
        "latency_per_watt": 327432.4305643371,
        "tokens_per_second": null,
        "tokens_per_watt": null
      },
      "config": {
        "suite_name": "coding",
        "benchmark_name": "mbpp",
        "task_name": "MBPP",
        "concurrency": 1,
        "num_requests": 100,
        "duration_s": null,
        "host": "localhost",
        "port": 12345,
        "endpoint": "/generate/simple",
        "mode": "balanced",
        "max_tokens": 256,
        "temperature": 0.7,
        "model_name": null,
        "model_variant": null,
        "quantization": null,
        "compression_techniques": null,
        "context_window": null,
        "run_id": "33ef8b0f-c183-474c-9495-bc0ccfb6df07"
      },
      "system_info": {
        "os_system": "Windows",
        "os_release": "10",
        "os_version": "10.0.26100",
        "hostname": "DESKTOP-0K2OI03",
        "python_version": "3.10.10",
        "python_implementation": "CPython",
        "cpu_name": "AMD64 Family 26 Model 68 Stepping 0, AuthenticAMD",
        "cpu_cores": 8,
        "cpu_threads": 16,
        "cpu_freq_mhz": 4700.0,
        "memory_total_gb": 31.15,
        "memory_available_gb": 19.11,
        "gpu_name": "NVIDIA GeForce RTX 5080",
        "gpu_count": 1,
        "gpu_memory_total_mb": 16303.0,
        "gpu_driver_version": "581.08",
        "cuda_version": "12.8",
        "maeum_version": "",
        "model_name": "",
        "model_variant": "",
        "quantization": ""
      },
      "model_info": {},
      "notes": {
        "status": "official_dataset",
        "benchmark_type": "mbpp",
        "dataset": "google-research-datasets/mbpp"
      },
      "raw_latencies": []
    },
    {
      "benchmark_id": "mbpp",
      "benchmark_name": "MBPP",
      "category": "coding",
      "mode": "fast",
      "timestamp": "20251202_150910",
      "duration_s": 186.28557467460632,
      "num_samples": 100,
      "success_count": 100,
      "error_count": 0,
      "latency": {
        "avg_ms": 1791.7399649973959,
        "p50_ms": 1902.9311499325559,
        "p90_ms": 1925.2359999809414,
        "p95_ms": 1934.4619070587219,
        "p99_ms": 1943.687814136502,
        "min_ms": 301.1948000639677,
        "max_ms": 2056.53930013068,
        "std_ms": 0.0,
        "count": 100
      },
      "power": {
        "power_avg_w": 189.89899390243897,
        "power_max_w": 215.504,
        "power_min_w": null,
        "gpu_util_avg": 58.489634146341466,
        "gpu_util_max": null,
        "gpu_mem_avg_mb": null,
        "gpu_mem_peak_mb": 5029.4609375,
        "gpu_temp_avg_c": null,
        "gpu_temp_max_c": 59.0,
        "cpu_util_avg": 8.092073170731698,
        "cpu_util_max": null,
        "cpu_mem_avg_mb": null,
        "cpu_mem_peak_mb": 13017.80078125
      },
      "accuracy": {
        "accuracy": 0.0,
        "f1": 0.12426154488654811,
        "em": 0.0,
        "precision": null,
        "recall": null,
        "extra": {
          "num_samples": 100,
          "dataset_status": "official_dataset",
          "dataset_name": "google-research-datasets/mbpp"
        }
      },
      "efficiency": {
        "perf_per_watt": 0.0028356073739601068,
        "latency_per_watt": 340249.6166877967,
        "tokens_per_second": null,
        "tokens_per_watt": null
      },
      "config": {
        "suite_name": "coding",
        "benchmark_name": "mbpp",
        "task_name": "MBPP",
        "concurrency": 1,
        "num_requests": 100,
        "duration_s": null,
        "host": "localhost",
        "port": 12345,
        "endpoint": "/generate/simple",
        "mode": "fast",
        "max_tokens": 256,
        "temperature": 0.7,
        "model_name": null,
        "model_variant": null,
        "quantization": null,
        "compression_techniques": null,
        "context_window": null,
        "run_id": "3acd2dc0-c200-4c36-8520-916395aa21ff"
      },
      "system_info": {
        "os_system": "Windows",
        "os_release": "10",
        "os_version": "10.0.26100",
        "hostname": "DESKTOP-0K2OI03",
        "python_version": "3.10.10",
        "python_implementation": "CPython",
        "cpu_name": "AMD64 Family 26 Model 68 Stepping 0, AuthenticAMD",
        "cpu_cores": 8,
        "cpu_threads": 16,
        "cpu_freq_mhz": 4700.0,
        "memory_total_gb": 31.15,
        "memory_available_gb": 19.11,
        "gpu_name": "NVIDIA GeForce RTX 5080",
        "gpu_count": 1,
        "gpu_memory_total_mb": 16303.0,
        "gpu_driver_version": "581.08",
        "cuda_version": "12.8",
        "maeum_version": "",
        "model_name": "",
        "model_variant": "",
        "quantization": ""
      },
      "model_info": {},
      "notes": {
        "status": "official_dataset",
        "benchmark_type": "mbpp",
        "dataset": "google-research-datasets/mbpp"
      },
      "raw_latencies": []
    },
    {
      "benchmark_id": "mbpp",
      "benchmark_name": "MBPP",
      "category": "coding",
      "mode": "quality",
      "timestamp": "20251202_150910",
      "duration_s": 187.6590654850006,
      "num_samples": 100,
      "success_count": 100,
      "error_count": 0,
      "latency": {
        "avg_ms": 1804.9747420148924,
        "p50_ms": 1907.4841999681666,
        "p90_ms": 1930.22687996272,
        "p95_ms": 1949.901167890057,
        "p99_ms": 1969.5754558173942,
        "min_ms": 265.9223999362439,
        "max_ms": 2012.8341000527143,
        "std_ms": 0.0,
        "count": 100
      },
      "power": {
        "power_avg_w": 190.64330277442673,
        "power_max_w": 215.238,
        "power_min_w": null,
        "gpu_util_avg": 59.10494571773221,
        "gpu_util_max": null,
        "gpu_mem_avg_mb": null,
        "gpu_mem_peak_mb": 5068.7421875,
        "gpu_temp_avg_c": null,
        "gpu_temp_max_c": 58.0,
        "cpu_util_avg": 9.50687575392038,
        "cpu_util_max": null,
        "cpu_mem_avg_mb": null,
        "cpu_mem_peak_mb": 13096.72265625
      },
      "accuracy": {
        "accuracy": 0.0,
        "f1": 0.1311286091786977,
        "em": 0.0,
        "precision": null,
        "recall": null,
        "extra": {
          "num_samples": 100,
          "dataset_status": "official_dataset",
          "dataset_name": "google-research-datasets/mbpp"
        }
      },
      "efficiency": {
        "perf_per_watt": 0.002804582401513856,
        "latency_per_watt": 344106.3462421379,
        "tokens_per_second": null,
        "tokens_per_watt": null
      },
      "config": {
        "suite_name": "coding",
        "benchmark_name": "mbpp",
        "task_name": "MBPP",
        "concurrency": 1,
        "num_requests": 100,
        "duration_s": null,
        "host": "localhost",
        "port": 12345,
        "endpoint": "/generate/simple",
        "mode": "quality",
        "max_tokens": 256,
        "temperature": 0.7,
        "model_name": null,
        "model_variant": null,
        "quantization": null,
        "compression_techniques": null,
        "context_window": null,
        "run_id": "76ad97f5-8eef-4079-b0ef-caa9481d468e"
      },
      "system_info": {
        "os_system": "Windows",
        "os_release": "10",
        "os_version": "10.0.26100",
        "hostname": "DESKTOP-0K2OI03",
        "python_version": "3.10.10",
        "python_implementation": "CPython",
        "cpu_name": "AMD64 Family 26 Model 68 Stepping 0, AuthenticAMD",
        "cpu_cores": 8,
        "cpu_threads": 16,
        "cpu_freq_mhz": 4700.0,
        "memory_total_gb": 31.15,
        "memory_available_gb": 19.11,
        "gpu_name": "NVIDIA GeForce RTX 5080",
        "gpu_count": 1,
        "gpu_memory_total_mb": 16303.0,
        "gpu_driver_version": "581.08",
        "cuda_version": "12.8",
        "maeum_version": "",
        "model_name": "",
        "model_variant": "",
        "quantization": ""
      },
      "model_info": {},
      "notes": {
        "status": "official_dataset",
        "benchmark_type": "mbpp",
        "dataset": "google-research-datasets/mbpp"
      },
      "raw_latencies": []
    },
    {
      "benchmark_id": "bbh",
      "benchmark_name": "BBH",
      "category": "reasoning",
      "mode": "auto",
      "timestamp": "20251202_150910",
      "duration_s": 160.18416666984558,
      "num_samples": 100,
      "success_count": 100,
      "error_count": 0,
      "latency": {
        "avg_ms": 1541.7221760051325,
        "p50_ms": 1528.6441500065848,
        "p90_ms": 1914.3334998982027,
        "p95_ms": 1921.1034869833384,
        "p99_ms": 1927.873474068474,
        "min_ms": 806.6334999166429,
        "max_ms": 1936.592800077051,
        "std_ms": 0.0,
        "count": 100
      },
      "power": {
        "power_avg_w": 186.48756890459444,
        "power_max_w": 214.595,
        "power_min_w": null,
        "gpu_util_avg": 60.135689045936395,
        "gpu_util_max": null,
        "gpu_mem_avg_mb": null,
        "gpu_mem_peak_mb": 5071.8046875,
        "gpu_temp_avg_c": null,
        "gpu_temp_max_c": 58.0,
        "cpu_util_avg": 9.031731448763226,
        "cpu_util_max": null,
        "cpu_mem_avg_mb": null,
        "cpu_mem_peak_mb": 13157.3203125
      },
      "accuracy": {
        "accuracy": 1.0,
        "f1": 1.0,
        "em": 1.0,
        "precision": null,
        "recall": null,
        "extra": {
          "num_samples": 100,
          "dataset_status": "official_dataset",
          "dataset_name": "lukaemon/bbh"
        }
      },
      "efficiency": {
        "perf_per_watt": 0.0033613285572094862,
        "latency_per_watt": 287512.0205294984,
        "tokens_per_second": null,
        "tokens_per_watt": null
      },
      "config": {
        "suite_name": "reasoning",
        "benchmark_name": "bbh",
        "task_name": "BBH",
        "concurrency": 1,
        "num_requests": 100,
        "duration_s": null,
        "host": "localhost",
        "port": 12345,
        "endpoint": "/generate/simple",
        "mode": "auto",
        "max_tokens": 256,
        "temperature": 0.7,
        "model_name": null,
        "model_variant": null,
        "quantization": null,
        "compression_techniques": null,
        "context_window": null,
        "run_id": "f6b32c2b-7488-40a7-a946-b86bbf81d26a"
      },
      "system_info": {
        "os_system": "Windows",
        "os_release": "10",
        "os_version": "10.0.26100",
        "hostname": "DESKTOP-0K2OI03",
        "python_version": "3.10.10",
        "python_implementation": "CPython",
        "cpu_name": "AMD64 Family 26 Model 68 Stepping 0, AuthenticAMD",
        "cpu_cores": 8,
        "cpu_threads": 16,
        "cpu_freq_mhz": 4700.0,
        "memory_total_gb": 31.15,
        "memory_available_gb": 19.11,
        "gpu_name": "NVIDIA GeForce RTX 5080",
        "gpu_count": 1,
        "gpu_memory_total_mb": 16303.0,
        "gpu_driver_version": "581.08",
        "cuda_version": "12.8",
        "maeum_version": "",
        "model_name": "",
        "model_variant": "",
        "quantization": ""
      },
      "model_info": {},
      "notes": {
        "status": "official_dataset",
        "benchmark_type": "bbh",
        "dataset": "lukaemon/bbh"
      },
      "raw_latencies": []
    },
    {
      "benchmark_id": "bbh",
      "benchmark_name": "BBH",
      "category": "reasoning",
      "mode": "balanced",
      "timestamp": "20251202_150910",
      "duration_s": 164.6424126625061,
      "num_samples": 100,
      "success_count": 100,
      "error_count": 0,
      "latency": {
        "avg_ms": 1612.147038995754,
        "p50_ms": 1752.9668499482796,
        "p90_ms": 1921.784490137361,
        "p95_ms": 1938.077418076573,
        "p99_ms": 1954.3703460157851,
        "min_ms": 992.926700040698,
        "max_ms": 1986.6390000097454,
        "std_ms": 0.0,
        "count": 100
      },
      "power": {
        "power_avg_w": 187.95144878706205,
        "power_max_w": 215.163,
        "power_min_w": null,
        "gpu_util_avg": 56.2911051212938,
        "gpu_util_max": null,
        "gpu_mem_avg_mb": null,
        "gpu_mem_peak_mb": 5058.4921875,
        "gpu_temp_avg_c": null,
        "gpu_temp_max_c": 58.0,
        "cpu_util_avg": 9.320080862533697,
        "cpu_util_max": null,
        "cpu_mem_avg_mb": null,
        "cpu_mem_peak_mb": 13169.07421875
      },
      "accuracy": {
        "accuracy": 1.0,
        "f1": 1.0,
        "em": 1.0,
        "precision": null,
        "recall": null,
        "extra": {
          "num_samples": 100,
          "dataset_status": "official_dataset",
          "dataset_name": "lukaemon/bbh"
        }
      },
      "efficiency": {
        "perf_per_watt": 0.003243252142831988,
        "latency_per_watt": 303005.37163702416,
        "tokens_per_second": null,
        "tokens_per_watt": null
      },
      "config": {
        "suite_name": "reasoning",
        "benchmark_name": "bbh",
        "task_name": "BBH",
        "concurrency": 1,
        "num_requests": 100,
        "duration_s": null,
        "host": "localhost",
        "port": 12345,
        "endpoint": "/generate/simple",
        "mode": "balanced",
        "max_tokens": 256,
        "temperature": 0.7,
        "model_name": null,
        "model_variant": null,
        "quantization": null,
        "compression_techniques": null,
        "context_window": null,
        "run_id": "b32525f0-51c6-46eb-a49d-e314765e5074"
      },
      "system_info": {
        "os_system": "Windows",
        "os_release": "10",
        "os_version": "10.0.26100",
        "hostname": "DESKTOP-0K2OI03",
        "python_version": "3.10.10",
        "python_implementation": "CPython",
        "cpu_name": "AMD64 Family 26 Model 68 Stepping 0, AuthenticAMD",
        "cpu_cores": 8,
        "cpu_threads": 16,
        "cpu_freq_mhz": 4700.0,
        "memory_total_gb": 31.15,
        "memory_available_gb": 19.11,
        "gpu_name": "NVIDIA GeForce RTX 5080",
        "gpu_count": 1,
        "gpu_memory_total_mb": 16303.0,
        "gpu_driver_version": "581.08",
        "cuda_version": "12.8",
        "maeum_version": "",
        "model_name": "",
        "model_variant": "",
        "quantization": ""
      },
      "model_info": {},
      "notes": {
        "status": "official_dataset",
        "benchmark_type": "bbh",
        "dataset": "lukaemon/bbh"
      },
      "raw_latencies": []
    },
    {
      "benchmark_id": "bbh",
      "benchmark_name": "BBH",
      "category": "reasoning",
      "mode": "fast",
      "timestamp": "20251202_150910",
      "duration_s": 163.30249547958374,
      "num_samples": 99,
      "success_count": 99,
      "error_count": 0,
      "latency": {
        "avg_ms": 1600.1678650081158,
        "p50_ms": 1651.2951499316841,
        "p90_ms": 1925.868139974773,
        "p95_ms": 1945.138781494461,
        "p99_ms": 1964.409423014149,
        "min_ms": 796.430799877271,
        "max_ms": 1970.4309001099318,
        "std_ms": 0.0,
        "count": 99
      },
      "power": {
        "power_avg_w": 187.27495643294776,
        "power_max_w": 214.8,
        "power_min_w": null,
        "gpu_util_avg": 61.61606535057862,
        "gpu_util_max": null,
        "gpu_mem_avg_mb": null,
        "gpu_mem_peak_mb": 5048.6640625,
        "gpu_temp_avg_c": null,
        "gpu_temp_max_c": 58.0,
        "cpu_util_avg": 9.30374404356707,
        "cpu_util_max": null,
        "cpu_mem_avg_mb": null,
        "cpu_mem_peak_mb": 13102.6640625
      },
      "accuracy": {
        "accuracy": 1.0,
        "f1": 1.0,
        "em": 1.0,
        "precision": null,
        "recall": null,
        "extra": {
          "num_samples": 100,
          "dataset_status": "official_dataset",
          "dataset_name": "lukaemon/bbh"
        }
      },
      "efficiency": {
        "perf_per_watt": 0.0032821598653917363,
        "latency_per_watt": 299671.3672047979,
        "tokens_per_second": null,
        "tokens_per_watt": null
      },
      "config": {
        "suite_name": "reasoning",
        "benchmark_name": "bbh",
        "task_name": "BBH",
        "concurrency": 1,
        "num_requests": 100,
        "duration_s": null,
        "host": "localhost",
        "port": 12345,
        "endpoint": "/generate/simple",
        "mode": "fast",
        "max_tokens": 256,
        "temperature": 0.7,
        "model_name": null,
        "model_variant": null,
        "quantization": null,
        "compression_techniques": null,
        "context_window": null,
        "run_id": "ceded5f9-4306-4404-a05a-b31b06d6c2af"
      },
      "system_info": {
        "os_system": "Windows",
        "os_release": "10",
        "os_version": "10.0.26100",
        "hostname": "DESKTOP-0K2OI03",
        "python_version": "3.10.10",
        "python_implementation": "CPython",
        "cpu_name": "AMD64 Family 26 Model 68 Stepping 0, AuthenticAMD",
        "cpu_cores": 8,
        "cpu_threads": 16,
        "cpu_freq_mhz": 4700.0,
        "memory_total_gb": 31.15,
        "memory_available_gb": 19.11,
        "gpu_name": "NVIDIA GeForce RTX 5080",
        "gpu_count": 1,
        "gpu_memory_total_mb": 16303.0,
        "gpu_driver_version": "581.08",
        "cuda_version": "12.8",
        "maeum_version": "",
        "model_name": "",
        "model_variant": "",
        "quantization": ""
      },
      "model_info": {},
      "notes": {
        "status": "official_dataset",
        "benchmark_type": "bbh",
        "dataset": "lukaemon/bbh"
      },
      "raw_latencies": []
    },
    {
      "benchmark_id": "bbh",
      "benchmark_name": "BBH",
      "category": "reasoning",
      "mode": "quality",
      "timestamp": "20251202_150910",
      "duration_s": 170.47046542167664,
      "num_samples": 100,
      "success_count": 100,
      "error_count": 0,
      "latency": {
        "avg_ms": 1667.2322459844872,
        "p50_ms": 1896.1542500182986,
        "p90_ms": 1927.1643199026585,
        "p95_ms": 1946.0953514731955,
        "p99_ms": 1965.0263830437325,
        "min_ms": 878.3956998959184,
        "max_ms": 1968.1530999951065,
        "std_ms": 0.0,
        "count": 100
      },
      "power": {
        "power_avg_w": 187.85372941176428,
        "power_max_w": 214.9,
        "power_min_w": null,
        "gpu_util_avg": 55.97581699346405,
        "gpu_util_max": null,
        "gpu_mem_avg_mb": null,
        "gpu_mem_peak_mb": 5070.6953125,
        "gpu_temp_avg_c": null,
        "gpu_temp_max_c": 58.0,
        "cpu_util_avg": 9.467712418300664,
        "cpu_util_max": null,
        "cpu_mem_avg_mb": null,
        "cpu_mem_peak_mb": 13176.66796875
      },
      "accuracy": {
        "accuracy": 1.0,
        "f1": 1.0,
        "em": 1.0,
        "precision": null,
        "recall": null,
        "extra": {
          "num_samples": 100,
          "dataset_status": "official_dataset",
          "dataset_name": "lukaemon/bbh"
        }
      },
      "efficiency": {
        "perf_per_watt": 0.003134747330441013,
        "latency_per_watt": 313195.79520373786,
        "tokens_per_second": null,
        "tokens_per_watt": null
      },
      "config": {
        "suite_name": "reasoning",
        "benchmark_name": "bbh",
        "task_name": "BBH",
        "concurrency": 1,
        "num_requests": 100,
        "duration_s": null,
        "host": "localhost",
        "port": 12345,
        "endpoint": "/generate/simple",
        "mode": "quality",
        "max_tokens": 256,
        "temperature": 0.7,
        "model_name": null,
        "model_variant": null,
        "quantization": null,
        "compression_techniques": null,
        "context_window": null,
        "run_id": "5b41ad15-3e07-4a03-8e4b-5f6ed3d9a141"
      },
      "system_info": {
        "os_system": "Windows",
        "os_release": "10",
        "os_version": "10.0.26100",
        "hostname": "DESKTOP-0K2OI03",
        "python_version": "3.10.10",
        "python_implementation": "CPython",
        "cpu_name": "AMD64 Family 26 Model 68 Stepping 0, AuthenticAMD",
        "cpu_cores": 8,
        "cpu_threads": 16,
        "cpu_freq_mhz": 4700.0,
        "memory_total_gb": 31.15,
        "memory_available_gb": 19.11,
        "gpu_name": "NVIDIA GeForce RTX 5080",
        "gpu_count": 1,
        "gpu_memory_total_mb": 16303.0,
        "gpu_driver_version": "581.08",
        "cuda_version": "12.8",
        "maeum_version": "",
        "model_name": "",
        "model_variant": "",
        "quantization": ""
      },
      "model_info": {},
      "notes": {
        "status": "official_dataset",
        "benchmark_type": "bbh",
        "dataset": "lukaemon/bbh"
      },
      "raw_latencies": []
    },
    {
      "benchmark_id": "coqa",
      "benchmark_name": "CoQA",
      "category": "conversation",
      "mode": "auto",
      "timestamp": "20251202_150910",
      "duration_s": 8.477321147918701,
      "num_samples": 4,
      "success_count": 4,
      "error_count": 0,
      "latency": {
        "avg_ms": 1957.317674998194,
        "p50_ms": 1951.064549968578,
        "p90_ms": 1977.980690007098,
        "p95_ms": 1981.8828245007899,
        "p99_ms": 1985.7849589944817,
        "min_ms": 1940.4895000625402,
        "max_ms": 1986.65209999308,
        "std_ms": 0.0,
        "count": 4
      },
      "power": {
        "power_avg_w": 184.41960273972603,
        "power_max_w": 216.255,
        "power_min_w": null,
        "gpu_util_avg": 67.23287671232876,
        "gpu_util_max": null,
        "gpu_mem_avg_mb": null,
        "gpu_mem_peak_mb": 5035.0859375,
        "gpu_temp_avg_c": null,
        "gpu_temp_max_c": 58.0,
        "cpu_util_avg": 7.952054794520551,
        "cpu_util_max": null,
        "cpu_mem_avg_mb": null,
        "cpu_mem_peak_mb": 12996.50390625
      },
      "accuracy": {
        "accuracy": 0.75,
        "f1": 0.06468031533182274,
        "em": 0.75,
        "precision": null,
        "recall": null,
        "extra": {
          "description": "Simple CoQA-style F1/EM over small Korean/English samples.",
          "num_turns": 4
        }
      },
      "efficiency": {
        "perf_per_watt": 0.002770179275143592,
        "latency_per_watt": 360967.7480586111,
        "tokens_per_second": null,
        "tokens_per_watt": null
      },
      "config": {
        "suite_name": "conversation",
        "benchmark_name": "coqa",
        "task_name": "CoQA",
        "concurrency": 1,
        "num_requests": 50,
        "duration_s": null,
        "host": "localhost",
        "port": 12345,
        "endpoint": "/generate/simple",
        "mode": "auto",
        "max_tokens": 256,
        "temperature": 0.7,
        "model_name": null,
        "model_variant": null,
        "quantization": null,
        "compression_techniques": null,
        "context_window": null,
        "run_id": "19dda0c4-ca44-4b71-91c4-e451c8d88a16"
      },
      "system_info": {
        "os_system": "Windows",
        "os_release": "10",
        "os_version": "10.0.26100",
        "hostname": "DESKTOP-0K2OI03",
        "python_version": "3.10.10",
        "python_implementation": "CPython",
        "cpu_name": "AMD64 Family 26 Model 68 Stepping 0, AuthenticAMD",
        "cpu_cores": 8,
        "cpu_threads": 16,
        "cpu_freq_mhz": 4700.0,
        "memory_total_gb": 31.15,
        "memory_available_gb": 19.11,
        "gpu_name": "NVIDIA GeForce RTX 5080",
        "gpu_count": 1,
        "gpu_memory_total_mb": 16303.0,
        "gpu_driver_version": "581.08",
        "cuda_version": "12.8",
        "maeum_version": "",
        "model_name": "",
        "model_variant": "",
        "quantization": ""
      },
      "model_info": {},
      "notes": {
        "benchmark_type": "coqa_simple",
        "description": "Small CoQA-style conversational QA benchmark."
      },
      "raw_latencies": []
    },
    {
      "benchmark_id": "coqa",
      "benchmark_name": "CoQA",
      "category": "conversation",
      "mode": "balanced",
      "timestamp": "20251202_150910",
      "duration_s": 8.508323907852173,
      "num_samples": 4,
      "success_count": 4,
      "error_count": 0,
      "latency": {
        "avg_ms": 1955.9546749806032,
        "p50_ms": 1951.9382000435144,
        "p90_ms": 1981.5548099111766,
        "p95_ms": 1985.0180053943768,
        "p99_ms": 1988.481200877577,
        "min_ms": 1930.69149996154,
        "max_ms": 1989.2507998738438,
        "std_ms": 0.0,
        "count": 4
      },
      "power": {
        "power_avg_w": 183.0130277777779,
        "power_max_w": 215.878,
        "power_min_w": null,
        "gpu_util_avg": 55.888888888888886,
        "gpu_util_max": null,
        "gpu_mem_avg_mb": null,
        "gpu_mem_peak_mb": 5053.1640625,
        "gpu_temp_avg_c": null,
        "gpu_temp_max_c": 58.0,
        "cpu_util_avg": 10.586111111111112,
        "cpu_util_max": null,
        "cpu_mem_avg_mb": null,
        "cpu_mem_peak_mb": 13075.91796875
      },
      "accuracy": {
        "accuracy": 0.75,
        "f1": 0.07519039847681218,
        "em": 0.75,
        "precision": null,
        "recall": null,
        "extra": {
          "description": "Simple CoQA-style F1/EM over small Korean/English samples.",
          "num_turns": 4
        }
      },
      "efficiency": {
        "perf_per_watt": 0.002793415678936148,
        "latency_per_watt": 357965.18726429966,
        "tokens_per_second": null,
        "tokens_per_watt": null
      },
      "config": {
        "suite_name": "conversation",
        "benchmark_name": "coqa",
        "task_name": "CoQA",
        "concurrency": 1,
        "num_requests": 50,
        "duration_s": null,
        "host": "localhost",
        "port": 12345,
        "endpoint": "/generate/simple",
        "mode": "balanced",
        "max_tokens": 256,
        "temperature": 0.7,
        "model_name": null,
        "model_variant": null,
        "quantization": null,
        "compression_techniques": null,
        "context_window": null,
        "run_id": "bac102ab-3dfe-4bc1-a39e-4fa414d6e552"
      },
      "system_info": {
        "os_system": "Windows",
        "os_release": "10",
        "os_version": "10.0.26100",
        "hostname": "DESKTOP-0K2OI03",
        "python_version": "3.10.10",
        "python_implementation": "CPython",
        "cpu_name": "AMD64 Family 26 Model 68 Stepping 0, AuthenticAMD",
        "cpu_cores": 8,
        "cpu_threads": 16,
        "cpu_freq_mhz": 4700.0,
        "memory_total_gb": 31.15,
        "memory_available_gb": 19.11,
        "gpu_name": "NVIDIA GeForce RTX 5080",
        "gpu_count": 1,
        "gpu_memory_total_mb": 16303.0,
        "gpu_driver_version": "581.08",
        "cuda_version": "12.8",
        "maeum_version": "",
        "model_name": "",
        "model_variant": "",
        "quantization": ""
      },
      "model_info": {},
      "notes": {
        "benchmark_type": "coqa_simple",
        "description": "Small CoQA-style conversational QA benchmark."
      },
      "raw_latencies": []
    },
    {
      "benchmark_id": "coqa",
      "benchmark_name": "CoQA",
      "category": "conversation",
      "mode": "fast",
      "timestamp": "20251202_150910",
      "duration_s": 7.392505168914795,
      "num_samples": 4,
      "success_count": 4,
      "error_count": 0,
      "latency": {
        "avg_ms": 1690.575924993027,
        "p50_ms": 1975.3982999827713,
        "p90_ms": 2012.3752700164914,
        "p95_ms": 2015.7581135164946,
        "p99_ms": 2019.1409570164979,
        "min_ms": 791.6143999900669,
        "max_ms": 2019.8927000164986,
        "std_ms": 0.0,
        "count": 4
      },
      "power": {
        "power_avg_w": 177.00380952380948,
        "power_max_w": 215.09,
        "power_min_w": null,
        "gpu_util_avg": 65.3015873015873,
        "gpu_util_max": null,
        "gpu_mem_avg_mb": null,
        "gpu_mem_peak_mb": 5064.5546875,
        "gpu_temp_avg_c": null,
        "gpu_temp_max_c": 58.0,
        "cpu_util_avg": 12.3015873015873,
        "cpu_util_max": null,
        "cpu_mem_avg_mb": null,
        "cpu_mem_peak_mb": 13135.30859375
      },
      "accuracy": {
        "accuracy": 0.75,
        "f1": 0.08957607433217188,
        "em": 0.75,
        "precision": null,
        "recall": null,
        "extra": {
          "description": "Simple CoQA-style F1/EM over small Korean/English samples.",
          "num_turns": 4
        }
      },
      "efficiency": {
        "perf_per_watt": 0.0033416285600849425,
        "latency_per_watt": 299238.3790130038,
        "tokens_per_second": null,
        "tokens_per_watt": null
      },
      "config": {
        "suite_name": "conversation",
        "benchmark_name": "coqa",
        "task_name": "CoQA",
        "concurrency": 1,
        "num_requests": 50,
        "duration_s": null,
        "host": "localhost",
        "port": 12345,
        "endpoint": "/generate/simple",
        "mode": "fast",
        "max_tokens": 256,
        "temperature": 0.7,
        "model_name": null,
        "model_variant": null,
        "quantization": null,
        "compression_techniques": null,
        "context_window": null,
        "run_id": "bcb62dda-37ff-4e2e-ab93-405d392390ed"
      },
      "system_info": {
        "os_system": "Windows",
        "os_release": "10",
        "os_version": "10.0.26100",
        "hostname": "DESKTOP-0K2OI03",
        "python_version": "3.10.10",
        "python_implementation": "CPython",
        "cpu_name": "AMD64 Family 26 Model 68 Stepping 0, AuthenticAMD",
        "cpu_cores": 8,
        "cpu_threads": 16,
        "cpu_freq_mhz": 4700.0,
        "memory_total_gb": 31.15,
        "memory_available_gb": 19.11,
        "gpu_name": "NVIDIA GeForce RTX 5080",
        "gpu_count": 1,
        "gpu_memory_total_mb": 16303.0,
        "gpu_driver_version": "581.08",
        "cuda_version": "12.8",
        "maeum_version": "",
        "model_name": "",
        "model_variant": "",
        "quantization": ""
      },
      "model_info": {},
      "notes": {
        "benchmark_type": "coqa_simple",
        "description": "Small CoQA-style conversational QA benchmark."
      },
      "raw_latencies": []
    },
    {
      "benchmark_id": "coqa",
      "benchmark_name": "CoQA",
      "category": "conversation",
      "mode": "quality",
      "timestamp": "20251202_150910",
      "duration_s": 7.256609201431274,
      "num_samples": 4,
      "success_count": 4,
      "error_count": 0,
      "latency": {
        "avg_ms": 1650.9623500169255,
        "p50_ms": 1955.778699950315,
        "p90_ms": 1983.5667100502178,
        "p95_ms": 1984.4794855697546,
        "p99_ms": 1985.3922610892914,
        "min_ms": 706.6969000734389,
        "max_ms": 1985.595100093633,
        "std_ms": 0.0,
        "count": 4
      },
      "power": {
        "power_avg_w": 177.40935483870956,
        "power_max_w": 215.628,
        "power_min_w": null,
        "gpu_util_avg": 56.38709677419355,
        "gpu_util_max": null,
        "gpu_mem_avg_mb": null,
        "gpu_mem_peak_mb": 5047.9765625,
        "gpu_temp_avg_c": null,
        "gpu_temp_max_c": 58.0,
        "cpu_util_avg": 11.991935483870966,
        "cpu_util_max": null,
        "cpu_mem_avg_mb": null,
        "cpu_mem_peak_mb": 13128.7734375
      },
      "accuracy": {
        "accuracy": 0.75,
        "f1": 0.11547876288962876,
        "em": 0.75,
        "precision": null,
        "recall": null,
        "extra": {
          "description": "Simple CoQA-style F1/EM over small Korean/English samples.",
          "num_turns": 4
        }
      },
      "efficiency": {
        "perf_per_watt": 0.0034139714977136555,
        "latency_per_watt": 292896.1653795025,
        "tokens_per_second": null,
        "tokens_per_watt": null
      },
      "config": {
        "suite_name": "conversation",
        "benchmark_name": "coqa",
        "task_name": "CoQA",
        "concurrency": 1,
        "num_requests": 50,
        "duration_s": null,
        "host": "localhost",
        "port": 12345,
        "endpoint": "/generate/simple",
        "mode": "quality",
        "max_tokens": 256,
        "temperature": 0.7,
        "model_name": null,
        "model_variant": null,
        "quantization": null,
        "compression_techniques": null,
        "context_window": null,
        "run_id": "26d21e2b-b7d9-49c3-9585-0955a0537b95"
      },
      "system_info": {
        "os_system": "Windows",
        "os_release": "10",
        "os_version": "10.0.26100",
        "hostname": "DESKTOP-0K2OI03",
        "python_version": "3.10.10",
        "python_implementation": "CPython",
        "cpu_name": "AMD64 Family 26 Model 68 Stepping 0, AuthenticAMD",
        "cpu_cores": 8,
        "cpu_threads": 16,
        "cpu_freq_mhz": 4700.0,
        "memory_total_gb": 31.15,
        "memory_available_gb": 19.11,
        "gpu_name": "NVIDIA GeForce RTX 5080",
        "gpu_count": 1,
        "gpu_memory_total_mb": 16303.0,
        "gpu_driver_version": "581.08",
        "cuda_version": "12.8",
        "maeum_version": "",
        "model_name": "",
        "model_variant": "",
        "quantization": ""
      },
      "model_info": {},
      "notes": {
        "benchmark_type": "coqa_simple",
        "description": "Small CoQA-style conversational QA benchmark."
      },
      "raw_latencies": []
    },
    {
      "benchmark_id": "kobest",
      "benchmark_name": "KoBEST",
      "category": "korean",
      "mode": "auto",
      "timestamp": "20251202_150910",
      "duration_s": 171.1759901046753,
      "num_samples": 100,
      "success_count": 100,
      "error_count": 0,
      "latency": {
        "avg_ms": 1637.4567949934863,
        "p50_ms": 1810.198749997653,
        "p90_ms": 1991.7348900111392,
        "p95_ms": 2006.4218004234135,
        "p99_ms": 2021.1087108356878,
        "min_ms": 550.1514999195933,
        "max_ms": 2036.4251001738012,
        "std_ms": 0.0,
        "count": 100
      },
      "power": {
        "power_avg_w": 189.51618236074307,
        "power_max_w": 217.45,
        "power_min_w": null,
        "gpu_util_avg": 58.149867374005304,
        "gpu_util_max": null,
        "gpu_mem_avg_mb": null,
        "gpu_mem_peak_mb": 5065.8671875,
        "gpu_temp_avg_c": null,
        "gpu_temp_max_c": 59.0,
        "cpu_util_avg": 10.004973474801067,
        "cpu_util_max": null,
        "cpu_mem_avg_mb": null,
        "cpu_mem_peak_mb": 13186.1875
      },
      "accuracy": {
        "accuracy": 0.93,
        "f1": 0.0337576207455063,
        "em": 0.93,
        "precision": null,
        "recall": null,
        "extra": {
          "num_samples": 100,
          "dataset_status": "official_dataset",
          "dataset_name": "skt/kobest_v1"
        }
      },
      "efficiency": {
        "perf_per_watt": 0.0030941650817405855,
        "latency_per_watt": 310324.5605678234,
        "tokens_per_second": null,
        "tokens_per_watt": null
      },
      "config": {
        "suite_name": "korean",
        "benchmark_name": "kobest",
        "task_name": "KoBEST",
        "concurrency": 1,
        "num_requests": 100,
        "duration_s": null,
        "host": "localhost",
        "port": 12345,
        "endpoint": "/generate/simple",
        "mode": "auto",
        "max_tokens": 256,
        "temperature": 0.7,
        "model_name": null,
        "model_variant": null,
        "quantization": null,
        "compression_techniques": null,
        "context_window": null,
        "run_id": "731ff8ba-1eeb-4909-b823-61a831255b42"
      },
      "system_info": {
        "os_system": "Windows",
        "os_release": "10",
        "os_version": "10.0.26100",
        "hostname": "DESKTOP-0K2OI03",
        "python_version": "3.10.10",
        "python_implementation": "CPython",
        "cpu_name": "AMD64 Family 26 Model 68 Stepping 0, AuthenticAMD",
        "cpu_cores": 8,
        "cpu_threads": 16,
        "cpu_freq_mhz": 4700.0,
        "memory_total_gb": 31.15,
        "memory_available_gb": 19.11,
        "gpu_name": "NVIDIA GeForce RTX 5080",
        "gpu_count": 1,
        "gpu_memory_total_mb": 16303.0,
        "gpu_driver_version": "581.08",
        "cuda_version": "12.8",
        "maeum_version": "",
        "model_name": "",
        "model_variant": "",
        "quantization": ""
      },
      "model_info": {},
      "notes": {
        "status": "official_dataset",
        "benchmark_type": "kobest",
        "dataset": "skt/kobest_v1"
      },
      "raw_latencies": []
    },
    {
      "benchmark_id": "kobest",
      "benchmark_name": "KoBEST",
      "category": "korean",
      "mode": "balanced",
      "timestamp": "20251202_150910",
      "duration_s": 167.87558722496033,
      "num_samples": 100,
      "success_count": 100,
      "error_count": 0,
      "latency": {
        "avg_ms": 1639.4940839963965,
        "p50_ms": 1746.3959000306204,
        "p90_ms": 1984.2264100676402,
        "p95_ms": 2001.5632084640674,
        "p99_ms": 2018.9000068604946,
        "min_ms": 875.5845001433045,
        "max_ms": 2022.5736000575125,
        "std_ms": 0.0,
        "count": 100
      },
      "power": {
        "power_avg_w": 189.71332493368718,
        "power_max_w": 217.222,
        "power_min_w": null,
        "gpu_util_avg": 54.92042440318303,
        "gpu_util_max": null,
        "gpu_mem_avg_mb": null,
        "gpu_mem_peak_mb": 5083.6796875,
        "gpu_temp_avg_c": null,
        "gpu_temp_max_c": 58.0,
        "cpu_util_avg": 9.673342175066322,
        "cpu_util_max": null,
        "cpu_mem_avg_mb": null,
        "cpu_mem_peak_mb": 13144.12109375
      },
      "accuracy": {
        "accuracy": 0.91,
        "f1": 0.029307073534893563,
        "em": 0.91,
        "precision": null,
        "recall": null,
        "extra": {
          "num_samples": 100,
          "dataset_status": "official_dataset",
          "dataset_name": "skt/kobest_v1"
        }
      },
      "efficiency": {
        "perf_per_watt": 0.0031519184544272455,
        "latency_per_watt": 311033.8738840662,
        "tokens_per_second": null,
        "tokens_per_watt": null
      },
      "config": {
        "suite_name": "korean",
        "benchmark_name": "kobest",
        "task_name": "KoBEST",
        "concurrency": 1,
        "num_requests": 100,
        "duration_s": null,
        "host": "localhost",
        "port": 12345,
        "endpoint": "/generate/simple",
        "mode": "balanced",
        "max_tokens": 256,
        "temperature": 0.7,
        "model_name": null,
        "model_variant": null,
        "quantization": null,
        "compression_techniques": null,
        "context_window": null,
        "run_id": "a42bb8d7-4f1a-4195-a5b8-305e8bc4abb3"
      },
      "system_info": {
        "os_system": "Windows",
        "os_release": "10",
        "os_version": "10.0.26100",
        "hostname": "DESKTOP-0K2OI03",
        "python_version": "3.10.10",
        "python_implementation": "CPython",
        "cpu_name": "AMD64 Family 26 Model 68 Stepping 0, AuthenticAMD",
        "cpu_cores": 8,
        "cpu_threads": 16,
        "cpu_freq_mhz": 4700.0,
        "memory_total_gb": 31.15,
        "memory_available_gb": 19.11,
        "gpu_name": "NVIDIA GeForce RTX 5080",
        "gpu_count": 1,
        "gpu_memory_total_mb": 16303.0,
        "gpu_driver_version": "581.08",
        "cuda_version": "12.8",
        "maeum_version": "",
        "model_name": "",
        "model_variant": "",
        "quantization": ""
      },
      "model_info": {},
      "notes": {
        "status": "official_dataset",
        "benchmark_type": "kobest",
        "dataset": "skt/kobest_v1"
      },
      "raw_latencies": []
    },
    {
      "benchmark_id": "kobest",
      "benchmark_name": "KoBEST",
      "category": "korean",
      "mode": "fast",
      "timestamp": "20251202_150910",
      "duration_s": 164.68408751487732,
      "num_samples": 100,
      "success_count": 100,
      "error_count": 0,
      "latency": {
        "avg_ms": 1608.5489959921688,
        "p50_ms": 1682.3725999565795,
        "p90_ms": 1975.386569951661,
        "p95_ms": 1989.9571624782402,
        "p99_ms": 2004.5277550048195,
        "min_ms": 758.4926998242736,
        "max_ms": 2019.8286999948323,
        "std_ms": 0.0,
        "count": 100
      },
      "power": {
        "power_avg_w": 189.40278184281885,
        "power_max_w": 219.369,
        "power_min_w": null,
        "gpu_util_avg": 62.74390243902439,
        "gpu_util_max": null,
        "gpu_mem_avg_mb": null,
        "gpu_mem_peak_mb": 5053.6640625,
        "gpu_temp_avg_c": null,
        "gpu_temp_max_c": 58.0,
        "cpu_util_avg": 9.164363143631435,
        "cpu_util_max": null,
        "cpu_mem_avg_mb": null,
        "cpu_mem_peak_mb": 13137.5234375
      },
      "accuracy": {
        "accuracy": 0.94,
        "f1": 0.031154487046147348,
        "em": 0.94,
        "precision": null,
        "recall": null,
        "extra": {
          "num_samples": 100,
          "dataset_status": "official_dataset",
          "dataset_name": "skt/kobest_v1"
        }
      },
      "efficiency": {
        "perf_per_watt": 0.003217470967716159,
        "latency_per_watt": 304663.65457139007,
        "tokens_per_second": null,
        "tokens_per_watt": null
      },
      "config": {
        "suite_name": "korean",
        "benchmark_name": "kobest",
        "task_name": "KoBEST",
        "concurrency": 1,
        "num_requests": 100,
        "duration_s": null,
        "host": "localhost",
        "port": 12345,
        "endpoint": "/generate/simple",
        "mode": "fast",
        "max_tokens": 256,
        "temperature": 0.7,
        "model_name": null,
        "model_variant": null,
        "quantization": null,
        "compression_techniques": null,
        "context_window": null,
        "run_id": "b819603c-193a-4648-ba7a-a75a2922f708"
      },
      "system_info": {
        "os_system": "Windows",
        "os_release": "10",
        "os_version": "10.0.26100",
        "hostname": "DESKTOP-0K2OI03",
        "python_version": "3.10.10",
        "python_implementation": "CPython",
        "cpu_name": "AMD64 Family 26 Model 68 Stepping 0, AuthenticAMD",
        "cpu_cores": 8,
        "cpu_threads": 16,
        "cpu_freq_mhz": 4700.0,
        "memory_total_gb": 31.15,
        "memory_available_gb": 19.11,
        "gpu_name": "NVIDIA GeForce RTX 5080",
        "gpu_count": 1,
        "gpu_memory_total_mb": 16303.0,
        "gpu_driver_version": "581.08",
        "cuda_version": "12.8",
        "maeum_version": "",
        "model_name": "",
        "model_variant": "",
        "quantization": ""
      },
      "model_info": {},
      "notes": {
        "status": "official_dataset",
        "benchmark_type": "kobest",
        "dataset": "skt/kobest_v1"
      },
      "raw_latencies": []
    },
    {
      "benchmark_id": "kobest",
      "benchmark_name": "KoBEST",
      "category": "korean",
      "mode": "quality",
      "timestamp": "20251202_150910",
      "duration_s": 165.15519404411316,
      "num_samples": 100,
      "success_count": 100,
      "error_count": 0,
      "latency": {
        "avg_ms": 1610.8086970145814,
        "p50_ms": 1676.5583999222144,
        "p90_ms": 1997.0637700986117,
        "p95_ms": 2024.6375549875665,
        "p99_ms": 2052.2113398765214,
        "min_ms": 779.5794000849128,
        "max_ms": 2056.927700061351,
        "std_ms": 0.0,
        "count": 100
      },
      "power": {
        "power_avg_w": 188.9179319865314,
        "power_max_w": 216.658,
        "power_min_w": null,
        "gpu_util_avg": 55.2,
        "gpu_util_max": null,
        "gpu_mem_avg_mb": null,
        "gpu_mem_peak_mb": 5063.1171875,
        "gpu_temp_avg_c": null,
        "gpu_temp_max_c": 58.0,
        "cpu_util_avg": 11.277845117845112,
        "cpu_util_max": null,
        "cpu_mem_avg_mb": null,
        "cpu_mem_peak_mb": 13183.36328125
      },
      "accuracy": {
        "accuracy": 0.92,
        "f1": 0.03160947740040135,
        "em": 0.92,
        "precision": null,
        "recall": null,
        "extra": {
          "num_samples": 100,
          "dataset_status": "official_dataset",
          "dataset_name": "skt/kobest_v1"
        }
      },
      "efficiency": {
        "perf_per_watt": 0.003217681475642778,
        "latency_per_watt": 304310.647865914,
        "tokens_per_second": null,
        "tokens_per_watt": null
      },
      "config": {
        "suite_name": "korean",
        "benchmark_name": "kobest",
        "task_name": "KoBEST",
        "concurrency": 1,
        "num_requests": 100,
        "duration_s": null,
        "host": "localhost",
        "port": 12345,
        "endpoint": "/generate/simple",
        "mode": "quality",
        "max_tokens": 256,
        "temperature": 0.7,
        "model_name": null,
        "model_variant": null,
        "quantization": null,
        "compression_techniques": null,
        "context_window": null,
        "run_id": "5f9637da-2941-4e01-9e90-205edced2251"
      },
      "system_info": {
        "os_system": "Windows",
        "os_release": "10",
        "os_version": "10.0.26100",
        "hostname": "DESKTOP-0K2OI03",
        "python_version": "3.10.10",
        "python_implementation": "CPython",
        "cpu_name": "AMD64 Family 26 Model 68 Stepping 0, AuthenticAMD",
        "cpu_cores": 8,
        "cpu_threads": 16,
        "cpu_freq_mhz": 4700.0,
        "memory_total_gb": 31.15,
        "memory_available_gb": 19.11,
        "gpu_name": "NVIDIA GeForce RTX 5080",
        "gpu_count": 1,
        "gpu_memory_total_mb": 16303.0,
        "gpu_driver_version": "581.08",
        "cuda_version": "12.8",
        "maeum_version": "",
        "model_name": "",
        "model_variant": "",
        "quantization": ""
      },
      "model_info": {},
      "notes": {
        "status": "official_dataset",
        "benchmark_type": "kobest",
        "dataset": "skt/kobest_v1"
      },
      "raw_latencies": []
    },
    {
      "benchmark_id": "klue",
      "benchmark_name": "KLUE",
      "category": "korean",
      "mode": "auto",
      "timestamp": "20251202_150910",
      "duration_s": 174.01120114326477,
      "num_samples": 100,
      "success_count": 100,
      "error_count": 0,
      "latency": {
        "avg_ms": 1633.1259550037794,
        "p50_ms": 1919.3095499649644,
        "p90_ms": 1944.4455701159313,
        "p95_ms": 1974.47355705197,
        "p99_ms": 2004.5015439880085,
        "min_ms": 270.14659997075796,
        "max_ms": 2111.2575998995453,
        "std_ms": 0.0,
        "count": 100
      },
      "power": {
        "power_avg_w": 188.18951069518727,
        "power_max_w": 216.401,
        "power_min_w": null,
        "gpu_util_avg": 56.711229946524064,
        "gpu_util_max": null,
        "gpu_mem_avg_mb": null,
        "gpu_mem_peak_mb": 5066.4921875,
        "gpu_temp_avg_c": null,
        "gpu_temp_max_c": 59.0,
        "cpu_util_avg": 9.35454545454546,
        "cpu_util_max": null,
        "cpu_mem_avg_mb": null,
        "cpu_mem_peak_mb": 13218.65625
      },
      "accuracy": {
        "accuracy": 0.46,
        "f1": 0.012135900917389758,
        "em": 0.46,
        "precision": null,
        "recall": null,
        "extra": {
          "num_samples": 100,
          "dataset_status": "official_dataset",
          "dataset_name": "klue"
        }
      },
      "efficiency": {
        "perf_per_watt": 0.0030641437408469472,
        "latency_per_watt": 307337.17437577166,
        "tokens_per_second": null,
        "tokens_per_watt": null
      },
      "config": {
        "suite_name": "korean",
        "benchmark_name": "klue",
        "task_name": "KLUE",
        "concurrency": 1,
        "num_requests": 100,
        "duration_s": null,
        "host": "localhost",
        "port": 12345,
        "endpoint": "/generate/simple",
        "mode": "auto",
        "max_tokens": 256,
        "temperature": 0.7,
        "model_name": null,
        "model_variant": null,
        "quantization": null,
        "compression_techniques": null,
        "context_window": null,
        "run_id": "21ed0bea-90b9-4e73-beb3-bb2dc204b46a"
      },
      "system_info": {
        "os_system": "Windows",
        "os_release": "10",
        "os_version": "10.0.26100",
        "hostname": "DESKTOP-0K2OI03",
        "python_version": "3.10.10",
        "python_implementation": "CPython",
        "cpu_name": "AMD64 Family 26 Model 68 Stepping 0, AuthenticAMD",
        "cpu_cores": 8,
        "cpu_threads": 16,
        "cpu_freq_mhz": 4700.0,
        "memory_total_gb": 31.15,
        "memory_available_gb": 19.11,
        "gpu_name": "NVIDIA GeForce RTX 5080",
        "gpu_count": 1,
        "gpu_memory_total_mb": 16303.0,
        "gpu_driver_version": "581.08",
        "cuda_version": "12.8",
        "maeum_version": "",
        "model_name": "",
        "model_variant": "",
        "quantization": ""
      },
      "model_info": {},
      "notes": {
        "status": "official_dataset",
        "benchmark_type": "klue_full",
        "dataset": "klue"
      },
      "raw_latencies": []
    },
    {
      "benchmark_id": "klue",
      "benchmark_name": "KLUE",
      "category": "korean",
      "mode": "balanced",
      "timestamp": "20251202_150910",
      "duration_s": 157.06819248199463,
      "num_samples": 100,
      "success_count": 100,
      "error_count": 0,
      "latency": {
        "avg_ms": 1499.162079996895,
        "p50_ms": 1862.803400028497,
        "p90_ms": 1942.5576598616317,
        "p95_ms": 1954.170238407096,
        "p99_ms": 1965.78281695256,
        "min_ms": 264.14179988205433,
        "max_ms": 1975.3875001333654,
        "std_ms": 0.0,
        "count": 100
      },
      "power": {
        "power_avg_w": 187.01087746170626,
        "power_max_w": 215.859,
        "power_min_w": null,
        "gpu_util_avg": 57.36396790663749,
        "gpu_util_max": null,
        "gpu_mem_avg_mb": null,
        "gpu_mem_peak_mb": 5029.0234375,
        "gpu_temp_avg_c": null,
        "gpu_temp_max_c": 58.0,
        "cpu_util_avg": 8.050401167031376,
        "cpu_util_max": null,
        "cpu_mem_avg_mb": null,
        "cpu_mem_peak_mb": 13125.71484375
      },
      "accuracy": {
        "accuracy": 0.55,
        "f1": 0.014717051050881298,
        "em": 0.55,
        "precision": null,
        "recall": null,
        "extra": {
          "num_samples": 100,
          "dataset_status": "official_dataset",
          "dataset_name": "klue"
        }
      },
      "efficiency": {
        "perf_per_watt": 0.0034173153136661956,
        "latency_per_watt": 280359.616037536,
        "tokens_per_second": null,
        "tokens_per_watt": null
      },
      "config": {
        "suite_name": "korean",
        "benchmark_name": "klue",
        "task_name": "KLUE",
        "concurrency": 1,
        "num_requests": 100,
        "duration_s": null,
        "host": "localhost",
        "port": 12345,
        "endpoint": "/generate/simple",
        "mode": "balanced",
        "max_tokens": 256,
        "temperature": 0.7,
        "model_name": null,
        "model_variant": null,
        "quantization": null,
        "compression_techniques": null,
        "context_window": null,
        "run_id": "06940ac3-9db0-4b44-b32f-f1a7d4d87245"
      },
      "system_info": {
        "os_system": "Windows",
        "os_release": "10",
        "os_version": "10.0.26100",
        "hostname": "DESKTOP-0K2OI03",
        "python_version": "3.10.10",
        "python_implementation": "CPython",
        "cpu_name": "AMD64 Family 26 Model 68 Stepping 0, AuthenticAMD",
        "cpu_cores": 8,
        "cpu_threads": 16,
        "cpu_freq_mhz": 4700.0,
        "memory_total_gb": 31.15,
        "memory_available_gb": 19.11,
        "gpu_name": "NVIDIA GeForce RTX 5080",
        "gpu_count": 1,
        "gpu_memory_total_mb": 16303.0,
        "gpu_driver_version": "581.08",
        "cuda_version": "12.8",
        "maeum_version": "",
        "model_name": "",
        "model_variant": "",
        "quantization": ""
      },
      "model_info": {},
      "notes": {
        "status": "official_dataset",
        "benchmark_type": "klue_full",
        "dataset": "klue"
      },
      "raw_latencies": []
    },
    {
      "benchmark_id": "klue",
      "benchmark_name": "KLUE",
      "category": "korean",
      "mode": "fast",
      "timestamp": "20251202_150910",
      "duration_s": 154.96700811386108,
      "num_samples": 100,
      "success_count": 100,
      "error_count": 0,
      "latency": {
        "avg_ms": 1479.1791839920916,
        "p50_ms": 1907.904400024563,
        "p90_ms": 1942.6798198837787,
        "p95_ms": 1955.627390925074,
        "p99_ms": 1968.5749619663693,
        "min_ms": 262.3079000040889,
        "max_ms": 1974.3824999313802,
        "std_ms": 0.0,
        "count": 100
      },
      "power": {
        "power_avg_w": 184.81249556213066,
        "power_max_w": 215.074,
        "power_min_w": null,
        "gpu_util_avg": 58.164940828402365,
        "gpu_util_max": null,
        "gpu_mem_avg_mb": null,
        "gpu_mem_peak_mb": 5053.9765625,
        "gpu_temp_avg_c": null,
        "gpu_temp_max_c": 58.0,
        "cpu_util_avg": 8.330991124260372,
        "cpu_util_max": null,
        "cpu_mem_avg_mb": null,
        "cpu_mem_peak_mb": 13112.81640625
      },
      "accuracy": {
        "accuracy": 0.5,
        "f1": 0.013633179470903986,
        "em": 0.5,
        "precision": null,
        "recall": null,
        "extra": {
          "num_samples": 100,
          "dataset_status": "official_dataset",
          "dataset_name": "klue"
        }
      },
      "efficiency": {
        "perf_per_watt": 0.0035055504299659314,
        "latency_per_watt": 273370.79637713445,
        "tokens_per_second": null,
        "tokens_per_watt": null
      },
      "config": {
        "suite_name": "korean",
        "benchmark_name": "klue",
        "task_name": "KLUE",
        "concurrency": 1,
        "num_requests": 100,
        "duration_s": null,
        "host": "localhost",
        "port": 12345,
        "endpoint": "/generate/simple",
        "mode": "fast",
        "max_tokens": 256,
        "temperature": 0.7,
        "model_name": null,
        "model_variant": null,
        "quantization": null,
        "compression_techniques": null,
        "context_window": null,
        "run_id": "ca33d451-523a-44fc-b74f-5177295947e9"
      },
      "system_info": {
        "os_system": "Windows",
        "os_release": "10",
        "os_version": "10.0.26100",
        "hostname": "DESKTOP-0K2OI03",
        "python_version": "3.10.10",
        "python_implementation": "CPython",
        "cpu_name": "AMD64 Family 26 Model 68 Stepping 0, AuthenticAMD",
        "cpu_cores": 8,
        "cpu_threads": 16,
        "cpu_freq_mhz": 4700.0,
        "memory_total_gb": 31.15,
        "memory_available_gb": 19.11,
        "gpu_name": "NVIDIA GeForce RTX 5080",
        "gpu_count": 1,
        "gpu_memory_total_mb": 16303.0,
        "gpu_driver_version": "581.08",
        "cuda_version": "12.8",
        "maeum_version": "",
        "model_name": "",
        "model_variant": "",
        "quantization": ""
      },
      "model_info": {},
      "notes": {
        "status": "official_dataset",
        "benchmark_type": "klue_full",
        "dataset": "klue"
      },
      "raw_latencies": []
    },
    {
      "benchmark_id": "klue",
      "benchmark_name": "KLUE",
      "category": "korean",
      "mode": "quality",
      "timestamp": "20251202_150910",
      "duration_s": 167.6658284664154,
      "num_samples": 99,
      "success_count": 99,
      "error_count": 0,
      "latency": {
        "avg_ms": 1605.5757489940152,
        "p50_ms": 1909.1714500682428,
        "p90_ms": 1939.3810499459505,
        "p95_ms": 1947.2657564957626,
        "p99_ms": 1955.1504630455747,
        "min_ms": 255.02309994772077,
        "max_ms": 1971.9173999037594,
        "std_ms": 0.0,
        "count": 99
      },
      "power": {
        "power_avg_w": 188.70942428376554,
        "power_max_w": 215.418,
        "power_min_w": null,
        "gpu_util_avg": 63.1118690313779,
        "gpu_util_max": null,
        "gpu_mem_avg_mb": null,
        "gpu_mem_peak_mb": 5024.6484375,
        "gpu_temp_avg_c": null,
        "gpu_temp_max_c": 59.0,
        "cpu_util_avg": 8.040654843110508,
        "cpu_util_max": null,
        "cpu_mem_avg_mb": null,
        "cpu_mem_peak_mb": 13098.43359375
      },
      "accuracy": {
        "accuracy": 0.43,
        "f1": 0.011401575405046155,
        "em": 0.43,
        "precision": null,
        "recall": null,
        "extra": {
          "num_samples": 100,
          "dataset_status": "official_dataset",
          "dataset_name": "klue"
        }
      },
      "efficiency": {
        "perf_per_watt": 0.0031721065361969038,
        "latency_per_watt": 302987.2752366362,
        "tokens_per_second": null,
        "tokens_per_watt": null
      },
      "config": {
        "suite_name": "korean",
        "benchmark_name": "klue",
        "task_name": "KLUE",
        "concurrency": 1,
        "num_requests": 100,
        "duration_s": null,
        "host": "localhost",
        "port": 12345,
        "endpoint": "/generate/simple",
        "mode": "quality",
        "max_tokens": 256,
        "temperature": 0.7,
        "model_name": null,
        "model_variant": null,
        "quantization": null,
        "compression_techniques": null,
        "context_window": null,
        "run_id": "55527094-93fe-4ce2-9b02-fa7144ad0dd6"
      },
      "system_info": {
        "os_system": "Windows",
        "os_release": "10",
        "os_version": "10.0.26100",
        "hostname": "DESKTOP-0K2OI03",
        "python_version": "3.10.10",
        "python_implementation": "CPython",
        "cpu_name": "AMD64 Family 26 Model 68 Stepping 0, AuthenticAMD",
        "cpu_cores": 8,
        "cpu_threads": 16,
        "cpu_freq_mhz": 4700.0,
        "memory_total_gb": 31.15,
        "memory_available_gb": 19.11,
        "gpu_name": "NVIDIA GeForce RTX 5080",
        "gpu_count": 1,
        "gpu_memory_total_mb": 16303.0,
        "gpu_driver_version": "581.08",
        "cuda_version": "12.8",
        "maeum_version": "",
        "model_name": "",
        "model_variant": "",
        "quantization": ""
      },
      "model_info": {},
      "notes": {
        "status": "official_dataset",
        "benchmark_type": "klue_full",
        "dataset": "klue"
      },
      "raw_latencies": []
    },
    {
      "benchmark_id": "kmmlu",
      "benchmark_name": "KMMLU",
      "category": "korean",
      "mode": "auto",
      "timestamp": "20251202_150910",
      "duration_s": 170.14414024353027,
      "num_samples": 100,
      "success_count": 100,
      "error_count": 0,
      "latency": {
        "avg_ms": 1654.049177991692,
        "p50_ms": 1616.7898500571027,
        "p90_ms": 1918.0531700141728,
        "p95_ms": 1938.0604515131563,
        "p99_ms": 1958.0677330121398,
        "min_ms": 999.7175999451429,
        "max_ms": 1973.4753998927772,
        "std_ms": 0.0,
        "count": 100
      },
      "power": {
        "power_avg_w": 188.49211896893584,
        "power_max_w": 214.887,
        "power_min_w": null,
        "gpu_util_avg": 59.34765366820886,
        "gpu_util_max": null,
        "gpu_mem_avg_mb": null,
        "gpu_mem_peak_mb": 5058.1953125,
        "gpu_temp_avg_c": null,
        "gpu_temp_max_c": 58.0,
        "cpu_util_avg": 8.603569068076684,
        "cpu_util_max": null,
        "cpu_mem_avg_mb": null,
        "cpu_mem_peak_mb": 13186.3515625
      },
      "accuracy": {
        "accuracy": 0.92,
        "f1": 0.92,
        "em": 0.92,
        "precision": null,
        "recall": null,
        "extra": {
          "num_samples": 100,
          "dataset_status": "builtin_samples",
          "dataset_name": "HAERAE-HUB/KMMLU"
        }
      },
      "efficiency": {
        "perf_per_watt": 0.0031296537696898674,
        "latency_per_watt": 311775.2344384805,
        "tokens_per_second": null,
        "tokens_per_watt": null
      },
      "config": {
        "suite_name": "korean",
        "benchmark_name": "kmmlu",
        "task_name": "KMMLU",
        "concurrency": 1,
        "num_requests": 100,
        "duration_s": null,
        "host": "localhost",
        "port": 12345,
        "endpoint": "/generate/simple",
        "mode": "auto",
        "max_tokens": 256,
        "temperature": 0.7,
        "model_name": null,
        "model_variant": null,
        "quantization": null,
        "compression_techniques": null,
        "context_window": null,
        "run_id": "71750a01-1996-4569-b77b-f1d1a369ddde"
      },
      "system_info": {
        "os_system": "Windows",
        "os_release": "10",
        "os_version": "10.0.26100",
        "hostname": "DESKTOP-0K2OI03",
        "python_version": "3.10.10",
        "python_implementation": "CPython",
        "cpu_name": "AMD64 Family 26 Model 68 Stepping 0, AuthenticAMD",
        "cpu_cores": 8,
        "cpu_threads": 16,
        "cpu_freq_mhz": 4700.0,
        "memory_total_gb": 31.15,
        "memory_available_gb": 19.11,
        "gpu_name": "NVIDIA GeForce RTX 5080",
        "gpu_count": 1,
        "gpu_memory_total_mb": 16303.0,
        "gpu_driver_version": "581.08",
        "cuda_version": "12.8",
        "maeum_version": "",
        "model_name": "",
        "model_variant": "",
        "quantization": ""
      },
      "model_info": {},
      "notes": {
        "status": "builtin_samples",
        "benchmark_type": "kmmlu",
        "dataset": "HAERAE-HUB/KMMLU"
      },
      "raw_latencies": []
    },
    {
      "benchmark_id": "kmmlu",
      "benchmark_name": "KMMLU",
      "category": "korean",
      "mode": "balanced",
      "timestamp": "20251202_150910",
      "duration_s": 167.56397199630737,
      "num_samples": 100,
      "success_count": 100,
      "error_count": 0,
      "latency": {
        "avg_ms": 1644.792694998905,
        "p50_ms": 1701.8761499784887,
        "p90_ms": 1918.842670088634,
        "p95_ms": 1930.1800701010507,
        "p99_ms": 1941.5174701134674,
        "min_ms": 972.0534000080079,
        "max_ms": 1945.7318999338895,
        "std_ms": 0.0,
        "count": 100
      },
      "power": {
        "power_avg_w": 187.8252712201593,
        "power_max_w": 214.683,
        "power_min_w": null,
        "gpu_util_avg": 60.786472148541115,
        "gpu_util_max": null,
        "gpu_mem_avg_mb": null,
        "gpu_mem_peak_mb": 5042.1328125,
        "gpu_temp_avg_c": null,
        "gpu_temp_max_c": 58.0,
        "cpu_util_avg": 7.994297082228133,
        "cpu_util_max": null,
        "cpu_mem_avg_mb": null,
        "cpu_mem_peak_mb": 13130.16796875
      },
      "accuracy": {
        "accuracy": 0.88,
        "f1": 0.88,
        "em": 0.88,
        "precision": null,
        "recall": null,
        "extra": {
          "num_samples": 100,
          "dataset_status": "builtin_samples",
          "dataset_name": "HAERAE-HUB/KMMLU"
        }
      },
      "efficiency": {
        "perf_per_watt": 0.0031897328042368644,
        "latency_per_watt": 308933.6340391061,
        "tokens_per_second": null,
        "tokens_per_watt": null
      },
      "config": {
        "suite_name": "korean",
        "benchmark_name": "kmmlu",
        "task_name": "KMMLU",
        "concurrency": 1,
        "num_requests": 100,
        "duration_s": null,
        "host": "localhost",
        "port": 12345,
        "endpoint": "/generate/simple",
        "mode": "balanced",
        "max_tokens": 256,
        "temperature": 0.7,
        "model_name": null,
        "model_variant": null,
        "quantization": null,
        "compression_techniques": null,
        "context_window": null,
        "run_id": "8238daaf-c2c5-4e46-ab90-4060433ab3de"
      },
      "system_info": {
        "os_system": "Windows",
        "os_release": "10",
        "os_version": "10.0.26100",
        "hostname": "DESKTOP-0K2OI03",
        "python_version": "3.10.10",
        "python_implementation": "CPython",
        "cpu_name": "AMD64 Family 26 Model 68 Stepping 0, AuthenticAMD",
        "cpu_cores": 8,
        "cpu_threads": 16,
        "cpu_freq_mhz": 4700.0,
        "memory_total_gb": 31.15,
        "memory_available_gb": 19.11,
        "gpu_name": "NVIDIA GeForce RTX 5080",
        "gpu_count": 1,
        "gpu_memory_total_mb": 16303.0,
        "gpu_driver_version": "581.08",
        "cuda_version": "12.8",
        "maeum_version": "",
        "model_name": "",
        "model_variant": "",
        "quantization": ""
      },
      "model_info": {},
      "notes": {
        "status": "builtin_samples",
        "benchmark_type": "kmmlu",
        "dataset": "HAERAE-HUB/KMMLU"
      },
      "raw_latencies": []
    },
    {
      "benchmark_id": "kmmlu",
      "benchmark_name": "KMMLU",
      "category": "korean",
      "mode": "fast",
      "timestamp": "20251202_150910",
      "duration_s": 174.62496495246887,
      "num_samples": 100,
      "success_count": 100,
      "error_count": 0,
      "latency": {
        "avg_ms": 1714.7478059958667,
        "p50_ms": 1796.8239999609068,
        "p90_ms": 1918.0742000695318,
        "p95_ms": 1925.860940089915,
        "p99_ms": 1933.647680110298,
        "min_ms": 1099.340199958533,
        "max_ms": 1935.27920008637,
        "std_ms": 0.0,
        "count": 100
      },
      "power": {
        "power_avg_w": 189.5852993630568,
        "power_max_w": 215.11,
        "power_min_w": null,
        "gpu_util_avg": 57.912738853503186,
        "gpu_util_max": null,
        "gpu_mem_avg_mb": null,
        "gpu_mem_peak_mb": 5042.1328125,
        "gpu_temp_avg_c": null,
        "gpu_temp_max_c": 58.0,
        "cpu_util_avg": 8.021082802547783,
        "cpu_util_max": null,
        "cpu_mem_avg_mb": null,
        "cpu_mem_peak_mb": 13123.82421875
      },
      "accuracy": {
        "accuracy": 0.9,
        "f1": 0.9,
        "em": 0.9,
        "precision": null,
        "recall": null,
        "extra": {
          "num_samples": 100,
          "dataset_status": "builtin_samples",
          "dataset_name": "HAERAE-HUB/KMMLU"
        }
      },
      "efficiency": {
        "perf_per_watt": 0.003031225077887199,
        "latency_per_watt": 325090.9761318712,
        "tokens_per_second": null,
        "tokens_per_watt": null
      },
      "config": {
        "suite_name": "korean",
        "benchmark_name": "kmmlu",
        "task_name": "KMMLU",
        "concurrency": 1,
        "num_requests": 100,
        "duration_s": null,
        "host": "localhost",
        "port": 12345,
        "endpoint": "/generate/simple",
        "mode": "fast",
        "max_tokens": 256,
        "temperature": 0.7,
        "model_name": null,
        "model_variant": null,
        "quantization": null,
        "compression_techniques": null,
        "context_window": null,
        "run_id": "6580e5da-ebb1-42fe-83d0-34fcbca2b2cb"
      },
      "system_info": {
        "os_system": "Windows",
        "os_release": "10",
        "os_version": "10.0.26100",
        "hostname": "DESKTOP-0K2OI03",
        "python_version": "3.10.10",
        "python_implementation": "CPython",
        "cpu_name": "AMD64 Family 26 Model 68 Stepping 0, AuthenticAMD",
        "cpu_cores": 8,
        "cpu_threads": 16,
        "cpu_freq_mhz": 4700.0,
        "memory_total_gb": 31.15,
        "memory_available_gb": 19.11,
        "gpu_name": "NVIDIA GeForce RTX 5080",
        "gpu_count": 1,
        "gpu_memory_total_mb": 16303.0,
        "gpu_driver_version": "581.08",
        "cuda_version": "12.8",
        "maeum_version": "",
        "model_name": "",
        "model_variant": "",
        "quantization": ""
      },
      "model_info": {},
      "notes": {
        "status": "builtin_samples",
        "benchmark_type": "kmmlu",
        "dataset": "HAERAE-HUB/KMMLU"
      },
      "raw_latencies": []
    },
    {
      "benchmark_id": "kmmlu",
      "benchmark_name": "KMMLU",
      "category": "korean",
      "mode": "quality",
      "timestamp": "20251202_150910",
      "duration_s": 165.56275749206543,
      "num_samples": 100,
      "success_count": 100,
      "error_count": 0,
      "latency": {
        "avg_ms": 1623.3649630099535,
        "p50_ms": 1601.4499000739306,
        "p90_ms": 1909.382260008715,
        "p95_ms": 1919.2607945145573,
        "p99_ms": 1929.1393290203996,
        "min_ms": 1032.2140001226217,
        "max_ms": 1932.1320001035929,
        "std_ms": 0.0,
        "count": 100
      },
      "power": {
        "power_avg_w": 188.11370342972393,
        "power_max_w": 214.684,
        "power_min_w": null,
        "gpu_util_avg": 57.5527908540686,
        "gpu_util_max": null,
        "gpu_mem_avg_mb": null,
        "gpu_mem_peak_mb": 5042.1328125,
        "gpu_temp_avg_c": null,
        "gpu_temp_max_c": 58.0,
        "cpu_util_avg": 8.101479488903829,
        "cpu_util_max": null,
        "cpu_mem_avg_mb": null,
        "cpu_mem_peak_mb": 13125.40234375
      },
      "accuracy": {
        "accuracy": 0.96,
        "f1": 0.96,
        "em": 0.96,
        "precision": null,
        "recall": null,
        "extra": {
          "num_samples": 100,
          "dataset_status": "builtin_samples",
          "dataset_name": "HAERAE-HUB/KMMLU"
        }
      },
      "efficiency": {
        "perf_per_watt": 0.003223333249339288,
        "latency_per_watt": 305377.1952098592,
        "tokens_per_second": null,
        "tokens_per_watt": null
      },
      "config": {
        "suite_name": "korean",
        "benchmark_name": "kmmlu",
        "task_name": "KMMLU",
        "concurrency": 1,
        "num_requests": 100,
        "duration_s": null,
        "host": "localhost",
        "port": 12345,
        "endpoint": "/generate/simple",
        "mode": "quality",
        "max_tokens": 256,
        "temperature": 0.7,
        "model_name": null,
        "model_variant": null,
        "quantization": null,
        "compression_techniques": null,
        "context_window": null,
        "run_id": "f93c8318-bd93-4b3d-8b88-680c0e3c403a"
      },
      "system_info": {
        "os_system": "Windows",
        "os_release": "10",
        "os_version": "10.0.26100",
        "hostname": "DESKTOP-0K2OI03",
        "python_version": "3.10.10",
        "python_implementation": "CPython",
        "cpu_name": "AMD64 Family 26 Model 68 Stepping 0, AuthenticAMD",
        "cpu_cores": 8,
        "cpu_threads": 16,
        "cpu_freq_mhz": 4700.0,
        "memory_total_gb": 31.15,
        "memory_available_gb": 19.11,
        "gpu_name": "NVIDIA GeForce RTX 5080",
        "gpu_count": 1,
        "gpu_memory_total_mb": 16303.0,
        "gpu_driver_version": "581.08",
        "cuda_version": "12.8",
        "maeum_version": "",
        "model_name": "",
        "model_variant": "",
        "quantization": ""
      },
      "model_info": {},
      "notes": {
        "status": "builtin_samples",
        "benchmark_type": "kmmlu",
        "dataset": "HAERAE-HUB/KMMLU"
      },
      "raw_latencies": []
    },
    {
      "benchmark_id": "xnli",
      "benchmark_name": "XNLI",
      "category": "multilingual",
      "mode": "auto",
      "timestamp": "20251202_150910",
      "duration_s": 164.29583549499512,
      "num_samples": 99,
      "success_count": 99,
      "error_count": 0,
      "latency": {
        "avg_ms": 1169.8061650106683,
        "p50_ms": 602.3770499741659,
        "p90_ms": 2168.214870034717,
        "p95_ms": 2200.1232279720716,
        "p99_ms": 2232.031585909426,
        "min_ms": 339.69519985839725,
        "max_ms": 2249.454200034961,
        "std_ms": 0.0,
        "count": 99
      },
      "power": {
        "power_avg_w": 190.52867132216053,
        "power_max_w": 238.664,
        "power_min_w": null,
        "gpu_util_avg": 49.204841713221604,
        "gpu_util_max": null,
        "gpu_mem_avg_mb": null,
        "gpu_mem_peak_mb": 5084.1328125,
        "gpu_temp_avg_c": null,
        "gpu_temp_max_c": 64.0,
        "cpu_util_avg": 7.051675977653645,
        "cpu_util_max": null,
        "cpu_mem_avg_mb": null,
        "cpu_mem_peak_mb": 14852.3828125
      },
      "accuracy": {
        "accuracy": 0.31,
        "f1": 0.31,
        "em": 0.31,
        "precision": null,
        "recall": null,
        "extra": {
          "num_samples": 100,
          "dataset_status": "official_dataset",
          "dataset_name": "facebook/xnli"
        }
      },
      "efficiency": {
        "perf_per_watt": 0.003206210672365157,
        "latency_per_watt": 222881.6143239547,
        "tokens_per_second": null,
        "tokens_per_watt": null
      },
      "config": {
        "suite_name": "multilingual",
        "benchmark_name": "xnli",
        "task_name": "XNLI",
        "concurrency": 1,
        "num_requests": 100,
        "duration_s": null,
        "host": "localhost",
        "port": 12345,
        "endpoint": "/generate/simple",
        "mode": "auto",
        "max_tokens": 256,
        "temperature": 0.7,
        "model_name": null,
        "model_variant": null,
        "quantization": null,
        "compression_techniques": null,
        "context_window": null,
        "run_id": "982bc554-531d-4012-b8a4-8890296ececd"
      },
      "system_info": {
        "os_system": "Windows",
        "os_release": "10",
        "os_version": "10.0.26100",
        "hostname": "DESKTOP-0K2OI03",
        "python_version": "3.10.10",
        "python_implementation": "CPython",
        "cpu_name": "AMD64 Family 26 Model 68 Stepping 0, AuthenticAMD",
        "cpu_cores": 8,
        "cpu_threads": 16,
        "cpu_freq_mhz": 4700.0,
        "memory_total_gb": 31.15,
        "memory_available_gb": 19.11,
        "gpu_name": "NVIDIA GeForce RTX 5080",
        "gpu_count": 1,
        "gpu_memory_total_mb": 16303.0,
        "gpu_driver_version": "581.08",
        "cuda_version": "12.8",
        "maeum_version": "",
        "model_name": "",
        "model_variant": "",
        "quantization": ""
      },
      "model_info": {},
      "notes": {
        "status": "official_dataset",
        "benchmark_type": "xnli",
        "dataset": "facebook/xnli"
      },
      "raw_latencies": []
    },
    {
      "benchmark_id": "xnli",
      "benchmark_name": "XNLI",
      "category": "multilingual",
      "mode": "balanced",
      "timestamp": "20251202_150910",
      "duration_s": 127.10372519493103,
      "num_samples": 100,
      "success_count": 100,
      "error_count": 0,
      "latency": {
        "avg_ms": 1205.8205549954437,
        "p50_ms": 1093.360000057146,
        "p90_ms": 2190.198429906741,
        "p95_ms": 2231.6404169250745,
        "p99_ms": 2273.0824039434087,
        "min_ms": 368.61829995177686,
        "max_ms": 2330.997799988836,
        "std_ms": 0.0,
        "count": 100
      },
      "power": {
        "power_avg_w": 197.95956357078495,
        "power_max_w": 251.007,
        "power_min_w": null,
        "gpu_util_avg": 59.27682596934175,
        "gpu_util_max": null,
        "gpu_mem_avg_mb": null,
        "gpu_mem_peak_mb": 5084.1328125,
        "gpu_temp_avg_c": null,
        "gpu_temp_max_c": 64.0,
        "cpu_util_avg": 7.103606853020754,
        "cpu_util_max": null,
        "cpu_mem_avg_mb": null,
        "cpu_mem_peak_mb": 13304.90625
      },
      "accuracy": {
        "accuracy": 0.35,
        "f1": 0.35,
        "em": 0.35,
        "precision": null,
        "recall": null,
        "extra": {
          "num_samples": 100,
          "dataset_status": "official_dataset",
          "dataset_name": "facebook/xnli"
        }
      },
      "efficiency": {
        "perf_per_watt": 0.003994453432720283,
        "latency_per_watt": 238703.71081157972,
        "tokens_per_second": null,
        "tokens_per_watt": null
      },
      "config": {
        "suite_name": "multilingual",
        "benchmark_name": "xnli",
        "task_name": "XNLI",
        "concurrency": 1,
        "num_requests": 100,
        "duration_s": null,
        "host": "localhost",
        "port": 12345,
        "endpoint": "/generate/simple",
        "mode": "balanced",
        "max_tokens": 256,
        "temperature": 0.7,
        "model_name": null,
        "model_variant": null,
        "quantization": null,
        "compression_techniques": null,
        "context_window": null,
        "run_id": "18d1391f-f884-400f-908b-29cfaa3496b3"
      },
      "system_info": {
        "os_system": "Windows",
        "os_release": "10",
        "os_version": "10.0.26100",
        "hostname": "DESKTOP-0K2OI03",
        "python_version": "3.10.10",
        "python_implementation": "CPython",
        "cpu_name": "AMD64 Family 26 Model 68 Stepping 0, AuthenticAMD",
        "cpu_cores": 8,
        "cpu_threads": 16,
        "cpu_freq_mhz": 4700.0,
        "memory_total_gb": 31.15,
        "memory_available_gb": 19.11,
        "gpu_name": "NVIDIA GeForce RTX 5080",
        "gpu_count": 1,
        "gpu_memory_total_mb": 16303.0,
        "gpu_driver_version": "581.08",
        "cuda_version": "12.8",
        "maeum_version": "",
        "model_name": "",
        "model_variant": "",
        "quantization": ""
      },
      "model_info": {},
      "notes": {
        "status": "official_dataset",
        "benchmark_type": "xnli",
        "dataset": "facebook/xnli"
      },
      "raw_latencies": []
    },
    {
      "benchmark_id": "xnli",
      "benchmark_name": "XNLI",
      "category": "multilingual",
      "mode": "fast",
      "timestamp": "20251202_150910",
      "duration_s": 125.92190861701965,
      "num_samples": 100,
      "success_count": 100,
      "error_count": 0,
      "latency": {
        "avg_ms": 1202.9038439970464,
        "p50_ms": 574.926650035195,
        "p90_ms": 2215.6468599801883,
        "p95_ms": 2248.766372932587,
        "p99_ms": 2281.885885884986,
        "min_ms": 309.92680019699037,
        "max_ms": 2326.652299845591,
        "std_ms": 0.0,
        "count": 100
      },
      "power": {
        "power_avg_w": 197.07580758807595,
        "power_max_w": 240.333,
        "power_min_w": null,
        "gpu_util_avg": 54.44083107497742,
        "gpu_util_max": null,
        "gpu_mem_avg_mb": null,
        "gpu_mem_peak_mb": 5084.1328125,
        "gpu_temp_avg_c": null,
        "gpu_temp_max_c": 64.0,
        "cpu_util_avg": 7.146612466124659,
        "cpu_util_max": null,
        "cpu_mem_avg_mb": null,
        "cpu_mem_peak_mb": 13303.796875
      },
      "accuracy": {
        "accuracy": 0.34,
        "f1": 0.34,
        "em": 0.34,
        "precision": null,
        "recall": null,
        "extra": {
          "num_samples": 100,
          "dataset_status": "official_dataset",
          "dataset_name": "facebook/xnli"
        }
      },
      "efficiency": {
        "perf_per_watt": 0.004049206737073631,
        "latency_per_watt": 237063.24650651883,
        "tokens_per_second": null,
        "tokens_per_watt": null
      },
      "config": {
        "suite_name": "multilingual",
        "benchmark_name": "xnli",
        "task_name": "XNLI",
        "concurrency": 1,
        "num_requests": 100,
        "duration_s": null,
        "host": "localhost",
        "port": 12345,
        "endpoint": "/generate/simple",
        "mode": "fast",
        "max_tokens": 256,
        "temperature": 0.7,
        "model_name": null,
        "model_variant": null,
        "quantization": null,
        "compression_techniques": null,
        "context_window": null,
        "run_id": "bc13ad65-5cac-4fe7-822e-1913dab010ff"
      },
      "system_info": {
        "os_system": "Windows",
        "os_release": "10",
        "os_version": "10.0.26100",
        "hostname": "DESKTOP-0K2OI03",
        "python_version": "3.10.10",
        "python_implementation": "CPython",
        "cpu_name": "AMD64 Family 26 Model 68 Stepping 0, AuthenticAMD",
        "cpu_cores": 8,
        "cpu_threads": 16,
        "cpu_freq_mhz": 4700.0,
        "memory_total_gb": 31.15,
        "memory_available_gb": 19.11,
        "gpu_name": "NVIDIA GeForce RTX 5080",
        "gpu_count": 1,
        "gpu_memory_total_mb": 16303.0,
        "gpu_driver_version": "581.08",
        "cuda_version": "12.8",
        "maeum_version": "",
        "model_name": "",
        "model_variant": "",
        "quantization": ""
      },
      "model_info": {},
      "notes": {
        "status": "official_dataset",
        "benchmark_type": "xnli",
        "dataset": "facebook/xnli"
      },
      "raw_latencies": []
    },
    {
      "benchmark_id": "xnli",
      "benchmark_name": "XNLI",
      "category": "multilingual",
      "mode": "quality",
      "timestamp": "20251202_150910",
      "duration_s": 122.02705144882202,
      "num_samples": 100,
      "success_count": 100,
      "error_count": 0,
      "latency": {
        "avg_ms": 1160.370532993693,
        "p50_ms": 583.482600050047,
        "p90_ms": 2178.3681399188936,
        "p95_ms": 2219.5974625018425,
        "p99_ms": 2260.826785084792,
        "min_ms": 323.30970000475645,
        "max_ms": 2317.4532998818904,
        "std_ms": 0.0,
        "count": 100
      },
      "power": {
        "power_avg_w": 195.33677340823962,
        "power_max_w": 254.075,
        "power_min_w": null,
        "gpu_util_avg": 57.91385767790262,
        "gpu_util_max": null,
        "gpu_mem_avg_mb": null,
        "gpu_mem_peak_mb": 5084.1328125,
        "gpu_temp_avg_c": null,
        "gpu_temp_max_c": 63.0,
        "cpu_util_avg": 7.029119850187273,
        "cpu_util_max": null,
        "cpu_mem_avg_mb": null,
        "cpu_mem_peak_mb": 13305.13671875
      },
      "accuracy": {
        "accuracy": 0.32,
        "f1": 0.32,
        "em": 0.32,
        "precision": null,
        "recall": null,
        "extra": {
          "num_samples": 100,
          "dataset_status": "official_dataset",
          "dataset_name": "facebook/xnli"
        }
      },
      "efficiency": {
        "perf_per_watt": 0.004216234765030343,
        "latency_per_watt": 226663.03587298724,
        "tokens_per_second": null,
        "tokens_per_watt": null
      },
      "config": {
        "suite_name": "multilingual",
        "benchmark_name": "xnli",
        "task_name": "XNLI",
        "concurrency": 1,
        "num_requests": 100,
        "duration_s": null,
        "host": "localhost",
        "port": 12345,
        "endpoint": "/generate/simple",
        "mode": "quality",
        "max_tokens": 256,
        "temperature": 0.7,
        "model_name": null,
        "model_variant": null,
        "quantization": null,
        "compression_techniques": null,
        "context_window": null,
        "run_id": "91a2c863-0587-4fbe-b5fa-77f587687524"
      },
      "system_info": {
        "os_system": "Windows",
        "os_release": "10",
        "os_version": "10.0.26100",
        "hostname": "DESKTOP-0K2OI03",
        "python_version": "3.10.10",
        "python_implementation": "CPython",
        "cpu_name": "AMD64 Family 26 Model 68 Stepping 0, AuthenticAMD",
        "cpu_cores": 8,
        "cpu_threads": 16,
        "cpu_freq_mhz": 4700.0,
        "memory_total_gb": 31.15,
        "memory_available_gb": 19.11,
        "gpu_name": "NVIDIA GeForce RTX 5080",
        "gpu_count": 1,
        "gpu_memory_total_mb": 16303.0,
        "gpu_driver_version": "581.08",
        "cuda_version": "12.8",
        "maeum_version": "",
        "model_name": "",
        "model_variant": "",
        "quantization": ""
      },
      "model_info": {},
      "notes": {
        "status": "official_dataset",
        "benchmark_type": "xnli",
        "dataset": "facebook/xnli"
      },
      "raw_latencies": []
    },
    {
      "benchmark_id": "latency",
      "benchmark_name": "Latency",
      "category": "performance",
      "mode": "auto",
      "timestamp": "20251202_150910",
      "duration_s": 15.29270052909851,
      "num_samples": 8,
      "success_count": 8,
      "error_count": 0,
      "latency": {
        "avg_ms": 1836.4888625219464,
        "p50_ms": 1900.5440501496196,
        "p90_ms": 2154.28003994748,
        "p95_ms": 2391.1892719799653,
        "p99_ms": 2628.0985040124506,
        "min_ms": 664.9605000857264,
        "max_ms": 2680.7450000196695,
        "std_ms": 0.0,
        "count": 8
      },
      "power": {
        "power_avg_w": 175.6625777777778,
        "power_max_w": 214.401,
        "power_min_w": null,
        "gpu_util_avg": 50.19259259259259,
        "gpu_util_max": null,
        "gpu_mem_avg_mb": null,
        "gpu_mem_peak_mb": 5084.1328125,
        "gpu_temp_avg_c": null,
        "gpu_temp_max_c": 58.0,
        "cpu_util_avg": 7.754074074074075,
        "cpu_util_max": null,
        "cpu_mem_avg_mb": null,
        "cpu_mem_peak_mb": 13322.921875
      },
      "accuracy": {
        "accuracy": null,
        "f1": null,
        "em": null,
        "precision": null,
        "recall": null,
        "extra": {}
      },
      "efficiency": {
        "perf_per_watt": 0.0030994072924160477,
        "latency_per_watt": 322602.36765078414,
        "tokens_per_second": null,
        "tokens_per_watt": null
      },
      "config": {
        "suite_name": "performance",
        "benchmark_name": "latency",
        "task_name": "Latency",
        "concurrency": 1,
        "num_requests": 50,
        "duration_s": null,
        "host": "localhost",
        "port": 12345,
        "endpoint": "/generate/simple",
        "mode": "auto",
        "max_tokens": 256,
        "temperature": 0.7,
        "model_name": null,
        "model_variant": null,
        "quantization": null,
        "compression_techniques": null,
        "context_window": null,
        "run_id": "8627cfb6-befe-49b9-bde5-1f4b391e3118"
      },
      "system_info": {
        "os_system": "Windows",
        "os_release": "10",
        "os_version": "10.0.26100",
        "hostname": "DESKTOP-0K2OI03",
        "python_version": "3.10.10",
        "python_implementation": "CPython",
        "cpu_name": "AMD64 Family 26 Model 68 Stepping 0, AuthenticAMD",
        "cpu_cores": 8,
        "cpu_threads": 16,
        "cpu_freq_mhz": 4700.0,
        "memory_total_gb": 31.15,
        "memory_available_gb": 19.11,
        "gpu_name": "NVIDIA GeForce RTX 5080",
        "gpu_count": 1,
        "gpu_memory_total_mb": 16303.0,
        "gpu_driver_version": "581.08",
        "cuda_version": "12.8",
        "maeum_version": "",
        "model_name": "",
        "model_variant": "",
        "quantization": ""
      },
      "model_info": {},
      "notes": {
        "benchmark_type": "latency_throughput_only",
        "description": "Simple latency/throughput benchmark for Maeum API."
      },
      "raw_latencies": []
    },
    {
      "benchmark_id": "latency",
      "benchmark_name": "Latency",
      "category": "performance",
      "mode": "balanced",
      "timestamp": "20251202_150910",
      "duration_s": 13.644614219665527,
      "num_samples": 8,
      "success_count": 8,
      "error_count": 0,
      "latency": {
        "avg_ms": 1627.0513249910437,
        "p50_ms": 1892.8747000172734,
        "p90_ms": 1916.1158000584692,
        "p95_ms": 1924.9521800153889,
        "p99_ms": 1933.7885599723086,
        "min_ms": 268.15420016646385,
        "max_ms": 1935.7521999627352,
        "std_ms": 0.0,
        "count": 8
      },
      "power": {
        "power_avg_w": 183.52952500000023,
        "power_max_w": 213.733,
        "power_min_w": null,
        "gpu_util_avg": 50.11666666666667,
        "gpu_util_max": null,
        "gpu_mem_avg_mb": null,
        "gpu_mem_peak_mb": 5084.1328125,
        "gpu_temp_avg_c": null,
        "gpu_temp_max_c": 58.0,
        "cpu_util_avg": 7.643333333333335,
        "cpu_util_max": null,
        "cpu_mem_avg_mb": null,
        "cpu_mem_peak_mb": 13311.03125
      },
      "accuracy": {
        "accuracy": null,
        "f1": null,
        "em": null,
        "precision": null,
        "recall": null,
        "extra": {}
      },
      "efficiency": {
        "perf_per_watt": 0.0033483837744505136,
        "latency_per_watt": 298611.95682622725,
        "tokens_per_second": null,
        "tokens_per_watt": null
      },
      "config": {
        "suite_name": "performance",
        "benchmark_name": "latency",
        "task_name": "Latency",
        "concurrency": 1,
        "num_requests": 50,
        "duration_s": null,
        "host": "localhost",
        "port": 12345,
        "endpoint": "/generate/simple",
        "mode": "balanced",
        "max_tokens": 256,
        "temperature": 0.7,
        "model_name": null,
        "model_variant": null,
        "quantization": null,
        "compression_techniques": null,
        "context_window": null,
        "run_id": "f1829615-a2a8-45e1-a113-85d7ae47604a"
      },
      "system_info": {
        "os_system": "Windows",
        "os_release": "10",
        "os_version": "10.0.26100",
        "hostname": "DESKTOP-0K2OI03",
        "python_version": "3.10.10",
        "python_implementation": "CPython",
        "cpu_name": "AMD64 Family 26 Model 68 Stepping 0, AuthenticAMD",
        "cpu_cores": 8,
        "cpu_threads": 16,
        "cpu_freq_mhz": 4700.0,
        "memory_total_gb": 31.15,
        "memory_available_gb": 19.11,
        "gpu_name": "NVIDIA GeForce RTX 5080",
        "gpu_count": 1,
        "gpu_memory_total_mb": 16303.0,
        "gpu_driver_version": "581.08",
        "cuda_version": "12.8",
        "maeum_version": "",
        "model_name": "",
        "model_variant": "",
        "quantization": ""
      },
      "model_info": {},
      "notes": {
        "benchmark_type": "latency_throughput_only",
        "description": "Simple latency/throughput benchmark for Maeum API."
      },
      "raw_latencies": []
    },
    {
      "benchmark_id": "latency",
      "benchmark_name": "Latency",
      "category": "performance",
      "mode": "fast",
      "timestamp": "20251202_150910",
      "duration_s": 12.996574878692627,
      "num_samples": 8,
      "success_count": 8,
      "error_count": 0,
      "latency": {
        "avg_ms": 1543.789087474579,
        "p50_ms": 1891.796650015749,
        "p90_ms": 1917.4341399921104,
        "p95_ms": 1918.3639570313971,
        "p99_ms": 1919.2937740706839,
        "min_ms": 421.52870004065335,
        "max_ms": 1919.5004000794142,
        "std_ms": 0.0,
        "count": 8
      },
      "power": {
        "power_avg_w": 180.8485789473683,
        "power_max_w": 213.781,
        "power_min_w": null,
        "gpu_util_avg": 66.45614035087719,
        "gpu_util_max": null,
        "gpu_mem_avg_mb": null,
        "gpu_mem_peak_mb": 5084.1328125,
        "gpu_temp_avg_c": null,
        "gpu_temp_max_c": 57.0,
        "cpu_util_avg": 7.826315789473685,
        "cpu_util_max": null,
        "cpu_mem_avg_mb": null,
        "cpu_mem_peak_mb": 13310.5
      },
      "accuracy": {
        "accuracy": null,
        "f1": null,
        "em": null,
        "precision": null,
        "recall": null,
        "extra": {}
      },
      "efficiency": {
        "perf_per_watt": 0.0035811818399052123,
        "latency_per_watt": 279192.0626642321,
        "tokens_per_second": null,
        "tokens_per_watt": null
      },
      "config": {
        "suite_name": "performance",
        "benchmark_name": "latency",
        "task_name": "Latency",
        "concurrency": 1,
        "num_requests": 50,
        "duration_s": null,
        "host": "localhost",
        "port": 12345,
        "endpoint": "/generate/simple",
        "mode": "fast",
        "max_tokens": 256,
        "temperature": 0.7,
        "model_name": null,
        "model_variant": null,
        "quantization": null,
        "compression_techniques": null,
        "context_window": null,
        "run_id": "1d9ebf39-4097-4cfc-8e01-5d4dcbe03dff"
      },
      "system_info": {
        "os_system": "Windows",
        "os_release": "10",
        "os_version": "10.0.26100",
        "hostname": "DESKTOP-0K2OI03",
        "python_version": "3.10.10",
        "python_implementation": "CPython",
        "cpu_name": "AMD64 Family 26 Model 68 Stepping 0, AuthenticAMD",
        "cpu_cores": 8,
        "cpu_threads": 16,
        "cpu_freq_mhz": 4700.0,
        "memory_total_gb": 31.15,
        "memory_available_gb": 19.11,
        "gpu_name": "NVIDIA GeForce RTX 5080",
        "gpu_count": 1,
        "gpu_memory_total_mb": 16303.0,
        "gpu_driver_version": "581.08",
        "cuda_version": "12.8",
        "maeum_version": "",
        "model_name": "",
        "model_variant": "",
        "quantization": ""
      },
      "model_info": {},
      "notes": {
        "benchmark_type": "latency_throughput_only",
        "description": "Simple latency/throughput benchmark for Maeum API."
      },
      "raw_latencies": []
    },
    {
      "benchmark_id": "latency",
      "benchmark_name": "Latency",
      "category": "performance",
      "mode": "quality",
      "timestamp": "20251202_150910",
      "duration_s": 15.156930208206177,
      "num_samples": 8,
      "success_count": 8,
      "error_count": 0,
      "latency": {
        "avg_ms": 1818.5935750370845,
        "p50_ms": 1905.9184499783441,
        "p90_ms": 1914.9641700088978,
        "p95_ms": 1918.9315635384992,
        "p99_ms": 1922.8989570681006,
        "min_ms": 1202.3459000047296,
        "max_ms": 1923.7806000746787,
        "std_ms": 0.0,
        "count": 8
      },
      "power": {
        "power_avg_w": 184.67240298507457,
        "power_max_w": 213.907,
        "power_min_w": null,
        "gpu_util_avg": 67.0,
        "gpu_util_max": null,
        "gpu_mem_avg_mb": null,
        "gpu_mem_peak_mb": 5084.1328125,
        "gpu_temp_avg_c": null,
        "gpu_temp_max_c": 57.0,
        "cpu_util_avg": 8.226865671641791,
        "cpu_util_max": null,
        "cpu_mem_avg_mb": null,
        "cpu_mem_peak_mb": 13309.51953125
      },
      "accuracy": {
        "accuracy": null,
        "f1": null,
        "em": null,
        "precision": null,
        "recall": null,
        "extra": {}
      },
      "efficiency": {
        "perf_per_watt": 0.0029772494320066583,
        "latency_per_watt": 335844.0455553159,
        "tokens_per_second": null,
        "tokens_per_watt": null
      },
      "config": {
        "suite_name": "performance",
        "benchmark_name": "latency",
        "task_name": "Latency",
        "concurrency": 1,
        "num_requests": 50,
        "duration_s": null,
        "host": "localhost",
        "port": 12345,
        "endpoint": "/generate/simple",
        "mode": "quality",
        "max_tokens": 256,
        "temperature": 0.7,
        "model_name": null,
        "model_variant": null,
        "quantization": null,
        "compression_techniques": null,
        "context_window": null,
        "run_id": "8b826da9-c3d9-4846-93d9-10012efe5d40"
      },
      "system_info": {
        "os_system": "Windows",
        "os_release": "10",
        "os_version": "10.0.26100",
        "hostname": "DESKTOP-0K2OI03",
        "python_version": "3.10.10",
        "python_implementation": "CPython",
        "cpu_name": "AMD64 Family 26 Model 68 Stepping 0, AuthenticAMD",
        "cpu_cores": 8,
        "cpu_threads": 16,
        "cpu_freq_mhz": 4700.0,
        "memory_total_gb": 31.15,
        "memory_available_gb": 19.11,
        "gpu_name": "NVIDIA GeForce RTX 5080",
        "gpu_count": 1,
        "gpu_memory_total_mb": 16303.0,
        "gpu_driver_version": "581.08",
        "cuda_version": "12.8",
        "maeum_version": "",
        "model_name": "",
        "model_variant": "",
        "quantization": ""
      },
      "model_info": {},
      "notes": {
        "benchmark_type": "latency_throughput_only",
        "description": "Simple latency/throughput benchmark for Maeum API."
      },
      "raw_latencies": []
    }
  ]
}